# 06 - 存储性能优化

**作者**: 云原生存储专家团队  
**创建日期**: 2025-10-19  
**最后更新**: 2025-10-19  
**版本**: v1.0

---

## 📋 本章导航

- [06 - 存储性能优化](#06---存储性能优化)
  - [📋 本章导航](#-本章导航)
  - [1. 性能指标](#1-性能指标)
    - [1.1 核心指标](#11-核心指标)
    - [1.2 指标采集](#12-指标采集)
    - [1.3 性能基准](#13-性能基准)
  - [2. 性能测试](#2-性能测试)
    - [2.1 FIO测试](#21-fio测试)
    - [2.2 dd测试](#22-dd测试)
    - [2.3 sysbench测试](#23-sysbench测试)
    - [2.4 Kubernetes存储性能测试](#24-kubernetes存储性能测试)
  - [3. Ceph性能优化](#3-ceph性能优化)
    - [3.1 OSD优化](#31-osd优化)
    - [3.2 网络优化](#32-网络优化)
    - [3.3 客户端优化](#33-客户端优化)
  - [4. 文件系统优化](#4-文件系统优化)
    - [4.1 文件系统选择](#41-文件系统选择)
    - [4.2 挂载选项](#42-挂载选项)
  - [5. 内核参数优化](#5-内核参数优化)
    - [5.1 I/O调度器](#51-io调度器)
    - [5.2 内核参数](#52-内核参数)
  - [6. 容量规划](#6-容量规划)
    - [6.1 容量预测](#61-容量预测)
    - [6.2 扩容策略](#62-扩容策略)
    - [6.3 成本优化](#63-成本优化)
  - [7. 性能监控](#7-性能监控)
    - [7.1 Prometheus监控](#71-prometheus监控)
    - [7.2 Grafana仪表盘](#72-grafana仪表盘)
    - [7.3 告警规则](#73-告警规则)
  - [8. 总结](#8-总结)

---

## 1. 性能指标

### 1.1 核心指标

**存储性能四大指标**:

```yaml
1. IOPS (Input/Output Operations Per Second):
   定义:
     - 每秒读写操作次数
     - 衡量随机读写性能
   
   典型值:
     - HDD: 100-200 IOPS
     - SATA SSD: 10,000-100,000 IOPS
     - NVMe SSD: 100,000-1,000,000+ IOPS
     - Ceph (3-way replica): 20,000-50,000 IOPS
   
   影响因素:
     - 存储介质 (HDD/SSD/NVMe)
     - 块大小 (4K/8K/16K)
     - 读写比例 (Read/Write)
     - 随机/顺序访问
     - 队列深度 (QD)

2. Throughput (吞吐量):
   定义:
     - 每秒传输的数据量 (MB/s, GB/s)
     - 衡量顺序读写性能
   
   典型值:
     - HDD (7200RPM): 100-200 MB/s
     - SATA SSD: 500-600 MB/s
     - NVMe SSD: 3,000-7,000 MB/s
     - Ceph (3-way replica): 500-2,000 MB/s
     - 10GbE网络: ~1,200 MB/s
     - 25GbE网络: ~3,000 MB/s
   
   影响因素:
     - 存储介质
     - 块大小
     - 网络带宽
     - CPU性能
     - 内存

3. Latency (延迟):
   定义:
     - 单次I/O操作的响应时间
     - 单位: 毫秒 (ms)、微秒 (μs)
   
   典型值:
     - HDD: 5-10 ms
     - SATA SSD: 0.1-1 ms
     - NVMe SSD: 0.01-0.1 ms (10-100 μs)
     - Ceph (local): 1-5 ms
     - Ceph (remote): 5-20 ms
   
   影响因素:
     - 存储介质
     - 网络延迟
     - 队列深度
     - CPU调度
     - 系统负载
   
   P99延迟:
     - 99%的请求在此延迟内完成
     - 比平均延迟更重要 (tail latency)

4. Capacity (容量):
   定义:
     - 可用存储空间
     - 实际可用 vs 原始容量
   
   计算:
     - Ceph (3-way replica): 实际容量 = 原始容量 / 3
     - Ceph (Erasure Coding 8+2): 实际容量 = 原始容量 * 0.8
   
   容量规划:
     - 预留20-30%空闲空间
     - 考虑增长率
     - 扩容时间窗口
```

---

### 1.2 指标采集

**Linux工具**:

```bash
# 1. iostat - I/O统计
iostat -x 1 10
# 关键列:
# - %util: 设备利用率 (100%表示饱和)
# - r/s, w/s: 每秒读写次数 (IOPS)
# - rMB/s, wMB/s: 每秒读写吞吐量
# - await: 平均等待时间 (延迟)
# - svctm: 平均服务时间

# 2. sar - 系统活动报告
sar -d 1 10
# 磁盘I/O统计

# 3. iotop - I/O进程监控
iotop -o
# 显示I/O占用Top进程

# 4. blktrace - 块设备跟踪
blktrace -d /dev/sda -o trace
blkparse -i trace

# 5. dstat - 综合监控
dstat -cdngy
# CPU、磁盘、网络、内存统计
```

---

### 1.3 性能基准

**存储性能分级**:

```yaml
高性能 (High Performance):
  IOPS: 100,000+
  吞吐量: 3,000+ MB/s
  延迟: < 1 ms (P99)
  应用: 数据库、实时分析
  成本: 高
  存储: NVMe SSD, 本地SSD

中等性能 (Medium Performance):
  IOPS: 10,000-100,000
  吞吐量: 500-3,000 MB/s
  延迟: 1-5 ms (P99)
  应用: Web应用、缓存
  成本: 中
  存储: SATA SSD, Ceph RBD

一般性能 (Standard Performance):
  IOPS: 1,000-10,000
  吞吐量: 100-500 MB/s
  延迟: 5-20 ms (P99)
  应用: 日志、归档
  成本: 低
  存储: HDD, Ceph (HDD)

归档 (Archive):
  IOPS: < 1,000
  吞吐量: < 100 MB/s
  延迟: 20+ ms
  应用: 冷数据
  成本: 极低
  存储: 对象存储, 磁带
```

---

## 2. 性能测试

### 2.1 FIO测试

**FIO (Flexible I/O Tester)** 是最强大的存储性能测试工具。

**安装FIO**:

```bash
# Ubuntu/Debian
apt-get install -y fio

# CentOS/RHEL
yum install -y fio
```

**随机读测试**:

```bash
# 随机读 (4K块, QD=32)
fio --name=randread --ioengine=libaio --iodepth=32 --rw=randread \
    --bs=4k --direct=1 --size=1G --numjobs=4 --runtime=60 \
    --group_reporting --filename=/mnt/test-file

# 参数说明:
# --ioengine=libaio: 使用Linux异步I/O
# --iodepth=32: 队列深度32
# --rw=randread: 随机读
# --bs=4k: 块大小4KB
# --direct=1: 绕过缓存 (Direct I/O)
# --size=1G: 测试文件大小
# --numjobs=4: 4个并发任务
# --runtime=60: 运行60秒
```

**随机写测试**:

```bash
# 随机写 (4K块, QD=32)
fio --name=randwrite --ioengine=libaio --iodepth=32 --rw=randwrite \
    --bs=4k --direct=1 --size=1G --numjobs=4 --runtime=60 \
    --group_reporting --filename=/mnt/test-file
```

**顺序读测试**:

```bash
# 顺序读 (1M块, QD=16)
fio --name=seqread --ioengine=libaio --iodepth=16 --rw=read \
    --bs=1m --direct=1 --size=4G --numjobs=1 --runtime=60 \
    --group_reporting --filename=/mnt/test-file
```

**顺序写测试**:

```bash
# 顺序写 (1M块, QD=16)
fio --name=seqwrite --ioengine=libaio --iodepth=16 --rw=write \
    --bs=1m --direct=1 --size=4G --numjobs=1 --runtime=60 \
    --group_reporting --filename=/mnt/test-file
```

**混合读写测试**:

```bash
# 70%读 + 30%写
fio --name=randrw --ioengine=libaio --iodepth=32 --rw=randrw \
    --rwmixread=70 --bs=4k --direct=1 --size=1G --numjobs=4 \
    --runtime=60 --group_reporting --filename=/mnt/test-file
```

**FIO配置文件**:

```ini
# fio.conf
[global]
ioengine=libaio
direct=1
size=1G
runtime=60
group_reporting

[randread-4k]
rw=randread
bs=4k
iodepth=32
numjobs=4
filename=/mnt/test-file-1

[randwrite-4k]
rw=randwrite
bs=4k
iodepth=32
numjobs=4
filename=/mnt/test-file-2

[seqread-1m]
rw=read
bs=1m
iodepth=16
numjobs=1
filename=/mnt/test-file-3

[seqwrite-1m]
rw=write
bs=1m
iodepth=16
numjobs=1
filename=/mnt/test-file-4

# 运行:
# fio fio.conf
```

**解析FIO输出**:

```bash
# 示例输出:
randread: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=32
...
  read: IOPS=12.5k, BW=48.8MiB/s (51.2MB/s)(2930MiB/60001msec)
    slat (usec): min=2, max=1234, avg=12.34, stdev=23.45
    clat (usec): min=123, max=12345, avg=2048.56, stdev=345.67
     lat (usec): min=234, max=13456, avg=2060.90, stdev=347.89
    clat percentiles (usec):
     |  1.00th=[  300],  5.00th=[  400], 10.00th=[  500], 20.00th=[  700],
     | 30.00th=[ 1000], 40.00th=[ 1500], 50.00th=[ 1900], 60.00th=[ 2200],
     | 70.00th=[ 2600], 80.00th=[ 3000], 90.00th=[ 3500], 95.00th=[ 4000],
     | 99.00th=[ 5000], 99.50th=[ 5500], 99.90th=[ 7000], 99.95th=[ 8000],
     | 99.99th=[10000]

# 关键指标:
# - IOPS=12.5k: 每秒12,500次读操作
# - BW=48.8MiB/s: 吞吐量48.8 MB/s
# - avg=2048.56: 平均延迟2.05 ms
# - 99.00th=[5000]: P99延迟5 ms
```

---

### 2.2 dd测试

**dd (Data Duplicator)** 是简单的I/O测试工具。

**顺序写测试**:

```bash
# 写入1GB数据
dd if=/dev/zero of=/mnt/test-file bs=1M count=1024 oflag=direct
# 1024+0 records in
# 1024+0 records out
# 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 2.12345 s, 505 MB/s
```

**顺序读测试**:

```bash
# 读取1GB数据
dd if=/mnt/test-file of=/dev/null bs=1M count=1024 iflag=direct
```

**随机读测试** (使用dd + seek):

```bash
# 随机读 (不推荐，FIO更好)
for i in {1..1000}; do
  dd if=/mnt/test-file of=/dev/null bs=4k count=1 skip=$((RANDOM % 262144)) iflag=direct 2>&1 | grep copied
done
```

---

### 2.3 sysbench测试

**sysbench** 支持文件I/O和数据库性能测试。

**安装sysbench**:

```bash
# Ubuntu/Debian
apt-get install -y sysbench

# CentOS/RHEL
yum install -y sysbench
```

**文件I/O测试**:

```bash
# 1. 准备测试文件 (16个, 每个1GB)
sysbench fileio --file-total-size=16G prepare

# 2. 随机读写测试
sysbench fileio --file-total-size=16G --file-test-mode=rndrw \
  --time=60 --max-requests=0 --threads=16 run

# 3. 顺序读测试
sysbench fileio --file-total-size=16G --file-test-mode=seqrd \
  --time=60 --max-requests=0 --threads=4 run

# 4. 顺序写测试
sysbench fileio --file-total-size=16G --file-test-mode=seqwr \
  --time=60 --max-requests=0 --threads=4 run

# 5. 清理
sysbench fileio --file-total-size=16G cleanup
```

---

### 2.4 Kubernetes存储性能测试

**dbench** - Kubernetes存储性能测试工具:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: dbench
spec:
  template:
    spec:
      containers:
      - name: dbench
        image: sotoaster/dbench:latest
        imagePullPolicy: Always
        env:
        - name: DBENCH_MOUNTPOINT
          value: /data
        volumeMounts:
        - name: dbench-pv
          mountPath: /data
      restartPolicy: Never
      volumes:
      - name: dbench-pv
        persistentVolumeClaim:
          claimName: dbench-pvc
  backoffLimit: 4

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: dbench-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: rook-ceph-block

# 运行:
# kubectl apply -f dbench.yaml
# kubectl logs job/dbench
```

**kubestr** - Kubernetes存储测试工具:

```bash
# 安装kubestr
curl -LO https://github.com/kastenhq/kubestr/releases/download/v0.4.37/kubestr-v0.4.37-linux-amd64.tar.gz
tar -xvzf kubestr-v0.4.37-linux-amd64.tar.gz
chmod +x kubestr
mv kubestr /usr/local/bin/

# FIO测试
kubestr fio -s rook-ceph-block -z 10Gi

# 示例输出:
# PVC created kubestr-fio-pvc-xxxxx
# Pod created kubestr-fio-pod-xxxxx
# Running FIO test (random-read-write) on StorageClass (rook-ceph-block)...
#
# FIO test results:
#   READ IOPS:    12345
#   WRITE IOPS:   10234
#   READ BW:      48.2 MB/s
#   WRITE BW:     40.1 MB/s
#   READ LATENCY: 2.5 ms
#   WRITE LATENCY: 3.1 ms
```

---

## 3. Ceph性能优化

### 3.1 OSD优化

**Ceph OSD参数调优**:

```yaml
# ceph.conf
[osd]
# 1. Journal/WAL优化 (BlueStore)
bluestore_block_db_size = 21474836480  # 20GB DB (SSD)
bluestore_block_wal_size = 1073741824  # 1GB WAL (SSD)
bluestore_min_alloc_size_hdd = 65536   # 64KB (HDD)
bluestore_min_alloc_size_ssd = 16384   # 16KB (SSD)

# 2. BlueStore缓存
bluestore_cache_size_hdd = 1073741824  # 1GB (HDD)
bluestore_cache_size_ssd = 3221225472  # 3GB (SSD)

# 3. OSD线程
osd_op_threads = 8                     # OSD操作线程 (建议: CPU核数)
osd_op_num_threads_per_shard = 2      # 每分片线程数
osd_op_num_shards = 32                 # 分片数

# 4. 客户端消息队列
osd_client_message_size_cap = 524288000  # 500MB

# 5. Recovery (恢复)
osd_max_backfills = 1                  # 最大同时恢复数
osd_recovery_max_active = 3            # 最大活跃恢复
osd_recovery_op_priority = 3           # 恢复优先级 (低)
osd_recovery_sleep_hdd = 0.1           # HDD恢复延迟
osd_recovery_sleep_ssd = 0             # SSD无延迟

# 6. Scrub (校验)
osd_scrub_begin_hour = 2               # 凌晨2点开始
osd_scrub_end_hour = 6                 # 早上6点结束
osd_scrub_during_recovery = false      # 恢复时不校验
osd_scrub_load_threshold = 0.5         # 负载阈值
```

**应用配置**:

```bash
# 方式1: ceph.conf (重启OSD)
# 编辑ceph.conf后重启OSD Pod

# 方式2: 在线调整 (临时)
ceph tell osd.* injectargs '--osd-max-backfills 1'
ceph tell osd.* injectargs '--osd-recovery-max-active 3'

# 方式3: 配置数据库 (永久)
ceph config set osd osd_max_backfills 1
ceph config set osd osd_recovery_max_active 3
```

---

### 3.2 网络优化

**Ceph网络配置**:

```yaml
网络要求:
  前端网络 (client):
    - 10GbE+ (推荐25GbE)
    - 低延迟 (< 1ms)
    - 用于客户端访问
  
  后端网络 (cluster):
    - 10GbE+ (推荐25GbE或40GbE)
    - 高带宽
    - 用于OSD复制

优化:
  1. 专用网络:
     - 前后端分离
     - VLAN隔离
     - 避免与其他流量竞争
  
  2. MTU (Jumbo Frame):
     - 设置MTU=9000
     - 减少TCP分片
     - 提升吞吐量
  
  3. TCP参数:
     - tcp_wmem/tcp_rmem
     - tcp_congestion_control=bbr
     - net.core.rmem_max/wmem_max
```

**配置MTU=9000**:

```bash
# 1. 检查当前MTU
ip link show | grep mtu

# 2. 设置MTU (临时)
ip link set eth0 mtu 9000
ip link set eth1 mtu 9000

# 3. 永久配置 (/etc/network/interfaces)
auto eth0
iface eth0 inet static
  address 10.0.1.10
  netmask 255.255.255.0
  mtu 9000

# 4. 验证
ping -M do -s 8972 10.0.1.11
# 8972 + 28 (IP+ICMP header) = 9000
```

**TCP调优**:

```bash
# /etc/sysctl.conf
net.core.rmem_max = 536870912         # 512MB接收缓冲
net.core.wmem_max = 536870912         # 512MB发送缓冲
net.ipv4.tcp_rmem = 4096 87380 536870912
net.ipv4.tcp_wmem = 4096 65536 536870912
net.ipv4.tcp_congestion_control = bbr  # BBR拥塞控制
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 8192

# 应用
sysctl -p
```

---

### 3.3 客户端优化

**RBD客户端优化**:

```yaml
# StorageClass参数
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-ceph-block-optimized
provisioner: rook-ceph.rbd.csi.ceph.com
parameters:
  clusterID: rook-ceph
  pool: replicapool
  imageFormat: "2"
  imageFeatures: layering,exclusive-lock,object-map,fast-diff
  csi.storage.k8s.io/fstype: ext4
  
  # RBD性能参数
  mounter: rbd-nbd  # 或 rbd-kernel
  mapOptions: "krbd:rxbounce"
  
reclaimPolicy: Delete
allowVolumeExpansion: true
mountOptions:
- discard                # TRIM支持
- noatime                # 不更新访问时间
- nodiratime             # 目录不更新访问时间
```

**CephFS客户端优化**:

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-cephfs-optimized
provisioner: rook-ceph.cephfs.csi.ceph.com
parameters:
  clusterID: rook-ceph
  fsName: myfs
  pool: myfs-data0
  
  # CephFS性能参数
  mounter: kernel  # 或 fuse
  
reclaimPolicy: Delete
allowVolumeExpansion: true
mountOptions:
- noatime
- nodiratime
- readdir_max_entries=1000
```

---

## 4. 文件系统优化

### 4.1 文件系统选择

**文件系统对比**:

```yaml
ext4:
  优势:
    ✅ 成熟稳定
    ✅ 兼容性好
    ✅ 性能均衡
  
  劣势:
    ❌ 不支持写时复制 (COW)
    ❌ 扩展性一般
  
  适用:
    - 通用场景
    - 数据库
  
  推荐配置:
    mkfs.ext4 -E lazy_itable_init=0,lazy_journal_init=0 /dev/sda1

xfs:
  优势:
    ✅ 高性能
    ✅ 大文件支持好
    ✅ 并行I/O
    ✅ 在线扩容
  
  劣势:
    ❌ 不支持在线缩容
    ❌ 元数据恢复慢
  
  适用:
    - 大文件
    - 高并发
    - Ceph OSD (BlueStore在裸盘上运行，不需要文件系统)
  
  推荐配置:
    mkfs.xfs -f -i size=2048 /dev/sda1

btrfs:
  优势:
    ✅ 写时复制 (COW)
    ✅ 快照
    ✅ 数据校验
    ✅ 透明压缩
  
  劣势:
    ❌ 性能开销
    ❌ 稳定性 (相对)
  
  适用:
    - 快照需求
    - 数据校验

f2fs (Flash-Friendly File System):
  优势:
    ✅ 为SSD优化
    ✅ 减少写放大
  
  适用:
    - SSD/NVMe
    - Android

选择建议:
  通用: ext4
  高性能: xfs
  快照: btrfs
  SSD: f2fs
```

---

### 4.2 挂载选项

**ext4挂载选项**:

```bash
mount -t ext4 -o noatime,nodiratime,discard,commit=60 /dev/sda1 /mnt

# 选项说明:
# - noatime: 不更新访问时间 (减少写入)
# - nodiratime: 目录不更新访问时间
# - discard: TRIM支持 (SSD)
# - commit=60: 60秒提交一次 (默认5秒)
```

**/etc/fstab配置**:

```bash
# /etc/fstab
/dev/sda1  /mnt  ext4  noatime,nodiratime,discard,commit=60  0 2
```

**xfs挂载选项**:

```bash
mount -t xfs -o noatime,nodiratime,discard,logbsize=256k /dev/sda1 /mnt

# 选项说明:
# - logbsize=256k: 日志缓冲区256KB (默认32KB)
```

---

## 5. 内核参数优化

### 5.1 I/O调度器

**Linux I/O调度器**:

```yaml
调度器类型:
  
1. noop (No Operation):
   特点:
     - 最简单
     - FIFO队列
     - 无合并、无排序
   
   适用:
     - SSD/NVMe (自带调度)
     - RAID控制器
   
   性能:
     - 延迟低
     - IOPS高

2. deadline:
   特点:
     - 保证最大延迟
     - 读优先
   
   适用:
     - 数据库
     - 实时应用
   
   性能:
     - 延迟可预测
     - 读性能好

3. cfq (Completely Fair Queuing):
   特点:
     - 公平调度
     - 按进程分配带宽
   
   适用:
     - 通用桌面
     - 多任务
   
   性能:
     - 公平性好
     - 吞吐量一般

4. mq-deadline (Multi-Queue Deadline):
   特点:
     - 多队列
     - NVMe优化
   
   适用:
     - NVMe SSD
     - 高IOPS
   
   性能:
     - 高并发
     - 低延迟

5. kyber:
   特点:
     - 动态调整
     - 延迟优先
   
   适用:
     - NVMe SSD
     - 延迟敏感
   
   性能:
     - P99延迟低
```

**查看和设置I/O调度器**:

```bash
# 查看当前调度器
cat /sys/block/sda/queue/scheduler
# [mq-deadline] kyber bfq none

# 临时设置
echo deadline > /sys/block/sda/queue/scheduler

# 永久设置 (GRUB)
# /etc/default/grub
GRUB_CMDLINE_LINUX="elevator=deadline"
# 更新GRUB:
update-grub

# 或使用udev规则
# /etc/udev/rules.d/60-scheduler.rules
ACTION=="add|change", KERNEL=="sd[a-z]", ATTR{queue/scheduler}="deadline"
ACTION=="add|change", KERNEL=="nvme[0-9]n[0-9]", ATTR{queue/scheduler}="none"
```

**推荐配置**:

```yaml
存储类型推荐:
  HDD: deadline或cfq
  SATA SSD: deadline或noop
  NVMe SSD: none或mq-deadline或kyber
  Ceph OSD (HDD): deadline
  Ceph OSD (SSD): none或mq-deadline
```

---

### 5.2 内核参数

**存储相关内核参数**:

```bash
# /etc/sysctl.conf

# 1. 虚拟内存
vm.swappiness = 10                    # 降低swap使用 (默认60)
vm.dirty_ratio = 15                   # 脏页比例15% (默认20%)
vm.dirty_background_ratio = 5         # 后台写回5% (默认10%)
vm.vfs_cache_pressure = 50            # 缓存压力 (默认100)

# 2. I/O
vm.min_free_kbytes = 1048576          # 最小空闲内存1GB
kernel.pid_max = 4194303              # 最大PID数

# 3. 文件系统
fs.file-max = 6553600                 # 最大打开文件数
fs.aio-max-nr = 1048576               # 最大异步I/O请求

# 4. 网络 (已在3.2节)
...

# 应用
sysctl -p
```

**验证**:

```bash
# 查看当前值
sysctl vm.swappiness
sysctl vm.dirty_ratio

# 查看所有
sysctl -a | grep vm.
```

---

## 6. 容量规划

### 6.1 容量预测

**容量增长模型**:

```yaml
线性增长模型:
  公式: 容量(t) = 初始容量 + 增长率 * t
  
  示例:
    初始容量: 100TB
    月增长率: 5TB/月
    6个月后: 100 + 5 * 6 = 130TB

指数增长模型:
  公式: 容量(t) = 初始容量 * (1 + 增长率)^t
  
  示例:
    初始容量: 100TB
    月增长率: 5% (0.05)
    6个月后: 100 * (1.05)^6 ≈ 134TB

实际增长 (混合):
  - 应用数据: 线性增长
  - 日志/监控: 线性增长
  - 备份/快照: 指数增长 (如果保留历史)
  - AI/ML数据: 指数增长
```

**容量监控**:

```bash
# Ceph容量
ceph df
# RAW STORAGE:
#     CLASS     SIZE        AVAIL       USED        RAW USED     %RAW USED
#     hdd       100 TiB     80 TiB      20 TiB      20 TiB           20.00
#     ssd        20 TiB     16 TiB       4 TiB       4 TiB           20.00
#     TOTAL     120 TiB     96 TiB      24 TiB      24 TiB           20.00
#
# POOLS:
#     POOL              ID     STORED      OBJECTS     USED        %USED     MAX AVAIL
#     replicapool        1     6.5 TiB     1.7M        19.5 TiB    24.38     25.5 TiB
#     myfs-data0         2       1 TiB     256k         3 TiB      3.75     25.5 TiB

# Kubernetes PVC使用
kubectl get pvc -A -o custom-columns=\
NAMESPACE:.metadata.namespace,\
NAME:.metadata.name,\
CAPACITY:.status.capacity.storage,\
STORAGECLASS:.spec.storageClassName

# 聚合统计
kubectl get pvc -A -o json | jq -r '
  .items[] | select(.status.phase == "Bound") | 
  .status.capacity.storage' | 
  awk '{sum+=$1} END {print sum}'
```

---

### 6.2 扩容策略

**Ceph扩容**:

```yaml
扩容方式:
  1. 添加OSD (横向扩展):
     - 增加存储容量
     - 提升IOPS和吞吐量
     - Ceph自动Rebalance
     - 推荐: 每次添加3-6个OSD
  
  2. 替换OSD (纵向扩展):
     - 更大容量磁盘
     - 逐个替换
     - Rebalance影响小
  
  3. 添加节点:
     - 横向扩展
     - 提升网络带宽
     - 提升冗余

扩容流程:
  1. 规划:
     - 容量需求
     - 性能需求
     - 预算
  
  2. 添加OSD:
     - 添加磁盘到节点
     - Rook自动发现
     - 或手动添加
  
  3. Rebalance:
     - Ceph自动数据迁移
     - 监控Rebalance进度
     - 控制Rebalance速度
  
  4. 验证:
     - 检查OSD状态
     - 检查PG分布
     - 性能测试

Rebalance控制:
  # 降低Rebalance影响 (白天)
  ceph tell osd.* injectargs '--osd-max-backfills 1'
  ceph tell osd.* injectargs '--osd-recovery-max-active 1'
  ceph tell osd.* injectargs '--osd-recovery-sleep-hdd 0.5'
  
  # 加速Rebalance (夜间)
  ceph tell osd.* injectargs '--osd-max-backfills 4'
  ceph tell osd.* injectargs '--osd-recovery-max-active 6'
  ceph tell osd.* injectargs '--osd-recovery-sleep-hdd 0'
```

---

### 6.3 成本优化

**存储成本优化策略**:

```yaml
1. 分层存储 (Tiering):
   热数据 (Hot):
     - SSD/NVMe
     - 高IOPS
     - 高成本
     - 示例: 数据库
   
   温数据 (Warm):
     - SATA SSD
     - 中等IOPS
     - 中等成本
     - 示例: 应用文件
   
   冷数据 (Cold):
     - HDD
     - 低IOPS
     - 低成本
     - 示例: 日志、归档
   
   冰数据 (Frozen):
     - 对象存储
     - 极低IOPS
     - 极低成本
     - 示例: 备份

2. 压缩:
   - Ceph BlueStore压缩
   - 节省30-70%空间
   - 轻微性能损失
   
   配置:
     ceph osd pool set replicapool compression_mode aggressive
     ceph osd pool set replicapool compression_algorithm snappy

3. Erasure Coding:
   - 替代3副本
   - 节省50%+空间
   - 适用于冷数据
   
   示例:
     3副本: 实际容量 = 原始 / 3 (33%利用率)
     EC 8+2: 实际容量 = 原始 * 0.8 (80%利用率)
   
   配置:
     ceph osd pool create ec-pool 128 128 erasure
     ceph osd pool set ec-pool allow_ec_overwrites true

4. 生命周期管理:
   - 自动迁移数据 (Hot -> Warm -> Cold)
   - 自动删除过期数据
   - 示例: 日志保留30天

5. 重复数据删除 (Deduplication):
   - 适用于备份
   - 节省空间
   - 性能开销

成本模型:
  SSD成本: ~$100/TB
  HDD成本: ~$20/TB
  对象存储: ~$5/TB (云)
  
  示例 (100TB):
    全SSD: 100TB * $100 = $10,000
    全HDD: 100TB * $20 = $2,000
    分层 (20TB SSD + 80TB HDD):
      20 * $100 + 80 * $20 = $3,600
```

---

## 7. 性能监控

### 7.1 Prometheus监控

**Ceph Exporter**:

```yaml
# Rook自动部署Ceph Exporter
# 查看Prometheus指标:
kubectl -n rook-ceph port-forward svc/rook-ceph-mgr 9283:9283
curl http://localhost:9283/metrics

# 关键指标:
ceph_health_status                        # 集群健康状态
ceph_osd_up                               # OSD启动数
ceph_osd_in                               # OSD加入数
ceph_pool_stored_bytes                    # Pool存储字节数
ceph_pool_objects                         # Pool对象数
ceph_osd_apply_latency_ms                 # OSD应用延迟
ceph_osd_commit_latency_ms                # OSD提交延迟
ceph_pool_rd_bytes                        # Pool读字节数
ceph_pool_wr_bytes                        # Pool写字节数
```

**Prometheus配置**:

```yaml
# prometheus.yaml
scrape_configs:
- job_name: 'ceph'
  static_configs:
  - targets: ['rook-ceph-mgr.rook-ceph:9283']
```

---

### 7.2 Grafana仪表盘

**导入Ceph仪表盘**:

```bash
# Grafana仪表盘ID:
# - 7056: Ceph Cluster
# - 5336: Ceph OSD
# - 5342: Ceph Pools

# 导入步骤:
# 1. Grafana -> Dashboards -> Import
# 2. 输入ID: 7056
# 3. 选择Prometheus数据源
# 4. Import
```

**自定义仪表盘**:

```json
{
  "dashboard": {
    "title": "Ceph Performance",
    "panels": [
      {
        "title": "IOPS",
        "targets": [
          {
            "expr": "rate(ceph_pool_rd[5m]) + rate(ceph_pool_wr[5m])"
          }
        ]
      },
      {
        "title": "Throughput",
        "targets": [
          {
            "expr": "rate(ceph_pool_rd_bytes[5m]) + rate(ceph_pool_wr_bytes[5m])"
          }
        ]
      },
      {
        "title": "Latency (P99)",
        "targets": [
          {
            "expr": "histogram_quantile(0.99, rate(ceph_osd_op_latency_bucket[5m]))"
          }
        ]
      }
    ]
  }
}
```

---

### 7.3 告警规则

**Prometheus告警**:

```yaml
# ceph-alerts.yaml
groups:
- name: ceph
  interval: 30s
  rules:
  
  # 集群健康
  - alert: CephClusterWarning
    expr: ceph_health_status == 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Ceph cluster is in warning state"
      description: "Ceph cluster {{ $labels.instance }} has been in HEALTH_WARN for more than 5 minutes."
  
  - alert: CephClusterError
    expr: ceph_health_status == 2
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Ceph cluster is in error state"
      description: "Ceph cluster {{ $labels.instance }} is in HEALTH_ERR."
  
  # OSD
  - alert: CephOSDDown
    expr: ceph_osd_up == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Ceph OSD is down"
      description: "OSD {{ $labels.ceph_daemon }} on {{ $labels.hostname }} is down."
  
  # 容量
  - alert: CephPoolNearFull
    expr: ceph_pool_percent_used > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Ceph pool is near full"
      description: "Pool {{ $labels.name }} is {{ $value }}% full."
  
  # 性能
  - alert: CephHighLatency
    expr: ceph_osd_apply_latency_ms > 100
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Ceph high latency"
      description: "OSD {{ $labels.ceph_daemon }} latency is {{ $value }}ms."
  
  # IOPS
  - alert: CephLowIOPS
    expr: rate(ceph_pool_rd[5m]) + rate(ceph_pool_wr[5m]) < 100
    for: 15m
    labels:
      severity: info
    annotations:
      summary: "Ceph low IOPS"
      description: "Pool {{ $labels.name }} IOPS is {{ $value }}."
```

---

## 8. 总结

```yaml
核心知识:
  ✅ 性能指标 (IOPS/吞吐量/延迟/容量)
  ✅ 性能测试 (FIO/dd/sysbench/kubestr)
  ✅ Ceph优化 (OSD/网络/客户端)
  ✅ 文件系统优化 (ext4/xfs)
  ✅ 内核优化 (I/O调度器/sysctl)
  ✅ 容量规划 (预测/扩容/成本)
  ✅ 性能监控 (Prometheus/Grafana/告警)

代码示例:
  - FIO测试配置
  - Ceph调优参数
  - 内核参数
  - Prometheus监控
  - Grafana仪表盘
  - 40+命令和配置

实战技能:
  - 性能基准测试
  - Ceph生产调优
  - 容量规划
  - 性能监控告警
```

---

**完成日期**: 2025-10-19  
**版本**: v1.0  
**作者**: 云原生存储专家团队

**Tags**: `#Performance` `#Optimization` `#Ceph` `#FIO` `#Monitoring` `#CloudNativeStorage`
