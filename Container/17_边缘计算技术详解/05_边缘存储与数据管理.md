# 边缘存储与数据管理

## 目录

- [边缘存储与数据管理](#边缘存储与数据管理)
  - [目录](#目录)
  - [存储架构](#存储架构)
    - [边缘存储挑战](#边缘存储挑战)
    - [存储层级](#存储层级)
    - [存储类型](#存储类型)
  - [分布式存储技术](#分布式存储技术)
    - [Ceph存储](#ceph存储)
    - [MinIO对象存储](#minio对象存储)
    - [Longhorn云原生存储](#longhorn云原生存储)
    - [OpenEBS存储](#openebs存储)
  - [边缘缓存策略](#边缘缓存策略)
    - [缓存架构](#缓存架构)
    - [缓存策略](#缓存策略)
    - [缓存一致性](#缓存一致性)
  - [数据生命周期管理](#数据生命周期管理)
    - [数据分级](#数据分级)
    - [数据保留策略](#数据保留策略)
    - [数据归档](#数据归档)
  - [边云数据同步](#边云数据同步)
    - [同步模式](#同步模式)
    - [数据传输优化](#数据传输优化)
    - [冲突解决](#冲突解决)
  - [数据安全与备份](#数据安全与备份)
    - [加密存储](#加密存储)
    - [访问控制](#访问控制)
    - [备份恢复](#备份恢复)
  - [实践案例](#实践案例)
    - [视频监控存储](#视频监控存储)
    - [IoT数据管理](#iot数据管理)
    - [AI模型分发](#ai模型分发)
  - [性能优化](#性能优化)
    - [IOPS优化](#iops优化)
    - [带宽优化](#带宽优化)
    - [容量规划](#容量规划)
  - [参考资料](#参考资料)
    - [技术文档](#技术文档)
    - [最佳实践](#最佳实践)

---

## 存储架构

### 边缘存储挑战

**核心挑战**:

```yaml
资源限制:
  计算: 有限的CPU/内存
  存储: 受限的本地存储容量
  网络: 不稳定的网络连接
  成本: 硬件成本敏感

可靠性要求:
  数据持久性: 防止数据丢失
  高可用性: 服务连续性
  容错能力: 硬件故障恢复
  灾难恢复: 备份与恢复

性能需求:
  低延迟: <10ms本地访问
  高吞吐: 支持视频流等高带宽
  并发访问: 多应用共享
  实时性: IoT数据实时写入

管理复杂度:
  分布式管理: 多节点协调
  自动化运维: 减少人工干预
  监控告警: 健康状态跟踪
  版本管理: 软件/数据版本控制
```

**边缘 vs 云存储对比**:

```yaml
对比维度:
  延迟:
    边缘: <10ms (本地)
    云端: 30-100ms (网络RTT)
  
  带宽:
    边缘: GB/s (本地总线)
    云端: MB/s (受网络限制)
  
  容量:
    边缘: TB级 (成本受限)
    云端: PB级 (弹性扩展)
  
  可靠性:
    边缘: 单点风险较高
    云端: 高冗余高可用
  
  成本:
    边缘: 硬件投资高
    云端: 按需付费灵活
  
  适用场景:
    边缘: 低延迟、实时、带宽敏感
    云端: 大容量、长期存储、备份
```

### 存储层级

**三层存储架构**:

```text
┌─────────────────────────────────────────────────┐
│              云端存储 (Cloud Storage)            │
│  - 长期归档                                      │
│  - 数据备份                                      │
│  - 大数据分析                                    │
│  - 容量: PB+                                     │
│  - 延迟: 50-100ms                                │
└──────────────────┬──────────────────────────────┘
                   │ WAN (广域网)
                   │ 同步/备份
                   ↓
┌─────────────────────────────────────────────────┐
│           区域边缘存储 (Regional Edge)           │
│  - 区域数据汇聚                                  │
│  - 中期数据存储 (7-30天)                        │
│  - 跨站点共享                                    │
│  - 容量: 10-100TB                                │
│  - 延迟: 5-20ms                                  │
└──────────────────┬──────────────────────────────┘
                   │ LAN (局域网)
                   │ 数据汇聚
                   ↓
┌─────────────────────────────────────────────────┐
│           本地边缘存储 (Local Edge)              │
│  - 实时数据存储                                  │
│  - 短期数据 (1-7天)                             │
│  - 本地缓存                                      │
│  - 容量: 1-10TB                                  │
│  - 延迟: <5ms                                    │
└─────────────────────────────────────────────────┘
                   │
                   ↓
         [边缘设备] [IoT传感器] [摄像头]
```

**数据流向**:

```yaml
热数据路径 (Hot Path):
  采集 → 边缘存储 → 实时处理 → 应用消费
  特点: 低延迟、高频访问、临时存储

温数据路径 (Warm Path):
  边缘存储 → 区域存储 → 近期分析
  特点: 中延迟、中频访问、中期存储

冷数据路径 (Cold Path):
  区域存储 → 云端存储 → 长期归档
  特点: 高延迟、低频访问、长期存储
```

### 存储类型

**块存储 (Block Storage)**:

```yaml
特点:
  - 原始块设备
  - 高性能IOPS
  - 支持文件系统
  - 直接挂载到容器/虚拟机

适用场景:
  - 数据库存储 (MySQL/PostgreSQL)
  - 虚拟机磁盘
  - 高性能应用

技术实现:
  - iSCSI
  - Longhorn
  - OpenEBS (cStor)
  - Ceph RBD

性能指标:
  - IOPS: 10K-100K+
  - 延迟: <1ms (SSD)
  - 吞吐: 500MB/s - 6GB/s
```

**文件存储 (File Storage)**:

```yaml
特点:
  - POSIX兼容
  - 多节点共享读写
  - 目录层级结构
  - NFS/CIFS协议

适用场景:
  - 共享配置
  - 日志文件
  - 应用数据
  - 用户文件

技术实现:
  - NFS Server
  - CephFS
  - GlusterFS
  - Samba

性能指标:
  - IOPS: 1K-10K
  - 延迟: 1-5ms
  - 吞吐: 100MB/s - 1GB/s
```

**对象存储 (Object Storage)**:

```yaml
特点:
  - RESTful API (S3兼容)
  - 扁平命名空间
  - 元数据丰富
  - 水平扩展

适用场景:
  - 视频/图像存储
  - 备份归档
  - 大文件存储
  - 静态资源

技术实现:
  - MinIO
  - Ceph RADOS Gateway
  - SeaweedFS
  - AWS S3 (云端)

性能指标:
  - 吞吐: 100MB/s - 10GB/s
  - 延迟: 10-50ms
  - 容量: 无限扩展
```

---

## 分布式存储技术

### Ceph存储

**架构概述**:

```text
┌─────────────────────────────────────────────┐
│              Ceph客户端层                   │
│  ┌─────────┐  ┌─────────┐  ┌────────────┐  │
│  │ RBD     │  │ CephFS  │  │ RADOS GW   │  │
│  │(块存储) │  │(文件)   │  │(对象S3)    │  │
│  └────┬────┘  └────┬────┘  └──────┬─────┘  │
└───────┼────────────┼──────────────┼─────────┘
        │            │              │
        └────────────┴──────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────┐
│            RADOS存储层                      │
│  (Reliable Autonomic Distributed Storage)  │
│                                             │
│  ┌────────┐  ┌────────┐  ┌────────┐        │
│  │  OSD 1 │  │  OSD 2 │  │  OSD 3 │  ...   │
│  │ (磁盘) │  │ (磁盘) │  │ (磁盘) │        │
│  └────────┘  └────────┘  └────────┘        │
└─────────────────────────────────────────────┘
        ↑
        │ CRUSH算法
        │ 数据分布
        ↓
┌─────────────────────────────────────────────┐
│            Monitor集群                      │
│  ┌──────┐  ┌──────┐  ┌──────┐              │
│  │ MON1 │  │ MON2 │  │ MON3 │              │
│  └──────┘  └──────┘  └──────┘              │
│  - 集群状态                                 │
│  - CRUSH Map                                │
│  - Paxos一致性                              │
└─────────────────────────────────────────────┘
```

**边缘部署配置**:

```yaml
# ceph-edge-cluster.yaml
apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: edge-ceph
  namespace: rook-ceph
spec:
  cephVersion:
    image: quay.io/ceph/ceph:v17.2.7  # Quincy
  
  dataDirHostPath: /var/lib/rook
  
  # 边缘资源配置 (精简模式)
  mon:
    count: 3  # 最小HA配置
    allowMultiplePerNode: false
    volumeClaimTemplate:
      spec:
        resources:
          requests:
            storage: 10Gi  # Monitor数据量小
  
  mgr:
    count: 2
    modules:
      - name: dashboard
        enabled: true
      - name: prometheus
        enabled: true
  
  storage:
    useAllNodes: false
    useAllDevices: false
    nodes:
      - name: "edge-node1"
        devices:
          - name: "nvme0n1"  # 使用NVMe SSD
      - name: "edge-node2"
        devices:
          - name: "nvme0n1"
      - name: "edge-node3"
        devices:
          - name: "nvme0n1"
  
  # 性能优化
  resources:
    osd:
      limits:
        cpu: "2"
        memory: "4Gi"
      requests:
        cpu: "1"
        memory: "2Gi"
  
  # 数据冗余 (边缘场景)
  placement:
    osd:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: role
              operator: In
              values:
              - storage
  
  network:
    provider: host  # 使用主机网络提升性能
  
  # 边缘优化配置
  healthCheck:
    daemonHealth:
      mon:
        interval: 30s
      osd:
        interval: 30s
```

**创建存储类**:

```yaml
# 块存储 (RBD)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: edge-ceph-rbd
provisioner: rook-ceph.rbd.csi.ceph.com
parameters:
  clusterID: rook-ceph
  pool: edge-rbd-pool
  imageFormat: "2"
  imageFeatures: layering
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/fstype: ext4
reclaimPolicy: Delete
allowVolumeExpansion: true
mountOptions:
  - discard  # SSD TRIM支持

---
# 文件存储 (CephFS)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: edge-cephfs
provisioner: rook-ceph.cephfs.csi.ceph.com
parameters:
  clusterID: rook-ceph
  fsName: edge-fs
  pool: edge-cephfs-data
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
reclaimPolicy: Delete
allowVolumeExpansion: true
```

**使用示例**:

```yaml
# 应用使用Ceph存储
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: video-storage
  namespace: surveillance
spec:
  storageClassName: edge-ceph-rbd
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi  # 视频监控存储

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: video-recorder
  namespace: surveillance
spec:
  replicas: 1
  selector:
    matchLabels:
      app: video-recorder
  template:
    metadata:
      labels:
        app: video-recorder
    spec:
      containers:
      - name: recorder
        image: video-recorder:latest
        volumeMounts:
        - name: video-data
          mountPath: /data/videos
        env:
        - name: STORAGE_PATH
          value: "/data/videos"
        - name: RETENTION_DAYS
          value: "7"  # 本地保留7天
      volumes:
      - name: video-data
        persistentVolumeClaim:
          claimName: video-storage
```

### MinIO对象存储

**MinIO边缘部署**:

```yaml
# minio-edge.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: minio-system

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: minio
  namespace: minio-system
spec:
  serviceName: minio
  replicas: 4  # 边缘4节点
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: minio/minio:RELEASE.2025-10-10T00-00-00Z
        args:
        - server
        - http://minio-{0...3}.minio.minio-system.svc.cluster.local/data
        - --console-address
        - ":9001"
        env:
        - name: MINIO_ROOT_USER
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: rootUser
        - name: MINIO_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: rootPassword
        # 边缘优化配置
        - name: MINIO_STORAGE_CLASS_STANDARD
          value: "EC:2"  # 纠删码 2+2
        - name: MINIO_CACHE
          value: "on"
        - name: MINIO_CACHE_DRIVES
          value: "/cache"
        - name: MINIO_CACHE_EXCLUDE
          value: "*.tmp"
        - name: MINIO_CACHE_QUOTA
          value: "80"  # 缓存使用80%
        ports:
        - containerPort: 9000
          name: api
        - containerPort: 9001
          name: console
        volumeMounts:
        - name: data
          mountPath: /data
        - name: cache
          mountPath: /cache
        resources:
          requests:
            cpu: 1
            memory: 2Gi
          limits:
            cpu: 2
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /minio/health/live
            port: 9000
          initialDelaySeconds: 120
          periodSeconds: 20
        readinessProbe:
          httpGet:
            path: /minio/health/ready
            port: 9000
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: cache
        emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: local-path  # 使用本地存储
      resources:
        requests:
          storage: 1Ti

---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: minio-system
spec:
  clusterIP: None
  ports:
  - port: 9000
    name: api
  selector:
    app: minio

---
apiVersion: v1
kind: Service
metadata:
  name: minio-api
  namespace: minio-system
spec:
  type: LoadBalancer
  ports:
  - port: 9000
    targetPort: 9000
    name: api
  - port: 9001
    targetPort: 9001
    name: console
  selector:
    app: minio
```

**MinIO客户端使用**:

```python
# minio_edge_client.py
from minio import Minio
from minio.error import S3Error
from datetime import timedelta
import io

class EdgeStorageClient:
    def __init__(self, endpoint, access_key, secret_key):
        self.client = Minio(
            endpoint,
            access_key=access_key,
            secret_key=secret_key,
            secure=False  # 边缘内网可用HTTP
        )
    
    def create_bucket(self, bucket_name):
        """创建存储桶"""
        try:
            if not self.client.bucket_exists(bucket_name):
                self.client.make_bucket(bucket_name)
                print(f"Bucket '{bucket_name}' created")
        except S3Error as e:
            print(f"Error: {e}")
    
    def upload_file(self, bucket_name, object_name, file_path):
        """上传文件"""
        try:
            self.client.fput_object(
                bucket_name, object_name, file_path,
                metadata={
                    "X-Edge-Node": "edge-node-1",
                    "X-Upload-Time": str(time.time())
                }
            )
            print(f"Uploaded: {object_name}")
        except S3Error as e:
            print(f"Error: {e}")
    
    def upload_video_stream(self, bucket_name, object_name, video_data):
        """上传视频流 (适用于监控录像)"""
        try:
            data_stream = io.BytesIO(video_data)
            self.client.put_object(
                bucket_name,
                object_name,
                data_stream,
                length=len(video_data),
                content_type='video/mp4'
            )
            print(f"Video uploaded: {object_name}")
        except S3Error as e:
            print(f"Error: {e}")
    
    def get_presigned_url(self, bucket_name, object_name, expires=3600):
        """生成预签名URL (用于临时访问)"""
        try:
            url = self.client.presigned_get_object(
                bucket_name,
                object_name,
                expires=timedelta(seconds=expires)
            )
            return url
        except S3Error as e:
            print(f"Error: {e}")
            return None
    
    def set_lifecycle_policy(self, bucket_name, days=7):
        """设置生命周期策略 (边缘数据7天自动删除)"""
        from minio.lifecycleconfig import LifecycleConfig, Rule, Expiration
        
        config = LifecycleConfig(
            [
                Rule(
                    rule_id="edge-retention",
                    status="Enabled",
                    expiration=Expiration(days=days)
                )
            ]
        )
        
        try:
            self.client.set_bucket_lifecycle(bucket_name, config)
            print(f"Lifecycle policy set: delete after {days} days")
        except S3Error as e:
            print(f"Error: {e}")

# 使用示例
if __name__ == '__main__':
    client = EdgeStorageClient(
        endpoint="minio-api.minio-system.svc.cluster.local:9000",
        access_key="minioadmin",
        secret_key="minioadmin"
    )
    
    # 创建存储桶
    client.create_bucket("edge-videos")
    
    # 设置7天自动删除
    client.set_lifecycle_policy("edge-videos", days=7)
    
    # 上传视频
    client.upload_file("edge-videos", "camera1/2025-10-19-10-00.mp4", "/data/video.mp4")
    
    # 获取临时访问URL
    url = client.get_presigned_url("edge-videos", "camera1/2025-10-19-10-00.mp4")
    print(f"Access URL: {url}")
```

### Longhorn云原生存储

**Longhorn架构**:

```text
┌─────────────────────────────────────────────────┐
│          Kubernetes应用层                        │
│  ┌──────┐  ┌──────┐  ┌──────┐                  │
│  │ Pod1 │  │ Pod2 │  │ Pod3 │                  │
│  └──┬───┘  └──┬───┘  └──┬───┘                  │
└─────┼─────────┼─────────┼───────────────────────┘
      │         │         │
      └─────────┴─────────┘
              │ PVC
              ↓
┌─────────────────────────────────────────────────┐
│        Longhorn Manager (控制平面)               │
│  - 卷管理                                        │
│  - 快照/备份                                     │
│  - 调度器                                        │
│  - UI Dashboard                                  │
└─────────────────┬───────────────────────────────┘
                  │
      ┌───────────┼───────────┐
      │           │           │
      ↓           ↓           ↓
┌─────────┐  ┌─────────┐  ┌─────────┐
│ Node 1  │  │ Node 2  │  │ Node 3  │
│ ┌─────┐ │  │ ┌─────┐ │  │ ┌─────┐ │
│ │Engine│ │  │ │Engine│ │  │ │Engine│ │
│ └──┬──┘ │  │ └──┬──┘ │  │ └──┬──┘ │
│    │    │  │    │    │  │    │    │
│ ┌──▼──┐ │  │ ┌──▼──┐ │  │ ┌──▼──┐ │
│ │Replica││  │ │Replica││  │ │Replica││
│ │(主)  │ │  │ │(副本)│ │  │ │(副本)│ │
│ └─────┘ │  │ └─────┘ │  │ └─────┘ │
│  /dev/  │  │  /dev/  │  │  /dev/  │
│  sdb    │  │  sdb    │  │  sdb    │
└─────────┘  └─────────┘  └─────────┘
```

**安装与配置**:

```bash
# 1. 安装Longhorn (使用Helm)
helm repo add longhorn https://charts.longhorn.io
helm repo update

# 边缘优化配置
helm install longhorn longhorn/longhorn \
  --namespace longhorn-system \
  --create-namespace \
  --set defaultSettings.defaultReplicaCount=2 \
  --set defaultSettings.guaranteedEngineManagerCPU=5 \
  --set defaultSettings.guaranteedReplicaManagerCPU=5 \
  --set persistence.defaultClass=true \
  --set persistence.defaultClassReplicaCount=2 \
  --set csi.attacherReplicaCount=1 \
  --set csi.provisionerReplicaCount=1 \
  --set csi.resizerReplicaCount=1 \
  --set csi.snapshotterReplicaCount=1

# 2. 访问UI
kubectl -n longhorn-system port-forward svc/longhorn-frontend 8080:80

# 3. 验证安装
kubectl -n longhorn-system get pods
kubectl get storageclass
```

**使用Longhorn存储**:

```yaml
# PVC示例
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: iot-timeseries-data
  namespace: iot-system
spec:
  storageClassName: longhorn
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi

---
# StatefulSet使用
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: timeseries-db
  namespace: iot-system
spec:
  serviceName: timeseries-db
  replicas: 3
  selector:
    matchLabels:
      app: timeseries-db
  template:
    metadata:
      labels:
        app: timeseries-db
    spec:
      containers:
      - name: influxdb
        image: influxdb:2.7
        ports:
        - containerPort: 8086
        volumeMounts:
        - name: data
          mountPath: /var/lib/influxdb2
        env:
        - name: INFLUXDB_DB
          value: "edge_metrics"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2
            memory: 4Gi
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      storageClassName: longhorn
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 100Gi
```

**Longhorn快照与备份**:

```yaml
# 创建定期快照 (CronJob)
apiVersion: batch/v1
kind: CronJob
metadata:
  name: longhorn-snapshot
  namespace: longhorn-system
spec:
  schedule: "0 */6 * * *"  # 每6小时
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: longhorn-service-account
          containers:
          - name: snapshot
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              # 获取所有PV
              for pv in $(kubectl get pv -o jsonpath='{.items[?(@.spec.storageClassName=="longhorn")].metadata.name}'); do
                # 创建快照
                kubectl -n longhorn-system create -f - <<EOF
              apiVersion: longhorn.io/v1beta2
              kind: Snapshot
              metadata:
                name: ${pv}-$(date +%Y%m%d-%H%M%S)
              spec:
                volumeName: ${pv}
              EOF
              done
          restartPolicy: OnFailure
```

### OpenEBS存储

**OpenEBS架构选择**:

```yaml
OpenEBS存储引擎:
  1. Local PV (本地卷):
     类型:
       - Hostpath: 主机目录
       - Device: 原始块设备
       - ZFS: ZFS文件系统
       - LVM: LVM卷
     
     特点:
       - 最高性能 (本地磁盘速度)
       - 无网络开销
       - 无冗余 (适合StatefulSet)
     
     适用场景:
       - 数据库 (MySQL/PostgreSQL)
       - 缓存 (Redis)
       - 消息队列 (Kafka)
  
  2. Replicated PV (Mayastor):
     特点:
       - 高性能 (基于NVMe-oF)
       - 数据冗余
       - 同步复制
     
     适用场景:
       - 需要高可用的应用
       - 关键业务数据
```

**安装OpenEBS**:

```bash
# 安装OpenEBS Operator
kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml

# 验证
kubectl get pods -n openebs

# 查看存储类
kubectl get sc
```

**Local PV配置**:

```yaml
# Local PV Hostpath
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-hostpath
  annotations:
    openebs.io/cas-type: local
    cas.openebs.io/config: |
      - name: StorageType
        value: hostpath
      - name: BasePath
        value: /var/openebs/local
provisioner: openebs.io/local
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete

---
# Local PV Device (原始块设备)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: openebs-device
  annotations:
    openebs.io/cas-type: local
    cas.openebs.io/config: |
      - name: StorageType
        value: device
      - name: FSType
        value: ext4
provisioner: openebs.io/local
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
```

**使用示例 - 高性能数据库**:

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
  namespace: database
spec:
  serviceName: mysql
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: mysql-data
          mountPath: /var/lib/mysql
        resources:
          requests:
            cpu: 2
            memory: 4Gi
          limits:
            cpu: 4
            memory: 8Gi
  volumeClaimTemplates:
  - metadata:
      name: mysql-data
    spec:
      storageClassName: openebs-device  # 使用原始块设备
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
```

---

## 边缘缓存策略

### 缓存架构

**多层缓存设计**:

```text
┌──────────────────────────────────────────┐
│        应用层缓存 (L1)                   │
│  - 内存缓存 (Redis/Memcached)            │
│  - 热点数据                              │
│  - TTL: 分钟级                           │
│  - 容量: GB级                            │
└──────────────┬───────────────────────────┘
               │ Cache Miss
               ↓
┌──────────────────────────────────────────┐
│        边缘内容缓存 (L2)                 │
│  - 本地SSD缓存                           │
│  - 温数据                                │
│  - TTL: 小时/天级                        │
│  - 容量: TB级                            │
└──────────────┬───────────────────────────┘
               │ Cache Miss
               ↓
┌──────────────────────────────────────────┐
│        区域缓存 (L3)                     │
│  - 区域共享缓存                          │
│  - 冷数据                                │
│  - TTL: 周级                             │
│  - 容量: 10TB+                           │
└──────────────┬───────────────────────────┘
               │ Cache Miss
               ↓
┌──────────────────────────────────────────┐
│        云端存储 (Origin)                 │
│  - 原始数据                              │
│  - 永久存储                              │
│  - 容量: PB级                            │
└──────────────────────────────────────────┘
```

### 缓存策略

**LRU (Least Recently Used) 缓存**:

```python
# edge_cache.py
from collections import OrderedDict
import threading
import time

class LRUCache:
    def __init__(self, capacity: int, ttl: int = 3600):
        """
        capacity: 最大缓存条目数
        ttl: 生存时间 (秒)
        """
        self.capacity = capacity
        self.ttl = ttl
        self.cache = OrderedDict()
        self.timestamps = {}
        self.lock = threading.Lock()
    
    def get(self, key: str):
        """获取缓存"""
        with self.lock:
            if key not in self.cache:
                return None
            
            # 检查是否过期
            if time.time() - self.timestamps[key] > self.ttl:
                del self.cache[key]
                del self.timestamps[key]
                return None
            
            # 移到最后 (最近使用)
            self.cache.move_to_end(key)
            return self.cache[key]
    
    def put(self, key: str, value):
        """存入缓存"""
        with self.lock:
            if key in self.cache:
                # 更新现有key
                self.cache.move_to_end(key)
            else:
                # 新key
                if len(self.cache) >= self.capacity:
                    # 删除最久未使用的
                    oldest = next(iter(self.cache))
                    del self.cache[oldest]
                    del self.timestamps[oldest]
            
            self.cache[key] = value
            self.timestamps[key] = time.time()
    
    def invalidate(self, key: str):
        """使缓存失效"""
        with self.lock:
            if key in self.cache:
                del self.cache[key]
                del self.timestamps[key]
    
    def clear(self):
        """清空缓存"""
        with self.lock:
            self.cache.clear()
            self.timestamps.clear()
    
    def size(self):
        """当前缓存大小"""
        return len(self.cache)

# 使用示例
cache = LRUCache(capacity=1000, ttl=3600)  # 1000条，1小时TTL

# 存储
cache.put("video:camera1:2025-10-19-10-00", video_data)

# 获取
data = cache.get("video:camera1:2025-10-19-10-00")
if data is None:
    # Cache miss - 从存储加载
    data = load_from_storage("video:camera1:2025-10-19-10-00")
    cache.put("video:camera1:2025-10-19-10-00", data)
```

**智能预取策略**:

```python
# prefetch_strategy.py
import asyncio
from typing import List
import numpy as np

class IntelligenPrefetcher:
    def __init__(self, cache, storage):
        self.cache = cache
        self.storage = storage
        self.access_history = []  # 访问历史
        self.prefetch_queue = asyncio.Queue()
    
    def record_access(self, key: str):
        """记录访问"""
        self.access_history.append({
            'key': key,
            'timestamp': time.time()
        })
        
        # 保留最近1000条
        if len(self.access_history) > 1000:
            self.access_history = self.access_history[-1000:]
        
        # 触发预测
        self.predict_next_access()
    
    def predict_next_access(self):
        """预测下一次访问 (简单规则)"""
        if len(self.access_history) < 10:
            return
        
        # 模式检测
        recent = [h['key'] for h in self.access_history[-10:]]
        
        # 示例规则: 如果访问camera1的视频，预取camera2
        if any('camera1' in key for key in recent):
            # 预取相关内容
            next_key = recent[-1].replace('camera1', 'camera2')
            asyncio.create_task(self.prefetch(next_key))
        
        # 时间序列预测
        # 如果访问10:00的视频，预取10:05的
        import re
        time_pattern = r'(\d{2})-(\d{2})'
        matches = re.search(time_pattern, recent[-1])
        if matches:
            hour, minute = matches.groups()
            next_minute = (int(minute) + 5) % 60
            next_key = re.sub(time_pattern, f'{hour}-{next_minute:02d}', recent[-1])
            asyncio.create_task(self.prefetch(next_key))
    
    async def prefetch(self, key: str):
        """异步预取"""
        # 检查是否已在缓存
        if self.cache.get(key) is not None:
            return
        
        # 从存储加载
        try:
            data = await self.storage.load_async(key)
            self.cache.put(key, data)
            print(f"Prefetched: {key}")
        except Exception as e:
            print(f"Prefetch failed for {key}: {e}")
```

**CDN式边缘缓存 (Nginx)**:

```nginx
# nginx-edge-cache.conf
http {
    # 缓存路径配置
    proxy_cache_path /data/nginx/cache 
                     levels=1:2 
                     keys_zone=edge_cache:100m 
                     max_size=500g 
                     inactive=7d 
                     use_temp_path=off;
    
    # 缓存键配置
    proxy_cache_key "$scheme$request_method$host$request_uri";
    
    # 上游服务器 (区域缓存或云端)
    upstream backend {
        server regional-cache.example.com:80;
        server cloud-origin.example.com:80 backup;
    }
    
    server {
        listen 80;
        server_name edge-cache.local;
        
        location /videos/ {
            proxy_cache edge_cache;
            proxy_cache_valid 200 7d;      # 成功响应缓存7天
            proxy_cache_valid 404 1m;      # 404缓存1分钟
            proxy_cache_use_stale error timeout updating;
            
            # 缓存头
            add_header X-Cache-Status $upstream_cache_status;
            add_header X-Edge-Node $hostname;
            
            # 范围请求支持 (视频seek)
            proxy_cache_convert_head off;
            proxy_cache_methods GET HEAD;
            proxy_set_header Range $http_range;
            
            # 大文件优化
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_max_temp_file_size 1024m;
            
            proxy_pass http://backend;
        }
        
        # 缓存管理API
        location /cache-admin/ {
            allow 10.0.0.0/8;  # 仅内网访问
            deny all;
            
            proxy_cache_purge edge_cache "$scheme$request_method$host$request_uri";
        }
    }
}
```

### 缓存一致性

**多节点缓存同步**:

```yaml
# 使用Redis作为缓存一致性协调器
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-cache
  namespace: edge-cache
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-cache
  template:
    metadata:
      labels:
        app: redis-cache
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        command:
        - redis-server
        - --maxmemory
        - "2gb"
        - --maxmemory-policy
        - "allkeys-lru"  # LRU淘汰
        - --save
        - ""  # 禁用持久化 (纯缓存)
        - --appendonly
        - "no"
        resources:
          requests:
            cpu: 500m
            memory: 2Gi
          limits:
            cpu: 1
            memory: 2Gi
```

**缓存失效通知**:

```python
# cache_invalidation.py
import redis
import json

class CacheInvalidationService:
    def __init__(self, redis_host='redis-cache.edge-cache.svc.cluster.local'):
        self.redis_client = redis.Redis(host=redis_host, port=6379, db=0)
        self.pubsub = self.redis_client.pubsub()
        self.local_cache = {}
    
    def subscribe_invalidation(self):
        """订阅缓存失效通知"""
        self.pubsub.subscribe('cache:invalidate')
        
        for message in self.pubsub.listen():
            if message['type'] == 'message':
                data = json.loads(message['data'])
                key = data['key']
                
                # 使本地缓存失效
                if key in self.local_cache:
                    del self.local_cache[key]
                    print(f"Invalidated local cache: {key}")
    
    def invalidate_cache(self, key: str):
        """发布缓存失效通知 (所有节点)"""
        message = json.dumps({'key': key, 'timestamp': time.time()})
        self.redis_client.publish('cache:invalidate', message)
        print(f"Published invalidation for: {key}")
    
    def get_with_cache(self, key: str, load_func):
        """带缓存的获取"""
        # 1. 检查本地缓存
        if key in self.local_cache:
            return self.local_cache[key]
        
        # 2. 检查Redis
        cached = self.redis_client.get(key)
        if cached:
            data = json.loads(cached)
            self.local_cache[key] = data
            return data
        
        # 3. 加载数据
        data = load_func(key)
        
        # 4. 写入Redis和本地缓存
        self.redis_client.setex(key, 3600, json.dumps(data))  # 1小时
        self.local_cache[key] = data
        
        return data
```

---

## 数据生命周期管理

### 数据分级

**数据温度分类**:

```yaml
热数据 (Hot Data):
  特征:
    - 高频访问 (每小时/分钟)
    - 低延迟要求 (<5ms)
    - 实时性强
  
  存储策略:
    - 位置: 边缘本地SSD
    - 冗余: 最小冗余 (单副本/2副本)
    - 容量: GB级
    - 保留: 1-3天
  
  典型场景:
    - 实时视频流
    - IoT传感器数据
    - 缓存数据
    - 会话数据

温数据 (Warm Data):
  特征:
    - 中频访问 (每天/周)
    - 中等延迟 (10-50ms)
    - 近期数据
  
  存储策略:
    - 位置: 区域边缘
    - 冗余: 标准冗余 (3副本/EC)
    - 容量: TB级
    - 保留: 7-30天
  
  典型场景:
    - 历史查询
    - 报表分析
    - 日志数据
    - 备份数据

冷数据 (Cold Data):
  特征:
    - 低频访问 (每月/年)
    - 高延迟可接受 (秒级)
    - 归档数据
  
  存储策略:
    - 位置: 云端存储
    - 冗余: 高冗余 (多地域)
    - 容量: PB级
    - 保留: 长期/永久
  
  典型场景:
    - 合规归档
    - 历史数据
    - 审计日志
    - 灾备数据
```

**自动分层实现**:

```python
# data_tiering.py
import time
from enum import Enum
from datetime import datetime, timedelta

class DataTier(Enum):
    HOT = "hot"      # 边缘SSD
    WARM = "warm"    # 区域存储
    COLD = "cold"    # 云端归档

class DataLifecycleManager:
    def __init__(self, hot_storage, warm_storage, cold_storage):
        self.hot_storage = hot_storage
        self.warm_storage = warm_storage
        self.cold_storage = cold_storage
        
        # 分层策略
        self.hot_retention_days = 3
        self.warm_retention_days = 30
    
    def classify_data(self, metadata):
        """根据元数据分类数据"""
        age_days = (datetime.now() - metadata['created_at']).days
        access_count = metadata.get('access_count', 0)
        last_access = metadata.get('last_access_time')
        
        # 规则1: 最近3天 → Hot
        if age_days < self.hot_retention_days:
            return DataTier.HOT
        
        # 规则2: 最近访问过 → Warm
        if last_access and (datetime.now() - last_access).days < 7:
            return DataTier.WARM
        
        # 规则3: 高频访问 → Warm
        if access_count > 100 and age_days < self.warm_retention_days:
            return DataTier.WARM
        
        # 规则4: 其他 → Cold
        return DataTier.COLD
    
    async def auto_tier_data(self, object_key, metadata):
        """自动分层"""
        current_tier = metadata.get('tier', DataTier.HOT)
        target_tier = self.classify_data(metadata)
        
        if current_tier == target_tier:
            return  # 无需迁移
        
        print(f"Tiering: {object_key} from {current_tier.value} to {target_tier.value}")
        
        # 迁移数据
        if current_tier == DataTier.HOT and target_tier == DataTier.WARM:
            await self._move_hot_to_warm(object_key)
        elif current_tier == DataTier.WARM and target_tier == DataTier.COLD:
            await self._move_warm_to_cold(object_key)
        elif current_tier == DataTier.HOT and target_tier == DataTier.COLD:
            # 直接归档
            await self._move_hot_to_cold(object_key)
    
    async def _move_hot_to_warm(self, object_key):
        """热 → 温"""
        # 1. 从边缘读取
        data = await self.hot_storage.read(object_key)
        
        # 2. 写入区域存储
        await self.warm_storage.write(object_key, data)
        
        # 3. 删除边缘副本
        await self.hot_storage.delete(object_key)
        
        print(f"Moved to warm: {object_key}")
    
    async def _move_warm_to_cold(self, object_key):
        """温 → 冷"""
        # 1. 从区域读取
        data = await self.warm_storage.read(object_key)
        
        # 2. 写入云端
        await self.cold_storage.write(object_key, data)
        
        # 3. 删除区域副本
        await self.warm_storage.delete(object_key)
        
        print(f"Archived to cold: {object_key}")
    
    async def _move_hot_to_cold(self, object_key):
        """热 → 冷 (跳过温)"""
        data = await self.hot_storage.read(object_key)
        await self.cold_storage.write(object_key, data)
        await self.hot_storage.delete(object_key)
        print(f"Direct archive: {object_key}")
    
    async def run_lifecycle_scan(self):
        """扫描并执行生命周期策略"""
        # 扫描热数据
        hot_objects = await self.hot_storage.list_all()
        for obj in hot_objects:
            metadata = await self.hot_storage.get_metadata(obj)
            await self.auto_tier_data(obj, metadata)
        
        # 扫描温数据
        warm_objects = await self.warm_storage.list_all()
        for obj in warm_objects:
            metadata = await self.warm_storage.get_metadata(obj)
            await self.auto_tier_data(obj, metadata)

# 定期执行 (CronJob)
```

### 数据保留策略

**Kubernetes CronJob实现**:

```yaml
# data-retention-job.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: data-retention-cleaner
  namespace: storage-system
spec:
  schedule: "0 2 * * *"  # 每天凌晨2点
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: storage-admin
          containers:
          - name: cleaner
            image: python:3.11-slim
            command:
            - python
            - /scripts/retention_cleaner.py
            env:
            - name: HOT_RETENTION_DAYS
              value: "3"
            - name: WARM_RETENTION_DAYS
              value: "30"
            - name: MINIO_ENDPOINT
              value: "minio-api.minio-system.svc.cluster.local:9000"
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: accessKey
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: secretKey
            volumeMounts:
            - name: scripts
              mountPath: /scripts
          volumes:
          - name: scripts
            configMap:
              name: retention-scripts
          restartPolicy: OnFailure
```

**清理脚本**:

```python
# retention_cleaner.py
import os
from datetime import datetime, timedelta
from minio import Minio
from minio.error import S3Error

class RetentionCleaner:
    def __init__(self):
        self.client = Minio(
            os.getenv('MINIO_ENDPOINT'),
            access_key=os.getenv('MINIO_ACCESS_KEY'),
            secret_key=os.getenv('MINIO_SECRET_KEY'),
            secure=False
        )
        self.hot_retention_days = int(os.getenv('HOT_RETENTION_DAYS', 3))
        self.warm_retention_days = int(os.getenv('WARM_RETENTION_DAYS', 30))
    
    def clean_bucket(self, bucket_name, retention_days):
        """清理过期对象"""
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        deleted_count = 0
        deleted_size = 0
        
        try:
            objects = self.client.list_objects(bucket_name, recursive=True)
            
            for obj in objects:
                if obj.last_modified < cutoff_date:
                    # 删除过期对象
                    self.client.remove_object(bucket_name, obj.object_name)
                    deleted_count += 1
                    deleted_size += obj.size
                    print(f"Deleted: {obj.object_name} (age: {(datetime.now() - obj.last_modified).days} days)")
            
            print(f"\nBucket: {bucket_name}")
            print(f"Deleted: {deleted_count} objects")
            print(f"Freed: {deleted_size / (1024**3):.2f} GB")
        
        except S3Error as e:
            print(f"Error cleaning {bucket_name}: {e}")
    
    def run(self):
        """执行清理"""
        # 热数据桶 (3天保留)
        hot_buckets = ['edge-videos', 'iot-realtime', 'cache-data']
        for bucket in hot_buckets:
            self.clean_bucket(bucket, self.hot_retention_days)
        
        # 温数据桶 (30天保留)
        warm_buckets = ['logs', 'analytics', 'backups']
        for bucket in warm_buckets:
            self.clean_bucket(bucket, self.warm_retention_days)

if __name__ == '__main__':
    cleaner = RetentionCleaner()
    cleaner.run()
```

### 数据归档

**归档到云端 (Rclone)**:

```yaml
# rclone-archive-job.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cloud-archive
  namespace: storage-system
spec:
  schedule: "0 3 * * 0"  # 每周日凌晨3点
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: rclone
            image: rclone/rclone:latest
            command:
            - sh
            - -c
            - |
              # 同步到云端
              rclone sync /data/archive \
                s3:my-bucket/edge-archive-$(hostname) \
                --transfers 4 \
                --checkers 8 \
                --s3-chunk-size 32M \
                --log-file /logs/rclone.log \
                --log-level INFO
              
              # 清理本地归档
              find /data/archive -mtime +7 -delete
            env:
            - name: RCLONE_CONFIG_S3_TYPE
              value: "s3"
            - name: RCLONE_CONFIG_S3_PROVIDER
              value: "AWS"
            - name: RCLONE_CONFIG_S3_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access_key
            - name: RCLONE_CONFIG_S3_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret_key
            - name: RCLONE_CONFIG_S3_REGION
              value: "us-east-1"
            volumeMounts:
            - name: archive-data
              mountPath: /data/archive
            - name: logs
              mountPath: /logs
          volumes:
          - name: archive-data
            persistentVolumeClaim:
              claimName: archive-pvc
          - name: logs
            emptyDir: {}
          restartPolicy: OnFailure
```

---

## 边云数据同步

### 同步模式

**三种同步策略**:

```yaml
1. 实时同步 (Real-time Sync):
   触发: 数据写入即同步
   延迟: 秒级
   带宽: 高
   适用:
     - 关键业务数据
     - 实时备份
     - 多活架构
   
   实现: 
     - 双写 (应用层)
     - CDC (Change Data Capture)
     - 事件驱动

2. 定期同步 (Periodic Sync):
   触发: 定时任务 (hourly/daily)
   延迟: 小时/天级
   带宽: 中
   适用:
     - 日志数据
     - 分析数据
     - 归档数据
   
   实现:
     - CronJob
     - Rsync
     - Rclone

3. 增量同步 (Incremental Sync):
   触发: 检测到变更
   延迟: 分钟级
   带宽: 低 (仅传输差异)
   适用:
     - 大文件
     - 模型文件
     - 数据库备份
   
   实现:
     - Rsync delta
     - Git-like diff
     - Block-level sync
```

**实时同步实现 (Kafka)**:

```yaml
# kafka-sync-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-sync-producer
  namespace: sync-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: sync-producer
  template:
    metadata:
      labels:
        app: sync-producer
    spec:
      containers:
      - name: producer
        image: edge-sync-producer:latest
        env:
        - name: KAFKA_BROKERS
          value: "kafka.sync-system.svc.cluster.local:9092"
        - name: SYNC_TOPIC
          value: "edge-to-cloud-sync"
        - name: MINIO_ENDPOINT
          value: "minio-api.minio-system.svc.cluster.local:9000"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1
            memory: 2Gi
```

**同步Producer**:

```python
# sync_producer.py
from kafka import KafkaProducer
from minio import Minio
import json
import hashlib

class DataSyncProducer:
    def __init__(self, kafka_brokers, minio_endpoint):
        self.producer = KafkaProducer(
            bootstrap_servers=kafka_brokers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            compression_type='gzip',
            max_request_size=10485760  # 10MB
        )
        
        self.minio = Minio(minio_endpoint, ...)
        self.topic = 'edge-to-cloud-sync'
    
    def watch_and_sync(self, bucket_name):
        """监听MinIO事件并同步"""
        # MinIO事件监听
        events = self.minio.listen_bucket_notification(
            bucket_name,
            events=['s3:ObjectCreated:*', 's3:ObjectRemoved:*']
        )
        
        for event in events:
            event_data = json.loads(event['Records'][0])
            object_key = event_data['s3']['object']['key']
            event_type = event_data['eventName']
            
            if 's3:ObjectCreated' in event_type:
                # 对象创建/更新
                self.sync_object(bucket_name, object_key)
            elif 's3:ObjectRemoved' in event_type:
                # 对象删除
                self.sync_deletion(bucket_name, object_key)
    
    def sync_object(self, bucket, key):
        """同步对象到云端"""
        # 1. 获取对象元数据
        stat = self.minio.stat_object(bucket, key)
        
        # 2. 计算校验和
        data = self.minio.get_object(bucket, key)
        checksum = hashlib.sha256(data.read()).hexdigest()
        
        # 3. 发送同步消息
        sync_message = {
            'action': 'PUT',
            'bucket': bucket,
            'key': key,
            'size': stat.size,
            'etag': stat.etag,
            'checksum': checksum,
            'metadata': stat.metadata,
            'timestamp': stat.last_modified.isoformat(),
            'edge_node': os.getenv('HOSTNAME')
        }
        
        self.producer.send(self.topic, value=sync_message)
        print(f"Synced: {key}")
    
    def sync_deletion(self, bucket, key):
        """同步删除操作"""
        sync_message = {
            'action': 'DELETE',
            'bucket': bucket,
            'key': key,
            'timestamp': datetime.now().isoformat(),
            'edge_node': os.getenv('HOSTNAME')
        }
        
        self.producer.send(self.topic, value=sync_message)
        print(f"Synced deletion: {key}")
```

**云端Consumer**:

```python
# sync_consumer.py (云端)
from kafka import KafkaConsumer
import boto3
import requests

class CloudSyncConsumer:
    def __init__(self, kafka_brokers, edge_endpoint):
        self.consumer = KafkaConsumer(
            'edge-to-cloud-sync',
            bootstrap_servers=kafka_brokers,
            group_id='cloud-sync-consumer',
            value_deserializer=lambda m: json.loads(m.decode('utf-8')),
            enable_auto_commit=True
        )
        
        self.s3 = boto3.client('s3')
        self.edge_endpoint = edge_endpoint
    
    def consume_and_apply(self):
        """消费并应用同步"""
        for message in self.consumer:
            sync_data = message.value
            action = sync_data['action']
            
            if action == 'PUT':
                self.apply_put(sync_data)
            elif action == 'DELETE':
                self.apply_delete(sync_data)
    
    def apply_put(self, data):
        """应用PUT操作"""
        bucket = data['bucket']
        key = data['key']
        
        # 1. 从边缘下载
        edge_url = f"http://{self.edge_endpoint}/{bucket}/{key}"
        response = requests.get(edge_url, stream=True)
        
        # 2. 上传到云端S3
        self.s3.upload_fileobj(
            response.raw,
            bucket,
            key,
            ExtraArgs={'Metadata': data['metadata']}
        )
        
        print(f"Applied PUT: {key}")
    
    def apply_delete(self, data):
        """应用DELETE操作"""
        self.s3.delete_object(Bucket=data['bucket'], Key=data['key'])
        print(f"Applied DELETE: {data['key']}")
```

### 数据传输优化

**断点续传**:

```python
# resumable_upload.py
import requests
import os

class ResumableUpload:
    def __init__(self, file_path, upload_url, chunk_size=5*1024*1024):
        self.file_path = file_path
        self.upload_url = upload_url
        self.chunk_size = chunk_size  # 5MB chunks
        self.file_size = os.path.getsize(file_path)
    
    def upload(self):
        """断点续传上传"""
        # 1. 检查已上传进度
        uploaded_size = self._get_uploaded_size()
        
        # 2. 从断点继续上传
        with open(self.file_path, 'rb') as f:
            f.seek(uploaded_size)
            
            while uploaded_size < self.file_size:
                chunk = f.read(self.chunk_size)
                if not chunk:
                    break
                
                # 上传chunk
                success = self._upload_chunk(chunk, uploaded_size)
                
                if success:
                    uploaded_size += len(chunk)
                    progress = (uploaded_size / self.file_size) * 100
                    print(f"Progress: {progress:.2f}%")
                else:
                    # 上传失败，重试
                    print("Chunk upload failed, retrying...")
                    f.seek(uploaded_size)
    
    def _get_uploaded_size(self):
        """查询已上传大小"""
        response = requests.head(self.upload_url)
        if response.status_code == 200:
            return int(response.headers.get('X-Uploaded-Size', 0))
        return 0
    
    def _upload_chunk(self, chunk, offset):
        """上传单个chunk"""
        headers = {
            'Content-Range': f'bytes {offset}-{offset+len(chunk)-1}/{self.file_size}'
        }
        
        try:
            response = requests.put(
                self.upload_url,
                data=chunk,
                headers=headers,
                timeout=60
            )
            return response.status_code == 200
        except Exception as e:
            print(f"Upload error: {e}")
            return False

# 使用
uploader = ResumableUpload('/data/large-video.mp4', 'https://cloud.example.com/upload/video123')
uploader.upload()
```

**压缩传输**:

```python
# compressed_sync.py
import gzip
import lz4.frame
from io import BytesIO

class CompressedSync:
    def compress_and_upload(self, data, algorithm='lz4'):
        """压缩后上传"""
        if algorithm == 'gzip':
            compressed = gzip.compress(data, compresslevel=6)
        elif algorithm == 'lz4':
            compressed = lz4.frame.compress(data, compression_level=4)
        else:
            compressed = data
        
        # 统计
        original_size = len(data)
        compressed_size = len(compressed)
        ratio = (1 - compressed_size / original_size) * 100
        
        print(f"Compression: {original_size} → {compressed_size} bytes ({ratio:.1f}% saved)")
        
        # 上传压缩数据
        self.upload(compressed, metadata={'compression': algorithm})
        
        return compressed_size
```

### 冲突解决

**版本控制策略**:

```python
# conflict_resolution.py
from enum import Enum

class ConflictResolutionStrategy(Enum):
    LAST_WRITE_WINS = "last_write_wins"      # 最后写入获胜
    EDGE_PRIORITY = "edge_priority"          # 边缘优先
    CLOUD_PRIORITY = "cloud_priority"        # 云端优先
    MANUAL_RESOLVE = "manual_resolve"        # 手动解决
    MERGE = "merge"                          # 合并 (仅文本)

class ConflictResolver:
    def __init__(self, strategy=ConflictResolutionStrategy.LAST_WRITE_WINS):
        self.strategy = strategy
    
    def resolve(self, edge_version, cloud_version):
        """解决冲突"""
        if self.strategy == ConflictResolutionStrategy.LAST_WRITE_WINS:
            return self._last_write_wins(edge_version, cloud_version)
        elif self.strategy == ConflictResolutionStrategy.EDGE_PRIORITY:
            return edge_version
        elif self.strategy == ConflictResolutionStrategy.CLOUD_PRIORITY:
            return cloud_version
        elif self.strategy == ConflictResolutionStrategy.MANUAL_RESOLVE:
            return self._manual_resolve(edge_version, cloud_version)
        elif self.strategy == ConflictResolutionStrategy.MERGE:
            return self._merge(edge_version, cloud_version)
    
    def _last_write_wins(self, edge_ver, cloud_ver):
        """最后写入获胜"""
        if edge_ver['timestamp'] > cloud_ver['timestamp']:
            return edge_ver
        else:
            return cloud_ver
    
    def _manual_resolve(self, edge_ver, cloud_ver):
        """手动解决 - 创建冲突记录"""
        conflict_record = {
            'status': 'CONFLICT',
            'edge_version': edge_ver,
            'cloud_version': cloud_ver,
            'created_at': datetime.now().isoformat()
        }
        
        # 保存冲突记录供管理员处理
        self._save_conflict_record(conflict_record)
        
        # 暂时保留两个版本
        return {
            'resolved': False,
            'edge': edge_ver,
            'cloud': cloud_ver
        }
    
    def _merge(self, edge_ver, cloud_ver):
        """合并 (简单实现 - 仅适用于文本)"""
        # 使用diff-merge算法
        # 这里简化处理
        merged_content = edge_ver['content'] + '\n' + cloud_ver['content']
        
        return {
            'content': merged_content,
            'timestamp': max(edge_ver['timestamp'], cloud_ver['timestamp']),
            'merged': True
        }
```

---

## 数据安全与备份

### 加密存储

**静态加密 (Encryption at Rest)**:

```yaml
# 使用LUKS加密本地磁盘
apiVersion: v1
kind: Pod
metadata:
  name: encrypted-storage-setup
  namespace: storage-system
spec:
  hostNetwork: true
  hostPID: true
  containers:
  - name: setup
    image: ubuntu:22.04
    securityContext:
      privileged: true
    command:
    - sh
    - -c
    - |
      # 安装cryptsetup
      apt-get update && apt-get install -y cryptsetup
      
      # 创建加密卷
      echo "mypassphrase" | cryptsetup luksFormat /dev/sdb --batch-mode
      echo "mypassphrase" | cryptsetup luksOpen /dev/sdb encrypted_disk
      
      # 格式化
      mkfs.ext4 /dev/mapper/encrypted_disk
      
      # 挂载
      mkdir -p /mnt/encrypted
      mount /dev/mapper/encrypted_disk /mnt/encrypted
      
      echo "Encrypted storage ready at /mnt/encrypted"
    volumeMounts:
    - name: dev
      mountPath: /dev
  volumes:
  - name: dev
    hostPath:
      path: /dev
```

**MinIO服务端加密**:

```yaml
# minio-with-encryption.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: minio-encrypted
  namespace: minio-system
spec:
  serviceName: minio-encrypted
  replicas: 4
  selector:
    matchLabels:
      app: minio-encrypted
  template:
    metadata:
      labels:
        app: minio-encrypted
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
        - server
        - http://minio-encrypted-{0...3}.minio-encrypted.minio-system.svc.cluster.local/data
        env:
        # 服务端加密配置
        - name: MINIO_KMS_KES_ENDPOINT
          value: "https://kes.minio-system.svc.cluster.local:7373"
        - name: MINIO_KMS_KES_KEY_NAME
          value: "minio-master-key"
        - name: MINIO_KMS_KES_CERT_FILE
          value: "/certs/kes-client.cert"
        - name: MINIO_KMS_KES_KEY_FILE
          value: "/certs/kes-client.key"
        - name: MINIO_KMS_KES_CA_PATH
          value: "/certs/kes-ca.cert"
        volumeMounts:
        - name: data
          mountPath: /data
        - name: certs
          mountPath: /certs
          readOnly: true
      volumes:
      - name: certs
        secret:
          secretName: minio-kes-certs
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Ti
```

**客户端加密**:

```python
# client_side_encryption.py
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2
import base64

class ClientSideEncryption:
    def __init__(self, password):
        # 从密码派生密钥
        kdf = PBKDF2(
            algorithm=hashes.SHA256(),
            length=32,
            salt=b'edge-storage-salt',  # 实际应用应使用随机salt
            iterations=100000
        )
        key = base64.urlsafe_b64encode(kdf.derive(password.encode()))
        self.cipher = Fernet(key)
    
    def encrypt_file(self, file_path, output_path):
        """加密文件"""
        with open(file_path, 'rb') as f:
            plaintext = f.read()
        
        ciphertext = self.cipher.encrypt(plaintext)
        
        with open(output_path, 'wb') as f:
            f.write(ciphertext)
        
        print(f"Encrypted: {file_path} → {output_path}")
    
    def decrypt_file(self, encrypted_path, output_path):
        """解密文件"""
        with open(encrypted_path, 'rb') as f:
            ciphertext = f.read()
        
        plaintext = self.cipher.decrypt(ciphertext)
        
        with open(output_path, 'wb') as f:
            f.write(plaintext)
        
        print(f"Decrypted: {encrypted_path} → {output_path}")
    
    def encrypt_object_before_upload(self, minio_client, bucket, key, file_path):
        """上传前加密"""
        import tempfile
        
        # 临时加密文件
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            self.encrypt_file(file_path, tmp.name)
            
            # 上传加密文件
            minio_client.fput_object(
                bucket, key, tmp.name,
                metadata={'encrypted': 'true', 'algorithm': 'Fernet'}
            )
        
        os.unlink(tmp.name)
        print(f"Uploaded encrypted: {key}")

# 使用
encryptor = ClientSideEncryption(password="my-secret-password")
encryptor.encrypt_object_before_upload(minio_client, "secure-bucket", "confidential.dat", "/data/file.dat")
```

### 访问控制

**MinIO IAM策略**:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::edge-videos/*",
        "arn:aws:s3:::edge-videos"
      ],
      "Condition": {
        "IpAddress": {
          "aws:SourceIp": "10.0.0.0/8"
        },
        "StringLike": {
          "s3:prefix": ["camera1/*", "camera2/*"]
        }
      }
    },
    {
      "Effect": "Deny",
      "Action": "s3:*",
      "Resource": "arn:aws:s3:::edge-videos/restricted/*"
    }
  ]
}
```

**Kubernetes RBAC**:

```yaml
# storage-rbac.yaml
---
# Role: 只读访问
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: storage-reader
  namespace: storage-system
rules:
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]

---
# Role: 管理员
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: storage-admin
  namespace: storage-system
rules:
- apiGroups: [""]
  resources: ["persistentvolumeclaims", "persistentvolumes"]
  verbs: ["*"]
- apiGroups: ["storage.k8s.io"]
  resources: ["storageclasses"]
  verbs: ["*"]
- apiGroups: ["snapshot.storage.k8s.io"]
  resources: ["volumesnapshots"]
  verbs: ["*"]

---
# RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-storage-reader
  namespace: storage-system
subjects:
- kind: ServiceAccount
  name: my-app
  namespace: my-app-namespace
roleRef:
  kind: Role
  name: storage-reader
  apiGroup: rbac.authorization.k8s.io
```

### 备份恢复

**Velero备份**:

```bash
# 安装Velero
velero install \
  --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.8.0 \
  --bucket edge-backups \
  --secret-file ./credentials-velero \
  --backup-location-config region=us-east-1 \
  --snapshot-location-config region=us-east-1 \
  --use-volume-snapshots=true

# 备份整个命名空间
velero backup create edge-storage-backup \
  --include-namespaces storage-system,minio-system \
  --storage-location default \
  --volume-snapshot-locations default

# 定时备份
velero schedule create daily-backup \
  --schedule="0 2 * * *" \
  --include-namespaces storage-system,minio-system

# 恢复
velero restore create --from-backup edge-storage-backup
```

**自定义备份脚本**:

```yaml
# backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: storage-backup
  namespace: storage-system
spec:
  schedule: "0 1 * * *"  # 每天凌晨1点
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: backup-sa
          containers:
          - name: backup
            image: restic/restic:latest
            command:
            - sh
            - -c
            - |
              # 初始化Restic仓库 (首次)
              restic -r s3:s3.amazonaws.com/edge-backups init || true
              
              # 备份PVC数据
              restic -r s3:s3.amazonaws.com/edge-backups backup /data \
                --tag edge-node-1 \
                --tag $(date +%Y-%m-%d)
              
              # 清理旧备份 (保留30天)
              restic -r s3:s3.amazonaws.com/edge-backups forget \
                --keep-daily 30 \
                --prune
            env:
            - name: RESTIC_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: restic-secret
                  key: password
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access_key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret_key
            volumeMounts:
            - name: data
              mountPath: /data
              readOnly: true
          volumes:
          - name: data
            persistentVolumeClaim:
              claimName: important-data-pvc
          restartPolicy: OnFailure
```

---

## 实践案例

### 视频监控存储

**架构设计**:

```yaml
视频监控存储方案:
  采集端:
    - 摄像头数量: 100+
    - 分辨率: 1080p/4K
    - 帧率: 25fps
    - 码率: 2-8 Mbps/camera
    - 总带宽: 200-800 Mbps
  
  边缘存储:
    - 类型: MinIO对象存储
    - 容量: 50TB (本地)
    - 保留: 7天
    - 冗余: EC 2+2
    - 性能: 1GB/s写入
  
  云端归档:
    - 类型: AWS S3 Glacier
    - 容量: 无限
    - 保留: 90天/永久
    - 成本: $0.004/GB/月
```

**部署配置**:

```yaml
# surveillance-storage.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: surveillance

---
# MinIO for 视频存储
apiVersion: v1
kind: Service
metadata:
  name: video-storage
  namespace: surveillance
spec:
  ports:
  - port: 9000
    name: api
  selector:
    app: minio

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: minio
  namespace: surveillance
spec:
  serviceName: video-storage
  replicas: 4
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
        - server
        - http://minio-{0...3}.video-storage.surveillance.svc.cluster.local/data
        env:
        - name: MINIO_STORAGE_CLASS_STANDARD
          value: "EC:2"  # 纠删码2+2
        - name: MINIO_BROWSER_REDIRECT_URL
          value: "http://surveillance-console.example.com"
        ports:
        - containerPort: 9000
        volumeMounts:
        - name: data
          mountPath: /data
        resources:
          requests:
            cpu: 2
            memory: 4Gi
          limits:
            cpu: 4
            memory: 8Gi
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      storageClassName: local-path  # 使用本地NVMe
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 12Ti  # 每节点12TB

---
# 视频录制服务
apiVersion: apps/v1
kind: Deployment
metadata:
  name: video-recorder
  namespace: surveillance
spec:
  replicas: 10  # 每个实例处理10个摄像头
  selector:
    matchLabels:
      app: video-recorder
  template:
    metadata:
      labels:
        app: video-recorder
    spec:
      containers:
      - name: recorder
        image: video-recorder:v2.0
        env:
        - name: MINIO_ENDPOINT
          value: "video-storage.surveillance.svc.cluster.local:9000"
        - name: BUCKET_NAME
          value: "surveillance-videos"
        - name: RETENTION_DAYS
          value: "7"
        - name: CAMERAS_PER_INSTANCE
          value: "10"
        resources:
          requests:
            cpu: 1
            memory: 2Gi
          limits:
            cpu: 2
            memory: 4Gi
```

**视频录制应用**:

```python
# video_recorder.py
import cv2
from minio import Minio
from datetime import datetime
import threading

class VideoRecorder:
    def __init__(self, camera_url, minio_client, bucket):
        self.camera_url = camera_url
        self.minio = minio_client
        self.bucket = bucket
        self.camera_id = camera_url.split('/')[-1]
    
    def record_stream(self):
        """录制视频流"""
        cap = cv2.VideoCapture(self.camera_url)
        
        # 视频编码器
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = 25
        resolution = (1920, 1080)
        
        segment_duration = 300  # 5分钟一个片段
        start_time = datetime.now()
        
        # 临时文件
        temp_file = f"/tmp/{self.camera_id}_{start_time.strftime('%Y%m%d_%H%M%S')}.mp4"
        out = cv2.VideoWriter(temp_file, fourcc, fps, resolution)
        
        frame_count = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            out.write(frame)
            frame_count += 1
            
            # 5分钟分段
            if frame_count >= fps * segment_duration:
                out.release()
                
                # 上传到MinIO
                object_name = f"{self.camera_id}/{start_time.strftime('%Y/%m/%d/%H-%M-%S')}.mp4"
                self.minio.fput_object(
                    self.bucket,
                    object_name,
                    temp_file,
                    metadata={
                        'camera_id': self.camera_id,
                        'start_time': start_time.isoformat(),
                        'duration': str(segment_duration),
                        'frames': str(frame_count)
                    }
                )
                
                print(f"Uploaded: {object_name}")
                
                # 删除临时文件
                os.remove(temp_file)
                
                # 开始新片段
                start_time = datetime.now()
                temp_file = f"/tmp/{self.camera_id}_{start_time.strftime('%Y%m%d_%H%M%S')}.mp4"
                out = cv2.VideoWriter(temp_file, fourcc, fps, resolution)
                frame_count = 0
        
        cap.release()
        out.release()

# 多摄像头并发录制
cameras = [
    "rtsp://camera1.example.com/stream",
    "rtsp://camera2.example.com/stream",
    # ... 更多摄像头
]

minio_client = Minio(
    "video-storage.surveillance.svc.cluster.local:9000",
    access_key="...",
    secret_key="...",
    secure=False
)

# 为每个摄像头启动录制线程
threads = []
for camera_url in cameras:
    recorder = VideoRecorder(camera_url, minio_client, "surveillance-videos")
    t = threading.Thread(target=recorder.record_stream)
    t.start()
    threads.append(t)

for t in threads:
    t.join()
```

### IoT数据管理

**时序数据库存储**:

```yaml
# influxdb-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: influxdb
  namespace: iot-system
spec:
  serviceName: influxdb
  replicas: 1
  selector:
    matchLabels:
      app: influxdb
  template:
    metadata:
      labels:
        app: influxdb
    spec:
      containers:
      - name: influxdb
        image: influxdb:2.7
        ports:
        - containerPort: 8086
        env:
        - name: INFLUXDB_DB
          value: "iot_metrics"
        - name: INFLUXDB_HTTP_AUTH_ENABLED
          value: "true"
        - name: INFLUXDB_DATA_ENGINE
          value: "tsm1"
        - name: INFLUXDB_DATA_MAX_SERIES_PER_DATABASE
          value: "0"  # 无限制
        volumeMounts:
        - name: data
          mountPath: /var/lib/influxdb2
        resources:
          requests:
            cpu: 2
            memory: 4Gi
          limits:
            cpu: 4
            memory: 8Gi
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      storageClassName: openebs-device  # 高性能存储
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 500Gi
```

**IoT数据采集**:

```python
# iot_data_collector.py
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
import random
import time

class IoTDataCollector:
    def __init__(self, influxdb_url, token, org, bucket):
        self.client = InfluxDBClient(url=influxdb_url, token=token, org=org)
        self.write_api = self.client.write_api(write_options=SYNCHRONOUS)
        self.bucket = bucket
        self.org = org
    
    def collect_sensor_data(self, sensor_id, sensor_type):
        """采集传感器数据"""
        while True:
            # 模拟传感器读数
            if sensor_type == "temperature":
                value = random.uniform(20.0, 30.0)
                unit = "celsius"
            elif sensor_type == "humidity":
                value = random.uniform(30.0, 70.0)
                unit = "percent"
            elif sensor_type == "pressure":
                value = random.uniform(980.0, 1020.0)
                unit = "hPa"
            
            # 写入InfluxDB
            point = Point("sensor_data") \
                .tag("sensor_id", sensor_id) \
                .tag("sensor_type", sensor_type) \
                .tag("location", "edge-site-1") \
                .field("value", value) \
                .field("unit", unit)
            
            self.write_api.write(bucket=self.bucket, org=self.org, record=point)
            
            time.sleep(10)  # 每10秒采集一次
    
    def query_recent_data(self, sensor_id, hours=1):
        """查询最近数据"""
        query = f'''
        from(bucket: "{self.bucket}")
          |> range(start: -{hours}h)
          |> filter(fn: (r) => r["_measurement"] == "sensor_data")
          |> filter(fn: (r) => r["sensor_id"] == "{sensor_id}")
          |> filter(fn: (r) => r["_field"] == "value")
        '''
        
        result = self.client.query_api().query(query, org=self.org)
        
        data = []
        for table in result:
            for record in table.records:
                data.append({
                    'time': record.get_time(),
                    'value': record.get_value(),
                    'sensor_id': record.values['sensor_id'],
                    'sensor_type': record.values['sensor_type']
                })
        
        return data

# 使用
collector = IoTDataCollector(
    influxdb_url="http://influxdb.iot-system.svc.cluster.local:8086",
    token="my-token",
    org="edge-org",
    bucket="iot_metrics"
)

# 启动采集
import threading
sensors = [
    ("temp_001", "temperature"),
    ("humid_001", "humidity"),
    ("press_001", "pressure"),
]

for sensor_id, sensor_type in sensors:
    t = threading.Thread(target=collector.collect_sensor_data, args=(sensor_id, sensor_type))
    t.daemon = True
    t.start()

# 保持运行
while True:
    time.sleep(60)
```

### AI模型分发

**模型存储与版本管理**:

```yaml
# model-registry.yaml
apiVersion: v1
kind: Service
metadata:
  name: model-registry
  namespace: ai-system
spec:
  ports:
  - port: 9000
  selector:
    app: model-registry

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-registry
  namespace: ai-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: model-registry
  template:
    metadata:
      labels:
        app: model-registry
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
        - server
        - /data
        env:
        - name: MINIO_ROOT_USER
          value: "minioadmin"
        - name: MINIO_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: model-registry-secret
              key: password
        ports:
        - containerPort: 9000
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: model-registry-pvc
```

**模型分发服务**:

```python
# model_distributor.py
from minio import Minio
import hashlib
import json

class ModelDistributor:
    def __init__(self, minio_client):
        self.minio = minio_client
        self.bucket = "ai-models"
    
    def upload_model(self, model_name, version, model_file_path, metadata=None):
        """上传AI模型"""
        # 计算模型哈希
        with open(model_file_path, 'rb') as f:
            model_hash = hashlib.sha256(f.read()).hexdigest()
        
        # 对象名称
        object_name = f"{model_name}/{version}/model.pth"
        
        # 元数据
        model_metadata = {
            'model_name': model_name,
            'version': version,
            'sha256': model_hash,
            'upload_time': datetime.now().isoformat(),
            **(metadata or {})
        }
        
        # 上传模型
        self.minio.fput_object(
            self.bucket,
            object_name,
            model_file_path,
            metadata=model_metadata
        )
        
        # 上传元数据JSON
        metadata_object = f"{model_name}/{version}/metadata.json"
        metadata_bytes = json.dumps(model_metadata, indent=2).encode('utf-8')
        self.minio.put_object(
            self.bucket,
            metadata_object,
            io.BytesIO(metadata_bytes),
            length=len(metadata_bytes),
            content_type='application/json'
        )
        
        print(f"Model uploaded: {object_name}")
        return model_hash
    
    def download_model(self, model_name, version, output_path):
        """下载模型到边缘节点"""
        object_name = f"{model_name}/{version}/model.pth"
        
        # 下载
        self.minio.fget_object(self.bucket, object_name, output_path)
        
        # 验证哈希
        metadata_object = f"{model_name}/{version}/metadata.json"
        metadata_response = self.minio.get_object(self.bucket, metadata_object)
        metadata = json.loads(metadata_response.read())
        
        with open(output_path, 'rb') as f:
            downloaded_hash = hashlib.sha256(f.read()).hexdigest()
        
        if downloaded_hash == metadata['sha256']:
            print(f"Model verified: {output_path}")
            return True
        else:
            print(f"Model verification failed!")
            os.remove(output_path)
            return False
    
    def list_model_versions(self, model_name):
        """列出模型所有版本"""
        prefix = f"{model_name}/"
        objects = self.minio.list_objects(self.bucket, prefix=prefix, recursive=True)
        
        versions = set()
        for obj in objects:
            parts = obj.object_name.split('/')
            if len(parts) >= 2:
                versions.add(parts[1])
        
        return sorted(list(versions))

# 使用
distributor = ModelDistributor(minio_client)

# 上传新模型
distributor.upload_model(
    model_name="yolov8",
    version="v8.0.0",
    model_file_path="/models/yolov8.pth",
    metadata={
        'framework': 'PyTorch',
        'task': 'object-detection',
        'input_size': '640x640',
        'classes': 80
    }
)

# 边缘节点下载
distributor.download_model("yolov8", "v8.0.0", "/edge/models/yolov8.pth")
```

---

## 性能优化

### IOPS优化

**存储性能调优**:

```yaml
优化策略:
  1. 使用NVMe SSD:
     - IOPS: 100K-1M
     - 延迟: <100μs
     - 顺序读写: 3-7 GB/s
  
  2. I/O调度器:
     - none (NVMe)
     - mq-deadline (SSD)
     - bfq (HDD)
  
  3. 文件系统:
     - XFS (大文件)
     - ext4 (通用)
     - Btrfs (快照/压缩)
  
  4. 挂载选项:
     - noatime (禁用访问时间)
     - nodiratime (禁用目录访问时间)
     - discard (SSD TRIM)
     - data=writeback (异步写入)
```

**实际配置**:

```bash
# 检查磁盘调度器
cat /sys/block/nvme0n1/queue/scheduler

# 设置为none (NVMe最佳)
echo none > /sys/block/nvme0n1/queue/scheduler

# XFS文件系统优化挂载
mount -o noatime,nodiratime,discard,largeio,inode64 /dev/nvme0n1 /data

# /etc/fstab持久化
/dev/nvme0n1  /data  xfs  noatime,nodiratime,discard,largeio,inode64  0 0

# 调整I/O队列深度
echo 1024 > /sys/block/nvme0n1/queue/nr_requests

# 调整读写缓存
echo 4096 > /sys/block/nvme0n1/queue/read_ahead_kb
```

### 带宽优化

**网络优化**:

```bash
# TCP调优
cat <<EOF >> /etc/sysctl.conf
# TCP缓冲区
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728
net.ipv4.tcp_rmem = 4096 87380 67108864
net.ipv4.tcp_wmem = 4096 65536 67108864

# TCP窗口缩放
net.ipv4.tcp_window_scaling = 1

# TCP拥塞控制 (BBR)
net.core.default_qdisc = fq
net.ipv4.tcp_congestion_control = bbr

# 连接队列
net.core.somaxconn = 4096
net.ipv4.tcp_max_syn_backlog = 8192

# 连接复用
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 15
EOF

sysctl -p
```

**MinIO性能调优**:

```yaml
# 高性能MinIO配置
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: minio-performance
spec:
  replicas: 4
  template:
    spec:
      containers:
      - name: minio
        image: minio/minio:latest
        args:
        - server
        - http://minio-performance-{0...3}.minio-service.default.svc.cluster.local/data{1...4}
        env:
        # 性能优化
        - name: MINIO_CACHE
          value: "on"
        - name: MINIO_CACHE_DRIVES
          value: "/cache"
        - name: MINIO_CACHE_QUOTA
          value: "80"
        - name: MINIO_CACHE_AFTER
          value: "3"
        - name: MINIO_CACHE_WATERMARK_LOW
          value: "70"
        - name: MINIO_CACHE_WATERMARK_HIGH
          value: "90"
        
        # API并发
        - name: MINIO_API_REQUESTS_MAX
          value: "10000"
        - name: MINIO_API_REQUESTS_DEADLINE
          value: "10s"
        
        resources:
          requests:
            cpu: 4
            memory: 16Gi
          limits:
            cpu: 8
            memory: 32Gi
```

### 容量规划

**容量计算工具**:

```python
# capacity_planner.py

class StorageCapacityPlanner:
    def __init__(self):
        self.GB = 1024**3
        self.TB = 1024**4
    
    def calculate_video_storage(self, cameras, days, bitrate_mbps=4, resolution="1080p"):
        """计算视频监控存储需求"""
        # 每小时数据量 (GB)
        hourly_data_per_camera = (bitrate_mbps * 3600) / 8 / 1024
        
        # 每天数据量
        daily_data_per_camera = hourly_data_per_camera * 24
        
        # 总容量
        total_cameras = cameras
        retention_days = days
        
        raw_capacity_gb = total_cameras * daily_data_per_camera * retention_days
        
        # 考虑纠删码开销 (EC 2+2: 2倍开销)
        ec_overhead = 2.0
        actual_capacity_gb = raw_capacity_gb * ec_overhead
        
        # 考虑文件系统开销 (10%)
        fs_overhead = 1.1
        total_capacity_gb = actual_capacity_gb * fs_overhead
        
        return {
            'cameras': cameras,
            'retention_days': days,
            'bitrate_mbps': bitrate_mbps,
            'resolution': resolution,
            'hourly_per_camera_gb': round(hourly_data_per_camera, 2),
            'daily_per_camera_gb': round(daily_data_per_camera, 2),
            'raw_capacity_tb': round(raw_capacity_gb / 1024, 2),
            'with_ec_tb': round(actual_capacity_gb / 1024, 2),
            'total_capacity_tb': round(total_capacity_gb / 1024, 2)
        }
    
    def calculate_iot_storage(self, sensors, sample_rate_sec, data_size_bytes, days):
        """计算IoT时序数据存储需求"""
        samples_per_day = (24 * 3600) / sample_rate_sec
        daily_data_per_sensor = samples_per_day * data_size_bytes
        
        total_sensors = sensors
        retention_days = days
        
        raw_capacity_gb = (total_sensors * daily_data_per_sensor * retention_days) / self.GB
        
        # InfluxDB压缩率 (约10:1)
        compression_ratio = 0.1
        compressed_capacity_gb = raw_capacity_gb * compression_ratio
        
        # 索引开销 (20%)
        index_overhead = 1.2
        total_capacity_gb = compressed_capacity_gb * index_overhead
        
        return {
            'sensors': sensors,
            'sample_rate_sec': sample_rate_sec,
            'data_size_bytes': data_size_bytes,
            'retention_days': days,
            'samples_per_day': int(samples_per_day),
            'raw_capacity_gb': round(raw_capacity_gb, 2),
            'compressed_gb': round(compressed_capacity_gb, 2),
            'total_capacity_gb': round(total_capacity_gb, 2)
        }
    
    def calculate_ai_model_storage(self, models, avg_model_size_gb, versions_per_model):
        """计算AI模型存储需求"""
        total_models = models
        total_versions = models * versions_per_model
        
        raw_capacity_gb = total_versions * avg_model_size_gb
        
        # 考虑增量存储优化 (30%空间节省)
        dedup_ratio = 0.7
        actual_capacity_gb = raw_capacity_gb * dedup_ratio
        
        # 冗余 (3副本)
        replication = 3
        total_capacity_gb = actual_capacity_gb * replication
        
        return {
            'models': models,
            'versions_per_model': versions_per_model,
            'avg_model_size_gb': avg_model_size_gb,
            'total_versions': total_versions,
            'raw_capacity_gb': round(raw_capacity_gb, 2),
            'with_dedup_gb': round(actual_capacity_gb, 2),
            'total_capacity_gb': round(total_capacity_gb, 2)
        }

# 使用示例
planner = StorageCapacityPlanner()

# 视频监控
video_req = planner.calculate_video_storage(
    cameras=100,
    days=7,
    bitrate_mbps=4,
    resolution="1080p"
)
print("视频监控存储需求:")
print(json.dumps(video_req, indent=2))

# IoT传感器
iot_req = planner.calculate_iot_storage(
    sensors=10000,
    sample_rate_sec=10,
    data_size_bytes=100,
    days=30
)
print("\nIoT存储需求:")
print(json.dumps(iot_req, indent=2))

# AI模型
model_req = planner.calculate_ai_model_storage(
    models=50,
    avg_model_size_gb=2,
    versions_per_model=10
)
print("\nAI模型存储需求:")
print(json.dumps(model_req, indent=2))
```

**输出示例**:

```json
视频监控存储需求:
{
  "cameras": 100,
  "retention_days": 7,
  "bitrate_mbps": 4,
  "resolution": "1080p",
  "hourly_per_camera_gb": 1.76,
  "daily_per_camera_gb": 42.19,
  "raw_capacity_tb": 28.92,
  "with_ec_tb": 57.83,
  "total_capacity_tb": 63.62
}

IoT存储需求:
{
  "sensors": 10000,
  "sample_rate_sec": 10,
  "data_size_bytes": 100,
  "retention_days": 30,
  "samples_per_day": 8640,
  "raw_capacity_gb": 242.26,
  "compressed_gb": 24.23,
  "total_capacity_gb": 29.07
}

AI模型存储需求:
{
  "models": 50,
  "versions_per_model": 10,
  "avg_model_size_gb": 2,
  "total_versions": 500,
  "raw_capacity_gb": 1000.0,
  "with_dedup_gb": 700.0,
  "total_capacity_gb": 2100.0
}
```

---

## 参考资料

### 技术文档

**分布式存储**:

- [Ceph Documentation](https://docs.ceph.com/)
- [MinIO Documentation](https://min.io/docs/)
- [Longhorn Documentation](https://longhorn.io/docs/)
- [OpenEBS Documentation](https://openebs.io/docs)

**数据管理**:

- [Velero Backup](https://velero.io/docs/)
- [Restic Backup](https://restic.readthedocs.io/)
- [Rclone Sync](https://rclone.org/docs/)

### 最佳实践

**云原生存储**:

- [CNCF Storage Landscape](https://landscape.cncf.io/guide#runtime--cloud-native-storage)
- [Kubernetes Storage Best Practices](https://kubernetes.io/docs/concepts/storage/)
- [Storage Performance Tuning](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/index)

**数据安全**:

- [NIST SP 800-111 - Storage Encryption](https://csrc.nist.gov/publications/detail/sp/800-111/final)
- [GDPR Compliance for Storage](https://gdpr.eu/)

---

**文档版本**: v1.0  
**最后更新**: 2025-10-19  
**维护者**: 虚拟化容器化技术知识库项目组

**下一步阅读**:

- [01_边缘计算概述与架构](./01_边缘计算概述与架构.md)
- [04_5G边缘计算MEC](./04_5G边缘计算MEC.md)
- [06_边缘AI与推理优化](./06_边缘AI与推理优化.md)
