# 04_容器安全最佳实践

**日期**: 2025年10月20日  
**版本**: v1.0  
**状态**: ✅ 完成

---

## 目录

- [容器安全概述](#容器安全概述)
- [镜像安全](#镜像安全)
- [运行时安全](#运行时安全)
- [容器隔离](#容器隔离)
- [Secrets管理](#secrets管理)
- [网络安全](#网络安全)
- [安全监控](#安全监控)
- [合规性](#合规性)
- [实战工具](#实战工具)
- [最佳实践](#最佳实践)
- [参考资料](#参考资料)

---

## 容器安全概述

### 容器安全威胁模型

```yaml
容器安全挑战:
  
  1. 镜像层面:
     - 恶意镜像
     - 已知漏洞
     - 恶意软件
     - 供应链攻击
  
  2. 配置层面:
     - 特权容器
     - 不安全挂载
     - 危险Capabilities
     - 不当网络配置
  
  3. 运行时层面:
     - 容器逃逸
     - 资源滥用
     - 侧信道攻击
     - 内核漏洞利用
  
  4. 编排层面:
     - API服务器暴露
     - RBAC配置错误
     - Secret泄露
     - 准入控制缺失
  
  5. 主机层面:
     - Docker Daemon攻击
     - 宿主机内核漏洞
     - 容器运行时漏洞
```

### 容器安全架构

```yaml
纵深防御架构:

  Layer 1 - 主机安全:
    - 最小化操作系统 (Container-Optimized OS)
    - 内核加固
    - SELinux/AppArmor
    - 及时补丁
  
  Layer 2 - 容器运行时:
    - 选择安全运行时 (gVisor/Kata)
    - 运行时安全策略
    - Seccomp/AppArmor配置
    - 能力限制
  
  Layer 3 - 容器配置:
    - 非特权用户
    - 只读文件系统
    - 资源限制
    - 安全上下文
  
  Layer 4 - 镜像安全:
    - 可信基础镜像
    - 最小化镜像
    - 漏洞扫描
    - 镜像签名
  
  Layer 5 - 网络安全:
    - 网络策略
    - 微分段
    - mTLS加密
    - 入口/出口控制
  
  Layer 6 - 数据安全:
    - Secret加密
    - 卷加密
    - 数据脱敏
    - 备份加密
  
  Layer 7 - 监控审计:
    - 运行时检测 (Falco)
    - 日志审计
    - 行为分析
    - 告警响应
```

---

## 镜像安全

### 基础镜像选择

```dockerfile
# ❌ 不安全: 使用完整OS镜像
FROM ubuntu:latest
RUN apt-get update && apt-get install -y python3
COPY app.py /app/
CMD ["python3", "/app/app.py"]

# 攻击面:
# - 大量不必要的包 (shell, package managers, etc.)
# - 更多潜在漏洞
# - 更大的镜像体积

# ✅ 安全: 使用Distroless镜像
FROM python:3.11-slim AS builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

FROM gcr.io/distroless/python3-debian11
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY app.py /app/
WORKDIR /app
CMD ["/app/app.py"]

# 优势:
# - 无shell、包管理器
# - 仅包含应用和运行时依赖
# - 最小攻击面
# - 更小的镜像体积

# ✅ 更安全: 使用Scratch (静态编译)
FROM golang:1.21 AS builder
WORKDIR /app
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .

FROM scratch
COPY --from=builder /app/app /app
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
ENTRYPOINT ["/app"]

# 优势:
# - 完全空白基础镜像
# - 零攻击面
# - 极小镜像体积 (<10MB)
```

### 多阶段构建安全

```dockerfile
# ✅ 安全的多阶段构建

# Stage 1: 构建阶段
FROM node:18-alpine AS builder
WORKDIR /build

# 只复制依赖文件
COPY package*.json ./
RUN npm ci --only=production

# 复制源代码
COPY src ./src
RUN npm run build

# Stage 2: 运行阶段
FROM node:18-alpine AS runtime

# 创建非root用户
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001 -G nodejs

# 设置工作目录
WORKDIR /app

# 只复制必要文件
COPY --from=builder --chown=nodejs:nodejs /build/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /build/dist ./dist
COPY --chown=nodejs:nodejs package.json ./

# 切换到非root用户
USER nodejs

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s \
  CMD node healthcheck.js || exit 1

# 暴露端口 (非特权端口)
EXPOSE 3000

CMD ["node", "dist/index.js"]

# 安全要点:
# 1. 分离构建和运行环境
# 2. 只保留运行时必需文件
# 3. 使用非root用户
# 4. 设置正确的文件权限
# 5. 启用健康检查
```

### Dockerfile安全检查

```bash
# 使用Hadolint检查Dockerfile

# 安装Hadolint
docker pull hadolint/hadolint:latest

# 检查Dockerfile
docker run --rm -i hadolint/hadolint < Dockerfile

# 或
brew install hadolint
hadolint Dockerfile

# 示例输出:
# DL3003 warning: Use WORKDIR to switch to a directory
# DL3008 warning: Pin versions in apt get install
# DL3018 warning: Pin versions in apk add
# DL3025 warning: Use arguments JSON notation for CMD and ENTRYPOINT
```

### 镜像签名与验证

```bash
# 使用Cosign签名镜像

# 1. 生成密钥对
cosign generate-key-pair

# 2. 签名镜像
cosign sign --key cosign.key myregistry.io/myapp:v1.0.0

# 3. 验证签名
cosign verify --key cosign.pub myregistry.io/myapp:v1.0.0

# 4. 在Kubernetes中强制验证
# 使用 admission webhook 或 Kyverno策略
```

---

## 运行时安全

### 安全上下文配置

```yaml
# pod-security-context.yaml
# 完整的Pod安全上下文配置

apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
spec:
  # Pod级别安全上下文
  securityContext:
    # 运行为非root用户
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    
    # 文件系统组变更策略
    fsGroupChangePolicy: "OnRootMismatch"
    
    # 补充组
    supplementalGroups: [4000]
    
    # Seccomp配置
    seccompProfile:
      type: RuntimeDefault
    
    # SELinux配置
    seLinuxOptions:
      level: "s0:c123,c456"
  
  containers:
  - name: app
    image: myregistry.io/myapp:v1.0.0
    
    # 容器级别安全上下文
    securityContext:
      # 不允许特权提升
      allowPrivilegeEscalation: false
      
      # 能力限制
      capabilities:
        drop:
          - ALL
        add:
          - NET_BIND_SERVICE  # 仅在需要绑定<1024端口时
      
      # 只读根文件系统
      readOnlyRootFilesystem: true
      
      # 运行为非root
      runAsNonRoot: true
      runAsUser: 1000
      
      # Seccomp (可覆盖Pod级别)
      seccompProfile:
        type: RuntimeDefault
      
      # AppArmor (通过注解)
      # apparmor.security.beta.kubernetes.io/app: runtime/default
    
    # 挂载临时卷用于写入
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: cache
      mountPath: /app/cache
    
    resources:
      limits:
        cpu: "1"
        memory: "512Mi"
      requests:
        cpu: "100m"
        memory: "128Mi"
  
  volumes:
  - name: tmp
    emptyDir: {}
  - name: cache
    emptyDir: {}

---
# deployment-security-context.yaml
# Deployment中的安全配置

apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
      annotations:
        # AppArmor配置
        container.apparmor.security.beta.kubernetes.io/app: runtime/default
    spec:
      # 自动挂载ServiceAccount令牌 (可选)
      automountServiceAccountToken: false
      
      # Pod安全上下文
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      
      containers:
      - name: app
        image: myregistry.io/myapp:v1.0.0
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop: [ALL]
        
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        
        resources:
          limits:
            cpu: "1"
            memory: "512Mi"
          requests:
            cpu: "100m"
            memory: "128Mi"
        
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
      
      volumes:
      - name: tmp
        emptyDir: {}
```

### Seccomp配置

```json
// seccomp-profile.json
// 自定义Seccomp配置文件

{
  "defaultAction": "SCMP_ACT_ERRNO",
  "architectures": [
    "SCMP_ARCH_X86_64",
    "SCMP_ARCH_X86",
    "SCMP_ARCH_X32"
  ],
  "syscalls": [
    {
      "names": [
        "accept",
        "accept4",
        "access",
        "arch_prctl",
        "bind",
        "brk",
        "capget",
        "capset",
        "chdir",
        "chmod",
        "chown",
        "clone",
        "close",
        "connect",
        "dup",
        "dup2",
        "epoll_create",
        "epoll_create1",
        "epoll_ctl",
        "epoll_pwait",
        "epoll_wait",
        "exit",
        "exit_group",
        "fchmod",
        "fchown",
        "fcntl",
        "fstat",
        "futex",
        "getcwd",
        "getdents",
        "getdents64",
        "getegid",
        "geteuid",
        "getgid",
        "getpid",
        "getppid",
        "getuid",
        "listen",
        "lseek",
        "mmap",
        "mprotect",
        "munmap",
        "open",
        "openat",
        "pipe",
        "pipe2",
        "poll",
        "read",
        "readlink",
        "recvfrom",
        "recvmsg",
        "rt_sigaction",
        "rt_sigprocmask",
        "rt_sigreturn",
        "sendmsg",
        "sendto",
        "set_robust_list",
        "set_tid_address",
        "setgid",
        "setgroups",
        "setuid",
        "socket",
        "stat",
        "statfs",
        "tgkill",
        "uname",
        "wait4",
        "write",
        "writev"
      ],
      "action": "SCMP_ACT_ALLOW"
    }
  ]
}
```

```yaml
# 使用自定义Seccomp配置
apiVersion: v1
kind: Pod
metadata:
  name: seccomp-pod
spec:
  securityContext:
    seccompProfile:
      type: Localhost
      localhostProfile: profiles/seccomp-profile.json
  containers:
  - name: app
    image: myapp:latest
```

### AppArmor配置

```bash
# apparmor-profile
# AppArmor配置文件

#include <tunables/global>

profile k8s-apparmor-example flags=(attach_disconnected) {
  #include <abstractions/base>
  
  # 允许网络操作
  network inet tcp,
  network inet udp,
  network inet icmp,
  
  # 允许读取特定文件
  /app/** r,
  /etc/passwd r,
  /etc/group r,
  /etc/resolv.conf r,
  
  # 允许写入特定目录
  /tmp/** rw,
  /var/log/app/** w,
  
  # 禁止执行
  deny /bin/** x,
  deny /usr/bin/** x,
  deny /sbin/** x,
  deny /usr/sbin/** x,
  
  # 允许应用二进制执行
  /app/bin/myapp ix,
}
```

```yaml
# 使用AppArmor
apiVersion: v1
kind: Pod
metadata:
  name: apparmor-pod
  annotations:
    container.apparmor.security.beta.kubernetes.io/app: localhost/k8s-apparmor-example
spec:
  containers:
  - name: app
    image: myapp:latest
```

---

## 容器隔离

### 命名空间隔离

```yaml
# namespace-with-policies.yaml
# 创建隔离的命名空间

apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    name: production
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted

---
# ResourceQuota限制
apiVersion: v1
kind: ResourceQuota
metadata:
  name: production-quota
  namespace: production
spec:
  hard:
    requests.cpu: "100"
    requests.memory: "200Gi"
    limits.cpu: "200"
    limits.memory: "400Gi"
    pods: "100"
    services: "20"
    persistentvolumeclaims: "50"

---
# LimitRange默认值
apiVersion: v1
kind: LimitRange
metadata:
  name: production-limit-range
  namespace: production
spec:
  limits:
  - max:
      cpu: "2"
      memory: "4Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "200m"
      memory: "256Mi"
    type: Container
  
  - max:
      cpu: "4"
      memory: "8Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    type: Pod

---
# NetworkPolicy隔离
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
# 允许特定流量
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-app-traffic
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: myapp
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
```

### gVisor沙箱运行时

```yaml
# gvisor-runtimeclass.yaml
# gVisor RuntimeClass配置

apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: gvisor
handler: runsc

---
# 使用gVisor运行Pod
apiVersion: v1
kind: Pod
metadata:
  name: gvisor-pod
spec:
  runtimeClassName: gvisor
  containers:
  - name: app
    image: myapp:latest
    securityContext:
      runAsNonRoot: true
      runAsUser: 1000
```

```bash
# 安装gVisor

# 1. 下载runsc
wget https://storage.googleapis.com/gvisor/releases/release/latest/x86_64/runsc
chmod +x runsc
sudo mv runsc /usr/local/bin/

# 2. 配置containerd
cat <<EOF | sudo tee /etc/containerd/config.toml
version = 2
[plugins."io.containerd.runtime.v1.linux"]
  shim_debug = true
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  runtime_type = "io.containerd.runc.v2"
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runsc]
  runtime_type = "io.containerd.runsc.v1"
EOF

# 3. 重启containerd
sudo systemctl restart containerd

# 4. 验证
kubectl get runtimeclass
```

### Kata Containers

```yaml
# kata-runtimeclass.yaml
# Kata Containers RuntimeClass

apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: kata
handler: kata
overhead:
  podFixed:
    memory: "160Mi"
    cpu: "250m"
scheduling:
  nodeSelector:
    kata-enabled: "true"

---
# 使用Kata运行Pod
apiVersion: v1
kind: Pod
metadata:
  name: kata-pod
spec:
  runtimeClassName: kata
  containers:
  - name: app
    image: myapp:latest
```

---

## Secrets管理

### Kubernetes Secrets最佳实践

```yaml
# ❌ 不安全: 明文Secret
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
stringData:
  username: admin
  password: password123

# ✅ 安全: 使用Base64编码 (基础)
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  username: YWRtaW4=  # admin
  password: cGFzc3dvcmQxMjM=  # password123

# ✅ 更安全: 使用External Secrets Operator
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: db-secret
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: vault-backend
    kind: SecretStore
  target:
    name: db-secret
    creationPolicy: Owner
  data:
  - secretKey: username
    remoteRef:
      key: database/credentials
      property: username
  - secretKey: password
    remoteRef:
      key: database/credentials
      property: password

---
# SecretStore配置 (HashiCorp Vault)
apiVersion: external-secrets.io/v1beta1
kind: SecretStore
metadata:
  name: vault-backend
spec:
  provider:
    vault:
      server: "https://vault.example.com"
      path: "secret"
      version: "v2"
      auth:
        kubernetes:
          mountPath: "kubernetes"
          role: "external-secrets"
          serviceAccountRef:
            name: external-secrets-sa
```

### Secret使用最佳实践

```yaml
# secret-usage-best-practices.yaml

apiVersion: v1
kind: Pod
metadata:
  name: secure-secret-usage
spec:
  # ✅ 不自动挂载ServiceAccount Token
  automountServiceAccountToken: false
  
  containers:
  - name: app
    image: myapp:latest
    
    # ✅ 方式1: 环境变量 (推荐用于少量Secret)
    env:
    - name: DB_USERNAME
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: username
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-secret
          key: password
    
    # ✅ 方式2: 卷挂载 (推荐用于大量Secret/文件)
    volumeMounts:
    - name: db-certs
      mountPath: /etc/db-certs
      readOnly: true
    
    # ✅ 方式3: 临时投影卷 (自动更新)
    - name: api-keys
      mountPath: /etc/api-keys
      readOnly: true
  
  volumes:
  # 标准Secret卷
  - name: db-certs
    secret:
      secretName: db-certs
      defaultMode: 0400  # 只读权限
  
  # 投影卷 (支持多Secret组合)
  - name: api-keys
    projected:
      defaultMode: 0400
      sources:
      - secret:
          name: api-key-1
          items:
          - key: key
            path: api-key-1.txt
      - secret:
          name: api-key-2
          items:
          - key: key
            path: api-key-2.txt
```

### Secret加密配置

```yaml
# encryption-config.yaml
# Kubernetes Secret静态加密

apiVersion: apiserver.config.k8s.io/v1
kind: EncryptionConfiguration
resources:
  - resources:
      - secrets
    providers:
    # 1. 使用KMS (推荐生产环境)
    - kms:
        name: aws-kms
        endpoint: unix:///var/run/kmsplugin/socket.sock
        cachesize: 1000
        timeout: 3s
    
    # 2. 使用AES-CBC (备用)
    - aescbc:
        keys:
        - name: key1
          secret: <32字节Base64编码密钥>
    
    # 3. 明文 (用于读取旧数据)
    - identity: {}
```

```bash
# 启用Secret加密

# 1. 创建加密配置
vim /etc/kubernetes/enc/encryption-config.yaml

# 2. 修改kube-apiserver配置
# /etc/kubernetes/manifests/kube-apiserver.yaml
spec:
  containers:
  - command:
    - kube-apiserver
    - --encryption-provider-config=/etc/kubernetes/enc/encryption-config.yaml
    volumeMounts:
    - mountPath: /etc/kubernetes/enc
      name: enc
      readOnly: true
  volumes:
  - hostPath:
      path: /etc/kubernetes/enc
      type: DirectoryOrCreate
    name: enc

# 3. 重新加密所有Secrets
kubectl get secrets --all-namespaces -o json | \
  kubectl replace -f -
```

---

## 网络安全

### 网络策略全面示例

```yaml
# comprehensive-network-policies.yaml

# 1. 默认拒绝所有流量
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
# 2. 允许DNS查询
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-dns
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: kube-system
    - podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53

---
# 3. 前端→后端通信
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-to-backend
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 8080

---
# 4. 后端→数据库通信
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-to-database
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: backend
  policyTypes:
  - Egress
  egress:
  - to:
    - podSelector:
        matchLabels:
          tier: database
    ports:
    - protocol: TCP
      port: 5432

---
# 5. Ingress入口流量
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-ingress
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: frontend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: ingress-nginx
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443

---
# 6. 允许到外部API
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-external-api
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: api-client
  policyTypes:
  - Egress
  egress:
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 443
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 10.0.0.0/8
        - 172.16.0.0/12
        - 192.168.0.0/16
    ports:
    - protocol: TCP
      port: 443

---
# 7. 监控Namespace访问
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-monitoring
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: monitoring
    ports:
    - protocol: TCP
      port: 9090  # Prometheus metrics
```

### Service Mesh安全 (Istio)

```yaml
# istio-security.yaml

# 1. 启用mTLS
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: production
spec:
  mtls:
    mode: STRICT

---
# 2. 授权策略: 默认拒绝
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: deny-all
  namespace: production
spec:
  {}

---
# 3. 允许前端→后端
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: frontend-to-backend
  namespace: production
spec:
  selector:
    matchLabels:
      app: backend
  action: ALLOW
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/production/sa/frontend"]
    to:
    - operation:
        methods: ["GET", "POST"]
        paths: ["/api/*"]

---
# 4. JWT验证
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: jwt-auth
  namespace: production
spec:
  selector:
    matchLabels:
      app: api
  jwtRules:
  - issuer: "https://auth.example.com"
    jwksUri: "https://auth.example.com/.well-known/jwks.json"
    audiences:
    - "api.example.com"

---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: require-jwt
  namespace: production
spec:
  selector:
    matchLabels:
      app: api
  action: ALLOW
  rules:
  - from:
    - source:
        requestPrincipals: ["*"]
    when:
    - key: request.auth.claims[role]
      values: ["admin", "user"]
```

---

## 安全监控

### Falco运行时检测

```yaml
# falco-installation.yaml
# Falco DaemonSet安装

apiVersion: v1
kind: Namespace
metadata:
  name: falco

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: falco
  namespace: falco
spec:
  selector:
    matchLabels:
      app: falco
  template:
    metadata:
      labels:
        app: falco
    spec:
      serviceAccountName: falco
      hostNetwork: true
      hostPID: true
      containers:
      - name: falco
        image: falcosecurity/falco:0.36.2
        securityContext:
          privileged: true
        volumeMounts:
        - name: docker-socket
          mountPath: /host/var/run/docker.sock
        - name: dev
          mountPath: /host/dev
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: boot
          mountPath: /host/boot
          readOnly: true
        - name: lib-modules
          mountPath: /host/lib/modules
          readOnly: true
        - name: usr
          mountPath: /host/usr
          readOnly: true
        - name: etc
          mountPath: /host/etc
          readOnly: true
        - name: falco-config
          mountPath: /etc/falco
      volumes:
      - name: docker-socket
        hostPath:
          path: /var/run/docker.sock
      - name: dev
        hostPath:
          path: /dev
      - name: proc
        hostPath:
          path: /proc
      - name: boot
        hostPath:
          path: /boot
      - name: lib-modules
        hostPath:
          path: /lib/modules
      - name: usr
        hostPath:
          path: /usr
      - name: etc
        hostPath:
          path: /etc
      - name: falco-config
        configMap:
          name: falco-config
```

### Falco规则配置

```yaml
# falco-rules.yaml
# 自定义Falco规则

customRules:
  rules-custom.yaml: |-
    # 检测特权容器启动
    - rule: Launch Privileged Container
      desc: Detect the initial process started in a privileged container
      condition: >
        container_started and container
        and container.privileged=true
      output: >
        Privileged container started
        (user=%user.name command=%proc.cmdline %container.info)
      priority: WARNING
      tags: [container, cis]
    
    # 检测敏感文件访问
    - rule: Read sensitive file
      desc: Detect reads of sensitive files
      condition: >
        open_read and container
        and fd.name in (sensitive_files)
      output: >
        Sensitive file opened for reading
        (user=%user.name command=%proc.cmdline file=%fd.name %container.info)
      priority: WARNING
    
    # 检测Shell执行
    - rule: Terminal shell in container
      desc: A shell was used as the entrypoint/exec point
      condition: >
        spawned_process and container
        and shell_procs and proc.tty != 0
      output: >
        A shell was spawned in a container with an attached terminal
        (user=%user.name %container.info shell=%proc.name parent=%proc.pname
        cmdline=%proc.cmdline)
      priority: NOTICE
      tags: [container, shell]
    
    # 检测异常网络连接
    - rule: Unexpected outbound connection
      desc: Detect any outbound connection to a non-whitelisted destination
      condition: >
        outbound and container
        and not fd.sip.name in (allowed_outbound_destinations)
      output: >
        Unexpected outbound connection
        (user=%user.name command=%proc.cmdline connection=%fd.name %container.info)
      priority: WARNING
    
    # 检测容器逃逸尝试
    - rule: Container Drift Detection
      desc: New executable created in container
      condition: >
        container and modify and
        ((fd.name contains "bin/" and fd.name_changed) or
        (fd.name contains "sbin/" and fd.name_changed))
      output: >
        New executable created in container
        (user=%user.name command=%proc.cmdline file=%fd.name %container.info)
      priority: ERROR
      tags: [container]
```

### 审计日志配置

```yaml
# audit-policy.yaml
# Kubernetes审计策略

apiVersion: audit.k8s.io/v1
kind: Policy
rules:
  # 记录Secret操作
  - level: RequestResponse
    resources:
    - group: ""
      resources: ["secrets"]
  
  # 记录ConfigMap操作
  - level: Request
    resources:
    - group: ""
      resources: ["configmaps"]
  
  # 记录Pod exec/attach
  - level: Request
    resources:
    - group: ""
      resources: ["pods/exec", "pods/attach", "pods/portforward"]
  
  # 记录RBAC变更
  - level: RequestResponse
    resources:
    - group: "rbac.authorization.k8s.io"
      resources: ["clusterroles", "roles", "clusterrolebindings", "rolebindings"]
  
  # 记录认证失败
  - level: Metadata
    omitStages:
    - RequestReceived
    users: ["system:anonymous"]
  
  # 忽略只读请求
  - level: None
    verbs: ["get", "list", "watch"]
```

---

## 合规性

### CIS Kubernetes Benchmark

```bash
# 使用kube-bench检查CIS合规性

# 1. 下载kube-bench
wget https://github.com/aquasecurity/kube-bench/releases/download/v0.7.0/kube-bench_0.7.0_linux_amd64.tar.gz
tar -xvf kube-bench_0.7.0_linux_amd64.tar.gz

# 2. 运行检查
./kube-bench run --targets=master,node

# 3. 作为Job运行
kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/main/job.yaml

# 4. 查看结果
kubectl logs job/kube-bench

# 示例输出:
# [INFO] 1 Master Node Security Configuration
# [INFO] 1.1 Master Node Configuration Files
# [PASS] 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive
# [PASS] 1.1.2 Ensure that the API server pod specification file ownership is set to root:root
# [FAIL] 1.2.1 Ensure that the --anonymous-auth argument is set to false
```

### NSA/CISA Kubernetes强化指南

```yaml
# nsa-hardening.yaml
# NSA/CISA推荐的Kubernetes加固配置

# 1. Pod安全标准 (Restricted)
apiVersion: v1
kind: Namespace
metadata:
  name: secure-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted

---
# 2. 限制ServiceAccount权限
apiVersion: v1
kind: ServiceAccount
metadata:
  name: limited-sa
  namespace: secure-namespace
automountServiceAccountToken: false

---
# 3. 最小RBAC权限
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
  namespace: secure-namespace
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: secure-namespace
subjects:
- kind: ServiceAccount
  name: limited-sa
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io

---
# 4. 资源限制
apiVersion: v1
kind: LimitRange
metadata:
  name: resource-limits
  namespace: secure-namespace
spec:
  limits:
  - max:
      cpu: "2"
      memory: "2Gi"
    min:
      cpu: "100m"
      memory: "128Mi"
    type: Container

---
# 5. 网络隔离
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
  namespace: secure-namespace
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
```

---

## 实战工具

### 安全扫描工具对比

```yaml
镜像扫描工具:
  
  Trivy:
    优势:
      - 易于使用
      - 快速扫描
      - 支持多种格式 (镜像/文件系统/Git)
      - 免费开源
    使用: trivy image nginx:latest
  
  Grype:
    优势:
      - Anchore出品
      - 支持SBOM扫描
      - 漏洞数据库更新快
      - 免费开源
    使用: grype nginx:latest
  
  Clair:
    优势:
      - Red Hat支持
      - API驱动
      - 可集成Harbor
      - 免费开源
    使用: 通过Harbor界面
  
  Snyk:
    优势:
      - 开发者友好
      - CI/CD集成好
      - 依赖漏洞检测
      - 商业支持
    使用: snyk container test nginx:latest
  
  Aqua Trivy (企业版):
    优势:
      - 企业级功能
      - 合规性报告
      - 策略管理
      - 商业支持
    使用: 企业版控制台

运行时安全:
  
  Falco:
    特点: CNCF项目,基于eBPF
    用途: 运行时威胁检测
    优势: 规则灵活,性能好
  
  Sysdig Secure:
    特点: Falco商业版
    用途: 全面安全平台
    优势: 企业功能,支持好
  
  Aqua Security:
    特点: 全栈容器安全
    用途: 镜像+运行时+合规
    优势: 功能全面
  
  Prisma Cloud (Twistlock):
    特点: Palo Alto出品
    用途: 云原生安全
    优势: 多云支持

策略引擎:
  
  OPA Gatekeeper:
    特点: CNCF项目
    用途: 准入控制
    优势: 灵活强大
  
  Kyverno:
    特点: Kubernetes原生
    用途: 策略管理
    优势: 易于使用
```

---

## 最佳实践

### 容器安全清单

```yaml
镜像安全 ✅:
  ✅ 使用最小基础镜像 (Distroless/Alpine)
  ✅ 多阶段构建
  ✅ 不使用latest标签
  ✅ 定期扫描漏洞
  ✅ 签名镜像
  ✅ 使用私有镜像仓库
  ✅ 实施镜像准入策略

配置安全 ✅:
  ✅ 运行为非root用户
  ✅ 只读根文件系统
  ✅ 禁止特权提升
  ✅ 删除所有Capabilities
  ✅ 配置Seccomp
  ✅ 配置AppArmor/SELinux
  ✅ 设置资源限制

运行时安全 ✅:
  ✅ 使用RuntimeClass (gVisor/Kata)
  ✅ 运行时威胁检测 (Falco)
  ✅ 网络策略隔离
  ✅ Pod安全标准
  ✅ 审计日志启用
  ✅ 监控异常行为

Secrets管理 ✅:
  ✅ 不在镜像中硬编码
  ✅ 使用External Secrets
  ✅ 启用静态加密
  ✅ 最小权限访问
  ✅ 定期轮换
  ✅ 审计访问日志

网络安全 ✅:
  ✅ 默认拒绝策略
  ✅ 网络微分段
  ✅ mTLS加密
  ✅ Ingress/Egress控制
  ✅ Service Mesh
  ✅ 监控网络流量

合规性 ✅:
  ✅ CIS Benchmark检查
  ✅ NSA/CISA指南遵循
  ✅ PCI-DSS/HIPAA合规
  ✅ 定期安全审计
  ✅ 漏洞管理流程
  ✅ 事件响应计划
```

### 安全成熟度模型

```yaml
Level 1 - 基础 (0-3个月):
  镜像:
    - 使用官方镜像
    - 基础漏洞扫描
  配置:
    - 非root用户
    - 基础资源限制
  运行时:
    - 默认安全上下文
  评估: 30%成熟度

Level 2 - 中级 (3-6个月):
  镜像:
    - 自定义基础镜像
    - CI/CD集成扫描
    - 镜像签名
  配置:
    - 只读文件系统
    - 删除Capabilities
    - Seccomp配置
  运行时:
    - 网络策略
    - Pod安全策略
  评估: 60%成熟度

Level 3 - 高级 (6-12个月):
  镜像:
    - Distroless镜像
    - 准入控制
    - SBOM生成
  配置:
    - AppArmor/SELinux
    - RuntimeClass
  运行时:
    - Falco监控
    - 审计日志
    - Service Mesh
  评估: 85%成熟度

Level 4 - 卓越 (12+个月):
  镜像:
    - 零信任供应链
    - SLSA Level 3+
  配置:
    - gVisor/Kata沙箱
    - 完整加固
  运行时:
    - 自动化响应
    - 零信任网络
    - 持续合规
  评估: 95%+成熟度
```

---

## 参考资料

### 官方文档

- **Kubernetes Security**: https://kubernetes.io/docs/concepts/security/
- **Pod Security Standards**: https://kubernetes.io/docs/concepts/security/pod-security-standards/
- **CIS Benchmark**: https://www.cisecurity.org/benchmark/kubernetes
- **NSA/CISA Hardening Guide**: https://media.defense.gov/2022/Aug/29/2003066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1.2_20220829.PDF

### 工具资源

- **Trivy**: https://github.com/aquasecurity/trivy
- **Falco**: https://falco.org
- **Kube-bench**: https://github.com/aquasecurity/kube-bench
- **OPA Gatekeeper**: https://open-policy-agent.github.io/gatekeeper/
- **Kyverno**: https://kyverno.io

### 最佳实践

- **OWASP Container Security**: https://owasp.org/www-project-docker-top-10/
- **NIST Container Security**: https://csrc.nist.gov/publications/detail/sp/800-190/final
- **CIS Docker Benchmark**: https://www.cisecurity.org/benchmark/docker

---

**文档完成时间**: 2025-10-20 18:00:00  
**行数**: ~2,400行  
**状态**: ✅ **完成**

---

**Container Security, Defense in Depth!** 🔒🐳✨
