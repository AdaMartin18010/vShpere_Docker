# 数据库与中间件迁移

> **返回**: [服务迁移与集成首页](README.md) | [混合部署架构首页](../README.md) | [部署指南首页](../../00_索引导航/README.md)

---

## 📋 目录

- [数据库与中间件迁移](#数据库与中间件迁移)
  - [📋 目录](#-目录)
  - [1. 数据库容器化](#1-数据库容器化)
  - [2. 消息队列迁移](#2-消息队列迁移)
  - [3. 缓存服务迁移](#3-缓存服务迁移)
  - [4. 数据同步](#4-数据同步)

---

## 1. 数据库容器化

**迁移策略**:

```text
核心生产库: 保留VM (稳定性优先)
  ├─ Oracle RAC
  ├─ SQL Server集群
  └─ 关键业务MySQL

开发测试库: 容器化 (快速部署)
  ├─ PostgreSQL (Kubernetes)
  ├─ MySQL (Kubernetes)
  └─ MongoDB (Kubernetes)

只读副本: 容器化 (读写分离)
  ├─ 主库 (VM)
  └─ 从库 (Kubernetes StatefulSet)
```

**MySQL容器化部署**:

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: mysql
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: rook-ceph-block
      resources:
        requests:
          storage: 100Gi
```

**数据迁移**:

```bash
# 1. 备份VM数据库
mysqldump -h vm-mysql \
  --single-transaction \
  --quick \
  --lock-tables=false \
  app_db > app_db.sql

# 2. 恢复到Kubernetes
kubectl exec -i mysql-0 -- \
  mysql -uroot -p${MYSQL_ROOT_PASSWORD} < app_db.sql

# 3. 验证数据
kubectl exec mysql-0 -- \
  mysql -uroot -p${MYSQL_ROOT_PASSWORD} \
  -e "SELECT COUNT(*) FROM app_db.users;"
```

---

## 2. 消息队列迁移

**Kafka迁移 (零停机)**:

```yaml
# 1. 部署Kubernetes Kafka集群
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: my-cluster
spec:
  kafka:
    version: 3.5.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 100Gi
        class: rook-ceph-block
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 10Gi
```

**迁移步骤**:

```bash
# 1. 配置MirrorMaker 2.0 (双向同步)
kubectl apply -f - << EOF
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaMirrorMaker2
metadata:
  name: vm-to-k8s-mirror
spec:
  version: 3.5.0
  replicas: 1
  connectCluster: "k8s-cluster"
  clusters:
  - alias: "vm-cluster"
    bootstrapServers: vm-kafka:9092
  - alias: "k8s-cluster"
    bootstrapServers: my-cluster-kafka-bootstrap:9092
  mirrors:
  - sourceCluster: "vm-cluster"
    targetCluster: "k8s-cluster"
    sourceConnector: {}
    heartbeatConnector: {}
    checkpointConnector: {}
EOF

# 2. 验证消息同步
kafka-console-consumer --bootstrap-server my-cluster-kafka-bootstrap:9092 \
  --topic test --from-beginning

# 3. 逐步切换生产者/消费者到K8s集群
```

---

## 3. 缓存服务迁移

**Redis迁移**:

```yaml
# Redis Cluster部署
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
spec:
  serviceName: redis
  replicas: 6  # 3主3从
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7.0-alpine
        ports:
        - containerPort: 6379
        - containerPort: 16379
        command:
        - redis-server
        - --cluster-enabled
        - "yes"
        - --cluster-config-file
        - /data/nodes.conf
        volumeMounts:
        - name: data
          mountPath: /data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```

**数据迁移 (RIOT - Redis IO Tools)**:

```bash
# 在线迁移 (源VM Redis → 目标K8s Redis)
docker run -it --rm \
  redislabs/riot-redis \
  replicate \
  --source redis://vm-redis:6379 \
  --target redis://k8s-redis:6379

# 验证数据
redis-cli -h k8s-redis -p 6379 INFO keyspace
```

---

## 4. 数据同步

**MySQL主从同步 (VM主 → K8s从)**:

```yaml
# Kubernetes MySQL从库
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-slave
spec:
  template:
    spec:
      initContainers:
      - name: init-slave
        image: mysql:8.0
        command:
        - bash
        - "-c"
        - |
          # 配置主从复制
          mysql -h vm-mysql-master -uroot -p${MYSQL_ROOT_PASSWORD} \
            -e "GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%' IDENTIFIED BY '${REPL_PASSWORD}';"
          
          # 获取binlog位置
          MASTER_LOG_FILE=$(mysql -h vm-mysql-master -uroot -p${MYSQL_ROOT_PASSWORD} \
            -e "SHOW MASTER STATUS\G" | grep File | awk '{print $2}')
          MASTER_LOG_POS=$(mysql -h vm-mysql-master -uroot -p${MYSQL_ROOT_PASSWORD} \
            -e "SHOW MASTER STATUS\G" | grep Position | awk '{print $2}')
          
          # 配置从库
          mysql -uroot -p${MYSQL_ROOT_PASSWORD} << EOF
          CHANGE MASTER TO
            MASTER_HOST='vm-mysql-master',
            MASTER_USER='repl',
            MASTER_PASSWORD='${REPL_PASSWORD}',
            MASTER_LOG_FILE='${MASTER_LOG_FILE}',
            MASTER_LOG_POS=${MASTER_LOG_POS};
          START SLAVE;
          EOF
      containers:
      - name: mysql
        image: mysql:8.0
        # ... (同上)
```

**CDC (Change Data Capture) - Debezium**:

```yaml
# Debezium MySQL Connector
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: mysql-connector
  labels:
    strimzi.io/cluster: connect-cluster
spec:
  class: io.debezium.connector.mysql.MySqlConnector
  config:
    database.hostname: vm-mysql
    database.port: 3306
    database.user: debezium
    database.password: ${DEBEZIUM_PASSWORD}
    database.server.id: 184054
    database.server.name: vm-mysql
    database.whitelist: app_db
    database.history.kafka.bootstrap.servers: my-cluster-kafka:9092
    database.history.kafka.topic: schema-changes.app_db
```

---

**更新时间**: 2025-10-19  
**文档版本**: v1.0  
**状态**: ✅ 完成
