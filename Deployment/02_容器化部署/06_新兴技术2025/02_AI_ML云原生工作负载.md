# AI/MLäº‘åŸç”Ÿå·¥ä½œè´Ÿè½½

> **è¿”å›**: [æ–°å…´æŠ€æœ¯2025](README.md) | [å®¹å™¨åŒ–éƒ¨ç½²é¦–é¡µ](../README.md) | [éƒ¨ç½²æŒ‡å—é¦–é¡µ](../../00_ç´¢å¼•å¯¼èˆª/README.md)

---

## ğŸ“‹ ç›®å½•

- [AI/MLäº‘åŸç”Ÿå·¥ä½œè´Ÿè½½](#aimläº‘åŸç”Ÿå·¥ä½œè´Ÿè½½)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [1. AI/MLäº‘åŸç”ŸæŠ€æœ¯æ¦‚è§ˆ](#1-aimläº‘åŸç”ŸæŠ€æœ¯æ¦‚è§ˆ)
    - [æŠ€æœ¯æ ˆå…¨æ™¯](#æŠ€æœ¯æ ˆå…¨æ™¯)
    - [AI/MLå·¥ä½œè´Ÿè½½ç‰¹ç‚¹](#aimlå·¥ä½œè´Ÿè½½ç‰¹ç‚¹)
  - [2. Kubernetes GPUè°ƒåº¦ (2025æœ€æ–°)](#2-kubernetes-gpuè°ƒåº¦-2025æœ€æ–°)
    - [NVIDIA GPU Operator 23.9+](#nvidia-gpu-operator-239)
    - [å®‰è£…NVIDIA GPU Operator](#å®‰è£…nvidia-gpu-operator)
    - [GPUèµ„æºç®¡ç† (MIG, Time-Slicing)](#gpuèµ„æºç®¡ç†-mig-time-slicing)
    - [GPUæ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦](#gpuæ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦)
  - [3. KubeFlow 1.8+ MLå¹³å°](#3-kubeflow-18-mlå¹³å°)
    - [KubeFlowæ¶æ„](#kubeflowæ¶æ„)
    - [å®‰è£…KubeFlow 1.8](#å®‰è£…kubeflow-18)
    - [Kubeflow Pipelineç¤ºä¾‹](#kubeflow-pipelineç¤ºä¾‹)
  - [4. Ray + KubeRayåˆ†å¸ƒå¼è®¡ç®—](#4-ray--kuberayåˆ†å¸ƒå¼è®¡ç®—)
    - [Ray 2.9+æ ¸å¿ƒæ¦‚å¿µ](#ray-29æ ¸å¿ƒæ¦‚å¿µ)
    - [å®‰è£…KubeRay Operator](#å®‰è£…kuberay-operator)
    - [RayClusteré…ç½®](#rayclusteré…ç½®)
    - [Rayåˆ†å¸ƒå¼è®­ç»ƒç¤ºä¾‹](#rayåˆ†å¸ƒå¼è®­ç»ƒç¤ºä¾‹)

---

## 1. AI/MLäº‘åŸç”ŸæŠ€æœ¯æ¦‚è§ˆ

### æŠ€æœ¯æ ˆå…¨æ™¯

```yaml
AI_ML_Cloud_Native_2025:
  æ ¸å¿ƒç»„ä»¶:
    è®¡ç®—è°ƒåº¦:
      - Kubernetes 1.28+ (GPUè°ƒåº¦)
      - NVIDIA GPU Operator
      - AMD ROCm Operator
      - Intel GPU Plugin
    
    åˆ†å¸ƒå¼æ¡†æ¶:
      - Ray 2.9+ (é€šç”¨åˆ†å¸ƒå¼)
      - Kuberay (Ray on K8s)
      - Horovod (åˆ†å¸ƒå¼è®­ç»ƒ)
      - DeepSpeed (å¤§æ¨¡å‹è®­ç»ƒ)
    
    MLå¹³å°:
      - Kubeflow 1.8+ (å®Œæ•´MLå¹³å°)
      - MLflow (å®éªŒè·Ÿè¸ª)
      - Weights & Biases (W&B)
      - DVC (æ•°æ®ç‰ˆæœ¬æ§åˆ¶)
    
    æ¨¡å‹æœåŠ¡:
      - KServe 0.12+ (æ¨¡å‹æ¨ç†)
      - Seldon Core (æ¨¡å‹éƒ¨ç½²)
      - TorchServe (PyTorch)
      - TensorFlow Serving
    
    å­˜å‚¨:
      - JuiceFS (åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ)
      - Alluxio (æ•°æ®ç¼–æ’)
      - MinIO (å¯¹è±¡å­˜å‚¨)
      - NFS-CSI (å…±äº«å­˜å‚¨)

  GPUæŠ€æœ¯æ ˆ:
    NVIDIA:
      - CUDA 12.3+
      - cuDNN 8.9+
      - NCCL 2.20+ (å¤šGPUé€šä¿¡)
      - NVLink (GPUäº’è”)
      - GPU Direct Storage
      - MIG (Multi-Instance GPU)
      - Time-Slicing (GPUæ—¶é—´ç‰‡)
    
    AMD:
      - ROCm 6.0+
      - MIOpen
      - RCCL
    
    Intel:
      - oneAPI 2024.0
      - oneDNN
      - Level Zero

  2025æ–°è¶‹åŠ¿:
    å¤§æ¨¡å‹è®­ç»ƒ:
      - LLM (GPT, LLaMA, Falcon)
      - å‚æ•°è§„æ¨¡: 70B-175B+
      - åˆ†å¸ƒå¼è®­ç»ƒ: å¼ é‡å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œ
      - æ··åˆç²¾åº¦: FP16, BF16, INT8
    
    æ¨ç†ä¼˜åŒ–:
      - TensorRT 9.0+
      - ONNX Runtime
      - OpenVINO
      - é‡åŒ–åŠ é€Ÿ (INT4/INT8)
    
    è¾¹ç¼˜AI:
      - Edge TPU
      - NVIDIA Jetson
      - æ¨¡å‹å‹ç¼©
      - è”é‚¦å­¦ä¹ 
```

### AI/MLå·¥ä½œè´Ÿè½½ç‰¹ç‚¹

```yaml
AI_ML_Workload_Characteristics:
  èµ„æºéœ€æ±‚:
    GPU:
      - è®­ç»ƒ: é«˜ç®—åŠ› (A100/H100)
      - æ¨ç†: å¹³è¡¡ (T4/L4)
      - æ•°é‡: å•å¡åˆ°æ•°ç™¾å¡
    
    å†…å­˜:
      - GPUå†…å­˜: 16GB-80GB per GPU
      - ç³»ç»Ÿå†…å­˜: 256GB-2TB
      - æ•°æ®é›†: TB-PBçº§
    
    å­˜å‚¨:
      - IOPS: æ•°åä¸‡åˆ°ç™¾ä¸‡
      - å¸¦å®½: 10GB/s+
      - å®¹é‡: TB-PBçº§
    
    ç½‘ç»œ:
      - GPUé—´: NVLink (600GB/s)
      - èŠ‚ç‚¹é—´: 100Gbps/200Gbps InfiniBand
      - å­˜å‚¨: RDMA
  
  å·¥ä½œè´Ÿè½½ç±»å‹:
    è®­ç»ƒ_Training:
      - æ‰¹å¤„ç†
      - é•¿æ—¶é—´è¿è¡Œ (å°æ—¶-å¤©)
      - GPUå¯†é›†
      - é€šä¿¡å¯†é›† (å¤šGPU)
    
    æ¨ç†_Inference:
      - åœ¨çº¿æœåŠ¡
      - ä½å»¶è¿Ÿè¦æ±‚ (<100ms)
      - é«˜ååé‡
      - å¼¹æ€§ä¼¸ç¼©
    
    è¶…å‚æ•°è°ƒä¼˜_HPO:
      - å¹¶è¡Œä»»åŠ¡
      - ä¸­ç­‰æ—¶é•¿
      - èµ„æºå¤šæ ·
    
    Notebookå¼€å‘:
      - äº¤äº’å¼
      - é•¿æœŸå ç”¨
      - ä¸­ç­‰èµ„æº
```

---

## 2. Kubernetes GPUè°ƒåº¦ (2025æœ€æ–°)

### NVIDIA GPU Operator 23.9+

```yaml
NVIDIA_GPU_Operator_2025:
  æ ¸å¿ƒåŠŸèƒ½:
    è‡ªåŠ¨åŒ–ç®¡ç†:
      - GPUé©±åŠ¨å®‰è£…
      - CUDAå·¥å…·åŒ…
      - Container Toolkit
      - Device Plugin
      - GPU Feature Discovery
      - DCGMç›‘æ§å¯¼å‡ºå™¨
    
    GPUç‰¹æ€§æ”¯æŒ:
      - MIG (Multi-Instance GPU)
      - Time-Slicing (æ—¶é—´ç‰‡)
      - GPUç›´é€š
      - vGPU (è™šæ‹ŸåŒ–)
      - GPUDirect RDMA
      - GPUDirect Storage
    
    ç›‘æ§å¯è§‚æµ‹æ€§:
      - DCGMæŒ‡æ ‡
      - Prometheusé›†æˆ
      - Grafanaä»ªè¡¨æ¿
      - GPUæ‹“æ‰‘å‘ç°
```

### å®‰è£…NVIDIA GPU Operator

```bash
#!/bin/bash
# install-nvidia-gpu-operator.sh - 2025

set -e

echo "=== å®‰è£…NVIDIA GPU Operator (2025) ==="

# 1. å‰ç½®æ£€æŸ¥
echo "1. æ£€æŸ¥GPUç¡¬ä»¶..."
lspci | grep -i nvidia

# æ£€æŸ¥å†…æ ¸ç‰ˆæœ¬
uname -r

# 2. æ·»åŠ Helmä»“åº“
echo "2. æ·»åŠ NVIDIA Helmä»“åº“..."
helm repo add nvidia https://nvidia.github.io/gpu-operator
helm repo update

# 3. åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace gpu-operator --dry-run=client -o yaml | kubectl apply -f -

# 4. å®‰è£…GPU Operator
echo "3. å®‰è£…GPU Operator..."
helm install gpu-operator nvidia/gpu-operator \
  --namespace gpu-operator \
  --version v23.9.1 \
  --set operator.defaultRuntime=containerd \
  --set driver.enabled=true \
  --set driver.version="535.129.03" \
  --set toolkit.enabled=true \
  --set devicePlugin.enabled=true \
  --set devicePlugin.version=v0.14.5 \
  --set mig.strategy=single \
  --set gfd.enabled=true \
  --set dcgmExporter.enabled=true \
  --set dcgmExporter.serviceMonitor.enabled=true \
  --set nodeStatusExporter.enabled=true

# 5. ç­‰å¾…éƒ¨ç½²å®Œæˆ
echo "4. ç­‰å¾…GPU Operatoréƒ¨ç½²..."
kubectl -n gpu-operator rollout status daemonset/nvidia-driver-daemonset
kubectl -n gpu-operator rollout status daemonset/nvidia-container-toolkit-daemonset
kubectl -n gpu-operator rollout status daemonset/nvidia-device-plugin-daemonset

# 6. éªŒè¯GPUå¯ç”¨æ€§
echo "5. éªŒè¯GPUèŠ‚ç‚¹..."
kubectl get nodes -o json | \
  jq '.items[] | {name: .metadata.name, gpus: .status.capacity."nvidia.com/gpu"}'

# 7. æ ‡è®°GPUèŠ‚ç‚¹
echo "6. æ ‡è®°GPUèŠ‚ç‚¹..."
for node in $(kubectl get nodes -o jsonpath='{.items[*].metadata.name}'); do
  GPU_COUNT=$(kubectl get node $node -o jsonpath='{.status.capacity.nvidia\.com/gpu}')
  if [ -n "$GPU_COUNT" ] && [ "$GPU_COUNT" != "0" ]; then
    kubectl label node $node gpu-type=nvidia --overwrite
    kubectl label node $node gpu-count=$GPU_COUNT --overwrite
  fi
done

# 8. è¿è¡Œæµ‹è¯•Pod
echo "7. è¿è¡ŒGPUæµ‹è¯•..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: gpu-test
spec:
  restartPolicy: Never
  containers:
  - name: cuda-test
    image: nvidia/cuda:12.3.0-base-ubuntu22.04
    command: ["nvidia-smi"]
    resources:
      limits:
        nvidia.com/gpu: 1
EOF

kubectl wait --for=condition=Completed pod/gpu-test --timeout=120s
kubectl logs gpu-test

# æ¸…ç†æµ‹è¯•Pod
kubectl delete pod gpu-test

echo ""
echo "=== GPU Operatorå®‰è£…å®Œæˆ ==="
echo "æŸ¥çœ‹GPUèŠ‚ç‚¹: kubectl get nodes -l gpu-type=nvidia"
echo "æŸ¥çœ‹GPUèµ„æº: kubectl describe nodes | grep nvidia.com/gpu"
```

### GPUèµ„æºç®¡ç† (MIG, Time-Slicing)

```yaml
# gpu-resource-configs.yaml

# 1. MIGé…ç½® (Multi-Instance GPU)
# A100 GPUå¯åˆ†å‰²ä¸ºæœ€å¤š7ä¸ªMIGå®ä¾‹
apiVersion: v1
kind: ConfigMap
metadata:
  name: mig-parted-config
  namespace: gpu-operator
data:
  config.yaml: |
    version: v1
    mig-configs:
      # A100-80GB é…ç½®ç­–ç•¥
      all-balanced:
        - devices: all
          mig-enabled: true
          mig-devices:
            "1g.10gb": 7    # 7ä¸ªå°å®ä¾‹
      
      half-half:
        - devices: all
          mig-enabled: true
          mig-devices:
            "3g.40gb": 2    # 2ä¸ªå¤§å®ä¾‹
      
      mixed:
        - devices: [0]
          mig-enabled: true
          mig-devices:
            "3g.40gb": 1
            "1g.10gb": 3
        - devices: [1]
          mig-enabled: false  # æ•´å¡æ¨¡å¼

---
# 2. Time-Slicingé…ç½® (GPUæ—¶é—´ç‰‡å…±äº«)
apiVersion: v1
kind: ConfigMap
metadata:
  name: device-plugin-config
  namespace: gpu-operator
data:
  config.yaml: |
    version: v1
    sharing:
      timeSlicing:
        resources:
        - name: nvidia.com/gpu
          replicas: 4  # 1ä¸ªç‰©ç†GPUè™šæ‹Ÿä¸º4ä¸ªé€»è¾‘GPU
        
        # ä¸åŒGPUç±»å‹ä¸åŒç­–ç•¥
        - name: nvidia.com/gpu
          selector:
            nvidia.com/gpu.product: "Tesla-T4"
          replicas: 8  # T4æ¨ç†å¡å¯ä»¥æ›´å¤šå…±äº«
        
        - name: nvidia.com/gpu
          selector:
            nvidia.com/gpu.product: "A100-SXM4-80GB"
          replicas: 2  # A100è®­ç»ƒå¡å°‘é‡å…±äº«

---
# 3. åº”ç”¨Time-Slicingçš„Pod
apiVersion: v1
kind: Pod
metadata:
  name: gpu-shared-pod-1
spec:
  containers:
  - name: app
    image: nvidia/cuda:12.3.0-base-ubuntu22.04
    command: ["sleep", "infinity"]
    resources:
      limits:
        nvidia.com/gpu: 1  # è·å¾—1/4ç‰©ç†GPU
---
apiVersion: v1
kind: Pod
metadata:
  name: gpu-shared-pod-2
spec:
  containers:
  - name: app
    image: nvidia/cuda:12.3.0-base-ubuntu22.04
    command: ["sleep", "infinity"]
    resources:
      limits:
        nvidia.com/gpu: 1  # å¦ä¸€ä¸ª1/4ç‰©ç†GPU
```

### GPUæ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦

```yaml
# gpu-topology-aware-scheduling.yaml

# 1. NodeLabelæ·»åŠ GPUæ‹“æ‰‘ä¿¡æ¯
# GPU Operatorè‡ªåŠ¨æ ‡è®°èŠ‚ç‚¹
# nvidia.com/gpu.count
# nvidia.com/gpu.product
# nvidia.com/gpu.memory
# nvidia.com/gpu.compute-capability
# topology.kubernetes.io/zone (ç‰©ç†ä½ç½®)

# 2. æ‹“æ‰‘æ„ŸçŸ¥çš„StatefulSet (å¤šGPUè®­ç»ƒ)
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: distributed-training
spec:
  serviceName: training
  replicas: 4  # 4ä¸ªè®­ç»ƒèŠ‚ç‚¹
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: training
  template:
    metadata:
      labels:
        app: training
    spec:
      # GPUèŠ‚ç‚¹é€‰æ‹©
      nodeSelector:
        gpu-type: nvidia
        nvidia.com/gpu.product: "A100-SXM4-80GB"
      
      # æ‹“æ‰‘æ„ŸçŸ¥ï¼šä¼˜å…ˆåŒä¸€æœºæ¶
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: training
              topologyKey: topology.kubernetes.io/zone
        
        # èŠ‚ç‚¹äº²å’Œæ€§ï¼šéœ€è¦NVLink
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.count
                operator: Gt
                values: ["7"]  # 8å¡èŠ‚ç‚¹
      
      containers:
      - name: trainer
        image: nvcr.io/nvidia/pytorch:23.12-py3
        command:
          - python
          - -m
          - torch.distributed.launch
          - --nproc_per_node=8
          - --nnodes=4
          - --node_rank=$(POD_INDEX)
          - --master_addr=training-0.training.default.svc.cluster.local
          - --master_port=23456
          - train.py
        env:
        - name: POD_INDEX
          valueFrom:
            fieldRef:
              fieldPath: metadata.labels['apps.kubernetes.io/pod-index']
        - name: NCCL_DEBUG
          value: "INFO"
        - name: NCCL_IB_DISABLE
          value: "0"  # å¯ç”¨InfiniBand
        - name: NCCL_NET_GDR_LEVEL
          value: "5"  # GPUDirect RDMA
        resources:
          limits:
            nvidia.com/gpu: 8  # æ¯ä¸ªPod 8å¼ GPU
            rdma/hca: 1  # InfiniBand HCA
        volumeMounts:
        - name: shm
          mountPath: /dev/shm
        - name: dataset
          mountPath: /data
      
      volumes:
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 64Gi  # å¤§shared memory for NCCL
      - name: dataset
        persistentVolumeClaim:
          claimName: imagenet-pvc
```

---

## 3. KubeFlow 1.8+ MLå¹³å°

### KubeFlowæ¶æ„

```yaml
Kubeflow_1_8_Architecture_2025:
  æ ¸å¿ƒç»„ä»¶:
    ä¸­å¿ƒDashboard:
      - ç»Ÿä¸€UIå…¥å£
      - å¤šç§Ÿæˆ·æ”¯æŒ
      - RBACé›†æˆ
      - å‘½åç©ºé—´ç®¡ç†
    
    Notebooks:
      - Jupyter/VS Code/RStudio
      - GPUèµ„æºè¯·æ±‚
      - PVCæŒä¹…åŒ–
      - è‡ªå®šä¹‰é•œåƒ
    
    Pipelines_v2:
      - MLå·¥ä½œæµç¼–æ’
      - DAGå¯è§†åŒ–
      - Artifactè·Ÿè¸ª
      - ç¼“å­˜ä¸å¤ç”¨
      - Tektonåç«¯
    
    Katib:
      - è¶…å‚æ•°ä¼˜åŒ– (HPO)
      - Neural Architecture Search (NAS)
      - å¤šç§ç®—æ³• (Grid/Random/Bayesian/Hyperband)
      - å¹¶è¡Œtrial
    
    Training_Operators:
      - TFJob (TensorFlow)
      - PyTorchJob (PyTorch)
      - MXJob (MXNet)
      - MPIJob (Horovod)
      - XGBoostJob
      - PaddleJob
    
    KServe:
      - æ¨¡å‹æœåŠ¡
      - è‡ªåŠ¨ä¼¸ç¼©
      - Canaryéƒ¨ç½²
      - A/Bæµ‹è¯•
      - Explainability

  2025æ–°ç‰¹æ€§:
    - KFP v2 GA (å®Œå…¨é‡å†™)
    - Vertex AIé›†æˆ
    - MLflowé›†æˆå¢å¼º
    - Rayé›†æˆ
    - å¤šäº‘æ”¯æŒ
```

### å®‰è£…KubeFlow 1.8

```bash
#!/bin/bash
# install-kubeflow-1.8.sh

set -e

echo "=== å®‰è£…Kubeflow 1.8 (2025) ==="

# 1. å‰ç½®è¦æ±‚
echo "1. æ£€æŸ¥å‰ç½®æ¡ä»¶..."
kubectl version --client
kustomize version

# 2. å…‹éš†Kubeflow manifests
echo "2. ä¸‹è½½Kubeflow manifests..."
git clone https://github.com/kubeflow/manifests.git
cd manifests
git checkout v1.8-branch

# 3. å®‰è£…cert-manager
echo "3. å®‰è£…cert-manager..."
kubectl apply -f common/cert-manager/cert-manager/base
kubectl wait --for=condition=ready pod -l 'app in (cert-manager,webhook)' \
  --timeout=180s -n cert-manager

# 4. å®‰è£…Istio (for KubeFlow)
echo "4. å®‰è£…Istio..."
kubectl apply -f common/istio-1-20/istio-crds/base
kubectl apply -f common/istio-1-20/istio-namespace/base
kubectl apply -f common/istio-1-20/istio-install/overlays/oauth2-proxy

# 5. å®‰è£…Dex (èº«ä»½è®¤è¯)
echo "5. å®‰è£…Dex..."
kubectl apply -f common/dex/overlays/istio

# 6. å®‰è£…OIDC AuthService
echo "6. å®‰è£…AuthService..."
kubectl apply -f common/oidc-client/oidc-authservice/overlays/ibm-storage-class

# 7. å®‰è£…Kubeflow Namespace
echo "7. åˆ›å»ºKubeflowå‘½åç©ºé—´..."
kubectl apply -f common/kubeflow-namespace/base

# 8. å®‰è£…Kubeflow Roles
kubectl apply -f common/kubeflow-roles/base
kubectl apply -f common/istio-1-20/kubeflow-istio-resources/base

# 9. å®‰è£…Kubeflow Pipelines
echo "8. å®‰è£…Kubeflow Pipelines..."
kubectl apply -f apps/pipeline/upstream/env/cert-manager/platform-agnostic-multi-user

# ç­‰å¾…Pipelineså°±ç»ª
kubectl wait --for=condition=ready pod -l app=ml-pipeline \
  --timeout=600s -n kubeflow

# 10. å®‰è£…Katib (è¶…å‚æ•°è°ƒä¼˜)
echo "9. å®‰è£…Katib..."
kubectl apply -f apps/katib/upstream/installs/katib-cert-manager

# 11. å®‰è£…Training Operators
echo "10. å®‰è£…Training Operators..."
kubectl apply -f apps/training-operator/upstream/overlays/kubeflow

# 12. å®‰è£…Notebooks
echo "11. å®‰è£…Notebooks..."
kubectl apply -f apps/jupyter/jupyter-web-app/upstream/overlays/istio
kubectl apply -f apps/jupyter/notebook-controller/upstream/overlays/kubeflow
kubectl apply -f apps/admission-webhook/upstream/overlays/cert-manager

# 13. å®‰è£…Central Dashboard
echo "12. å®‰è£…Central Dashboard..."
kubectl apply -f apps/centraldashboard/upstream/overlays/oauth2-proxy
kubectl apply -f apps/profiles/upstream/overlays/kubeflow

# 14. å®‰è£…Volumes Web App
kubectl apply -f apps/volumes-web-app/upstream/overlays/istio

# 15. å®‰è£…Tensorboards
kubectl apply -f apps/tensorboard/tensorboards-web-app/upstream/overlays/istio
kubectl apply -f apps/tensorboard/tensorboard-controller/upstream/overlays/kubeflow

# 16. å®‰è£…KServe
echo "13. å®‰è£…KServe..."
kubectl apply -f contrib/kserve/kserve
kubectl apply -f contrib/kserve/models-web-app/overlays/kubeflow

# 17. éªŒè¯å®‰è£…
echo "14. éªŒè¯å®‰è£…..."
kubectl get pods -n kubeflow
kubectl get pods -n istio-system

# 18. è·å–è®¿é—®ä¿¡æ¯
echo ""
echo "=== Kubeflowå®‰è£…å®Œæˆ ==="
echo "Dashboard URL: http://<LoadBalancer-IP>"
echo "é»˜è®¤ç”¨æˆ·: user@example.com"
echo "é»˜è®¤å¯†ç : 12341234"
echo ""
echo "è·å–LoadBalancer IP:"
echo "kubectl get svc istio-ingressgateway -n istio-system"
```

### Kubeflow Pipelineç¤ºä¾‹

```python
# ml_pipeline.py - Kubeflow Pipeline v2
from kfp import dsl
from kfp import compiler
from kfp.dsl import Input, Output, Dataset, Model, Metrics

@dsl.component(
    base_image='python:3.10',
    packages_to_install=['pandas', 'scikit-learn']
)
def load_data(dataset_path: str, output_data: Output[Dataset]):
    """åŠ è½½æ•°æ®"""
    import pandas as pd
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv(dataset_path)
    
    # ä¿å­˜åˆ°artifact
    df.to_csv(output_data.path, index=False)
    print(f"Loaded {len(df)} samples")

@dsl.component(
    base_image='python:3.10',
    packages_to_install=['pandas', 'scikit-learn']
)
def preprocess_data(
    input_data: Input[Dataset],
    train_data: Output[Dataset],
    test_data: Output[Dataset]
):
    """æ•°æ®é¢„å¤„ç†"""
    import pandas as pd
    from sklearn.model_selection import train_test_split
    
    df = pd.read_csv(input_data.path)
    
    # åˆ†å‰²è®­ç»ƒ/æµ‹è¯•é›†
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
    
    train_df.to_csv(train_data.path, index=False)
    test_df.to_csv(test_data.path, index=False)
    print(f"Train: {len(train_df)}, Test: {len(test_df)}")

@dsl.component(
    base_image='python:3.10',
    packages_to_install=['pandas', 'scikit-learn', 'joblib']
)
def train_model(
    train_data: Input[Dataset],
    model: Output[Model],
    metrics: Output[Metrics]
):
    """è®­ç»ƒæ¨¡å‹"""
    import pandas as pd
    from sklearn.ensemble import RandomForestClassifier
    import joblib
    import json
    
    train_df = pd.read_csv(train_data.path)
    X = train_df.drop('target', axis=1)
    y = train_df['target']
    
    # è®­ç»ƒ
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X, y)
    
    # ä¿å­˜æ¨¡å‹
    joblib.dump(clf, model.path)
    
    # è®°å½•æŒ‡æ ‡
    train_score = clf.score(X, y)
    metrics.log_metric('train_accuracy', train_score)
    print(f"Training accuracy: {train_score:.4f}")

@dsl.component(
    base_image='python:3.10',
    packages_to_install=['pandas', 'scikit-learn', 'joblib']
)
def evaluate_model(
    model: Input[Model],
    test_data: Input[Dataset],
    metrics: Output[Metrics]
):
    """è¯„ä¼°æ¨¡å‹"""
    import pandas as pd
    import joblib
    from sklearn.metrics import accuracy_score, f1_score
    
    test_df = pd.read_csv(test_data.path)
    X_test = test_df.drop('target', axis=1)
    y_test = test_df['target']
    
    # åŠ è½½æ¨¡å‹
    clf = joblib.load(model.path)
    
    # é¢„æµ‹
    y_pred = clf.predict(X_test)
    
    # è®¡ç®—æŒ‡æ ‡
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    metrics.log_metric('test_accuracy', accuracy)
    metrics.log_metric('f1_score', f1)
    print(f"Test accuracy: {accuracy:.4f}, F1: {f1:.4f}")

@dsl.pipeline(
    name='ML Training Pipeline',
    description='Complete ML training pipeline'
)
def ml_pipeline(dataset_path: str = 'gs://my-bucket/data.csv'):
    # 1. åŠ è½½æ•°æ®
    load_task = load_data(dataset_path=dataset_path)
    
    # 2. é¢„å¤„ç†
    preprocess_task = preprocess_data(input_data=load_task.outputs['output_data'])
    
    # 3. è®­ç»ƒ
    train_task = train_model(train_data=preprocess_task.outputs['train_data'])
    
    # 4. è¯„ä¼°
    evaluate_task = evaluate_model(
        model=train_task.outputs['model'],
        test_data=preprocess_task.outputs['test_data']
    )
    
    # GPUèµ„æºé…ç½®
    train_task.set_gpu_limit(1)
    train_task.set_memory_limit('8Gi')
    train_task.set_cpu_limit('4')

# ç¼–è¯‘Pipeline
if __name__ == '__main__':
    compiler.Compiler().compile(
        pipeline_func=ml_pipeline,
        package_path='ml_pipeline.yaml'
    )
```

```bash
# æäº¤Pipeline
python ml_pipeline.py

# ä½¿ç”¨kfp SDKæäº¤
python -c "
from kfp import Client
client = Client(host='http://kubeflow-pipelines-api.kubeflow:8888')
run = client.create_run_from_pipeline_package(
    'ml_pipeline.yaml',
    arguments={'dataset_path': 'gs://my-data/train.csv'}
)
print(f'Run ID: {run.run_id}')
"
```

---

## 4. Ray + KubeRayåˆ†å¸ƒå¼è®¡ç®—

### Ray 2.9+æ ¸å¿ƒæ¦‚å¿µ

```yaml
Ray_2_9_Overview:
  æ ¸å¿ƒç‰¹æ€§:
    åˆ†å¸ƒå¼è®¡ç®—:
      - Taskå¹¶è¡Œ (@ray.remote)
      - Actoræ¨¡å‹ (æœ‰çŠ¶æ€)
      - Object Store (é›¶æ‹·è´)
      - è‡ªåŠ¨æ•…éšœæ¢å¤
    
    AIåº“ç”Ÿæ€:
      - Ray Train (åˆ†å¸ƒå¼è®­ç»ƒ)
      - Ray Data (æ•°æ®å¤„ç†)
      - Ray Serve (æ¨¡å‹æœåŠ¡)
      - Ray Tune (è¶…å‚æ•°è°ƒä¼˜)
      - Ray RLlib (å¼ºåŒ–å­¦ä¹ )
    
    èµ„æºç®¡ç†:
      - CPU/GPU/Customèµ„æº
      - èµ„æºæ‰“åŒ…
      - èŠ‚ç‚¹äº²å’Œæ€§
      - å¼¹æ€§ä¼¸ç¼©
  
  2025æ–°ç‰¹æ€§:
    - Native GPUæ”¯æŒå¢å¼º
    - Kubernetesé›†æˆæ”¹è¿›
    - æ•°æ®é¢„å¤„ç†åŠ é€Ÿ
    - å¤§æ¨¡å‹è®­ç»ƒä¼˜åŒ–
```

### å®‰è£…KubeRay Operator

```bash
#!/bin/bash
# install-kuberay-operator.sh

set -e

echo "=== å®‰è£…KubeRay Operator (2025) ==="

# 1. æ·»åŠ Helmä»“åº“
helm repo add kuberay https://ray-project.github.io/kuberay-helm/
helm repo update

# 2. å®‰è£…KubeRay Operator
kubectl create namespace ray-system --dry-run=client -o yaml | kubectl apply -f -

helm install kuberay-operator kuberay/kuberay-operator \
  --namespace ray-system \
  --version 1.1.0

# 3. ç­‰å¾…Operatorå°±ç»ª
kubectl wait --for=condition=available deployment/kuberay-operator \
  -n ray-system --timeout=300s

echo "=== KubeRay Operatorå®‰è£…å®Œæˆ ==="
```

### RayClusteré…ç½®

```yaml
# raycluster-gpu.yaml
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: ray-gpu-cluster
  namespace: ray
spec:
  # Rayç‰ˆæœ¬
  rayVersion: '2.9.0'
  
  # å¯ç”¨è‡ªåŠ¨ä¼¸ç¼©
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Default
    idleTimeoutSeconds: 60
    resources:
      limits:
        cpu: "1"
        memory: "2Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
  
  # HeadèŠ‚ç‚¹
  headGroupSpec:
    rayStartParams:
      dashboard-host: '0.0.0.0'
      block: 'true'
    template:
      spec:
        containers:
        - name: ray-head
          image: rayproject/ray:2.9.0-py310-gpu
          ports:
          - containerPort: 6379  # Redis
            name: redis
          - containerPort: 8265  # Dashboard
            name: dashboard
          - containerPort: 10001  # Client
            name: client
          resources:
            limits:
              cpu: "4"
              memory: "16Gi"
            requests:
              cpu: "2"
              memory: "8Gi"
          volumeMounts:
          - name: ray-logs
            mountPath: /tmp/ray
        volumes:
        - name: ray-logs
          emptyDir: {}
  
  # Workerç»„ (GPU)
  workerGroupSpecs:
  - groupName: gpu-workers
    replicas: 2
    minReplicas: 0
    maxReplicas: 10
    rayStartParams:
      block: 'true'
    template:
      spec:
        nodeSelector:
          gpu-type: nvidia
        containers:
        - name: ray-worker
          image: rayproject/ray:2.9.0-py310-gpu
          resources:
            limits:
              cpu: "8"
              memory: "32Gi"
              nvidia.com/gpu: "1"  # 1 GPU per worker
            requests:
              cpu: "4"
              memory: "16Gi"
              nvidia.com/gpu: "1"
          volumeMounts:
          - name: ray-logs
            mountPath: /tmp/ray
          - name: shm
            mountPath: /dev/shm
        volumes:
        - name: ray-logs
          emptyDir: {}
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 8Gi  # Shared memory for Ray Object Store
  
  - groupName: cpu-workers
    replicas: 4
    minReplicas: 2
    maxReplicas: 20
    rayStartParams:
      block: 'true'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.9.0-py310
          resources:
            limits:
              cpu: "4"
              memory: "16Gi"
            requests:
              cpu: "2"
              memory: "8Gi"

---
# Ray Dashboard Service
apiVersion: v1
kind: Service
metadata:
  name: ray-dashboard
  namespace: ray
spec:
  type: LoadBalancer
  selector:
    ray.io/cluster: ray-gpu-cluster
    ray.io/node-type: head
  ports:
  - name: dashboard
    port: 8265
    targetPort: 8265
  - name: client
    port: 10001
    targetPort: 10001
```

### Rayåˆ†å¸ƒå¼è®­ç»ƒç¤ºä¾‹

```python
# ray_distributed_training.py
import ray
from ray import train
from ray.train import ScalingConfig
from ray.train.torch import TorchTrainer
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset

# 1. å®šä¹‰æ¨¡å‹
class SimpleModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

# 2. å®šä¹‰è®­ç»ƒå‡½æ•°
def train_func(config):
    # è·å–åˆ†å¸ƒå¼é…ç½®
    world_size = train.get_context().get_world_size()
    rank = train.get_context().get_world_rank()
    
    print(f"Worker {rank}/{world_size} starting...")
    
    # åˆ›å»ºæ¨¡å‹ (è‡ªåŠ¨åˆ†å¸ƒå¼)
    model = SimpleModel()
    model = train.torch.prepare_model(model)
    
    # æ•°æ®åŠ è½½
    # ... (DataLoader)
    
    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(config['num_epochs']):
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = nn.CrossEntropyLoss()(output, target)
            loss.backward()
            optimizer.step()
            
            if batch_idx % 100 == 0:
                print(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}")
                
                # æŠ¥å‘ŠæŒ‡æ ‡åˆ°Ray
                train.report({'loss': loss.item(), 'epoch': epoch})

# 3. åˆ›å»ºTrainer
if __name__ == '__main__':
    # è¿æ¥åˆ°Rayé›†ç¾¤
    ray.init(address='ray://ray-dashboard.ray:10001')
    
    # é…ç½®åˆ†å¸ƒå¼è®­ç»ƒ
    scaling_config = ScalingConfig(
        num_workers=4,  # 4ä¸ªworker
        use_gpu=True,   # ä½¿ç”¨GPU
        resources_per_worker={'CPU': 4, 'GPU': 1}  # æ¯ä¸ªworkerèµ„æº
    )
    
    # åˆ›å»ºTrainer
    trainer = TorchTrainer(
        train_loop_per_worker=train_func,
        train_loop_config={'num_epochs': 10},
        scaling_config=scaling_config
    )
    
    # å¼€å§‹è®­ç»ƒ
    result = trainer.fit()
    print(f"Training completed: {result}")
```

---

ç”±äºå“åº”é•¿åº¦é™åˆ¶ï¼Œæˆ‘å°†åœ¨ä¸‹ä¸€éƒ¨åˆ†ç»§ç»­å®ŒæˆAI/MLæ–‡æ¡£çš„å‰©ä½™ç« èŠ‚ï¼ˆæ¨¡å‹æœåŠ¡ã€MLOpsã€GPUå…±äº«ç­‰ï¼‰ã€‚è®©æˆ‘ä¿å­˜å½“å‰è¿›åº¦å¹¶ç»§ç»­ã€‚

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0 (è¿›è¡Œä¸­)  
**æ›´æ–°æ—¥æœŸ**: 2025-10-20  
**çŠ¶æ€**: ğŸ”„ **åˆ›å»ºä¸­ - AI/MLäº‘åŸç”Ÿå·¥ä½œè´Ÿè½½**

---

(æ–‡æ¡£å°†ç»§ç»­æ·»åŠ ï¼šKServeæ¨¡å‹æœåŠ¡ã€MLOpsæµç¨‹ã€GPUå…±äº«è™šæ‹ŸåŒ–ã€åˆ†å¸ƒå¼è®­ç»ƒæœ€ä½³å®è·µã€å­˜å‚¨æ•°æ®ç®¡ç†ã€ç”Ÿäº§ç¯å¢ƒæ¡ˆä¾‹)
