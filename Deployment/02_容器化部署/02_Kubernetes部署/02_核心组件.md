# Kubernetes核心组件

> **返回**: [Kubernetes部署目录](README.md) | [容器化部署首页](../README.md) | [部署指南首页](../../00_索引导航/README.md)

---

## 📋 目录

- [Kubernetes核心组件](#kubernetes核心组件)
  - [📋 目录](#-目录)
  - [1. 组件架构概述](#1-组件架构概述)
  - [2. kube-apiserver](#2-kube-apiserver)
  - [3. etcd](#3-etcd)
  - [4. kube-controller-manager](#4-kube-controller-manager)
  - [5. kube-scheduler](#5-kube-scheduler)
  - [6. kubelet](#6-kubelet)
  - [7. kube-proxy](#7-kube-proxy)
  - [8. 组件通信与认证](#8-组件通信与认证)
  - [9. 组件监控与日志](#9-组件监控与日志)
  - [10. 性能调优](#10-性能调优)
  - [相关文档](#相关文档)

---

## 1. 组件架构概述

```yaml
Kubernetes_Architecture:
  控制平面组件 (Control Plane):
    kube-apiserver:
      作用: 集群API入口，RESTful接口
      端口: 6443
      高可用: 多实例负载均衡
    
    etcd:
      作用: 分布式键值存储，集群数据持久化
      端口: 2379 (客户端), 2380 (集群通信)
      高可用: 3/5/7节点集群
    
    kube-controller-manager:
      作用: 运行控制器，维护集群期望状态
      端口: 10257
      高可用: Leader选举
    
    kube-scheduler:
      作用: Pod调度器，分配Pod到节点
      端口: 10259
      高可用: Leader选举
    
    cloud-controller-manager (可选):
      作用: 云平台集成
      高可用: Leader选举
  
  节点组件 (Node Components):
    kubelet:
      作用: 节点代理，管理Pod生命周期
      端口: 10250
      每节点一个实例
    
    kube-proxy:
      作用: 网络代理，实现Service
      端口: 10256
      每节点一个实例
    
    Container Runtime:
      - containerd (推荐)
      - Docker Engine (deprecated)
      - CRI-O
  
  插件 (Addons):
    CoreDNS: 集群DNS
    CNI: 网络插件 (Calico, Flannel, Cilium)
    CSI: 存储插件 (Rook-Ceph, Longhorn)
    Metrics Server: 资源指标
    Dashboard: Web UI
    Ingress Controller: HTTP路由

  通信流程:
    kubectl -> kube-apiserver -> etcd (存储)
    kube-apiserver -> kubelet -> Container Runtime
    kube-scheduler -> kube-apiserver (调度决策)
    kube-controller-manager -> kube-apiserver (控制循环)
```

---

## 2. kube-apiserver

```yaml
kube_apiserver:
  功能:
    - 提供Kubernetes API
    - 认证、授权、准入控制
    - 数据验证和转换
    - 与etcd交互
    - 集群组件通信枢纽
  
  关键特性:
    RESTful API:
      - HTTP/HTTPS
      - JSON格式
      - 资源版本控制
    
    认证 (Authentication):
      - X509证书
      - Bearer Token
      - Basic Auth (不推荐)
      - OpenID Connect
      - Webhook Token
    
    授权 (Authorization):
      - RBAC (推荐)
      - ABAC
      - Node
      - Webhook
    
    准入控制 (Admission Control):
      - ValidatingAdmissionWebhook
      - MutatingAdmissionWebhook
      - ResourceQuota
      - LimitRanger
      - PodSecurityPolicy
  
  配置参数 (重要):
    基础配置:
      --advertise-address: API Server监听IP
      --bind-address: 绑定地址
      --secure-port: HTTPS端口 (默认6443)
      --insecure-port: HTTP端口 (已废弃)
    
    etcd配置:
      --etcd-servers: etcd服务器地址
      --etcd-cafile: etcd CA证书
      --etcd-certfile: etcd客户端证书
      --etcd-keyfile: etcd客户端密钥
    
    认证授权:
      --client-ca-file: 客户端CA证书
      --authorization-mode: 授权模式 (Node,RBAC)
      --enable-admission-plugins: 启用的准入插件
    
    性能优化:
      --max-requests-inflight: 最大并发请求数 (默认400)
      --max-mutating-requests-inflight: 最大变更请求 (默认200)
      --request-timeout: 请求超时时间 (默认60s)
    
    审计日志:
      --audit-log-path: 审计日志路径
      --audit-log-maxage: 日志保留天数
      --audit-log-maxsize: 单个日志文件大小
      --audit-policy-file: 审计策略文件
```

**API Server配置示例**:

```yaml
# /etc/kubernetes/manifests/kube-apiserver.yaml
apiVersion: v1
kind: Pod
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - name: kube-apiserver
    image: registry.k8s.io/kube-apiserver:v1.28.0
    command:
    - kube-apiserver
    - --advertise-address=192.168.1.10
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction,PodSecurityPolicy
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://127.0.0.1:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
    - --requestheader-allowed-names=front-proxy-client
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    # 性能优化
    - --max-requests-inflight=800
    - --max-mutating-requests-inflight=400
    # 审计日志
    - --audit-log-path=/var/log/kubernetes/audit.log
    - --audit-log-maxage=30
    - --audit-log-maxbackup=10
    - --audit-log-maxsize=100
    - --audit-policy-file=/etc/kubernetes/audit-policy.yaml
    volumeMounts:
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /var/log/kubernetes
      name: audit-log
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /var/log/kubernetes
      type: DirectoryOrCreate
    name: audit-log
```

**审计策略配置**:

```yaml
# /etc/kubernetes/audit-policy.yaml
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
  # 不记录只读请求
  - level: None
    verbs: ["get", "list", "watch"]
  
  # 不记录系统事件
  - level: None
    users: ["system:kube-proxy"]
    verbs: ["watch"]
    resources:
      - group: ""
        resources: ["endpoints", "services"]
  
  # 记录Secret的元数据
  - level: Metadata
    resources:
      - group: ""
        resources: ["secrets", "configmaps"]
  
  # 记录Pod变更的请求体
  - level: Request
    resources:
      - group: ""
        resources: ["pods"]
    verbs: ["create", "update", "patch", "delete"]
  
  # 默认记录元数据
  - level: Metadata
    omitStages:
      - "RequestReceived"
```

---

## 3. etcd

```yaml
etcd:
  作用:
    - 分布式键值存储
    - 存储所有集群数据
    - 一致性保证 (Raft算法)
    - 高可用
  
  关键特性:
    Raft共识算法:
      - Leader选举
      - 日志复制
      - 安全性保证
    
    数据模型:
      - 键值存储
      - 分层命名空间
      - 版本控制
      - Watch机制
    
    性能:
      - 写入延迟 < 10ms (本地SSD)
      - 每秒10,000次写入
      - 支持百万级键
  
  部署模式:
    堆叠etcd (Stacked):
      - etcd与控制平面组件同节点
      - 简化部署
      - 资源共享
      - 推荐3/5/7节点
    
    外部etcd (External):
      - etcd独立部署
      - 资源隔离
      - 更高可用性
      - 推荐大规模集群
  
  配置参数:
    基础配置:
      --name: 节点名称
      --data-dir: 数据目录
      --listen-client-urls: 客户端监听地址
      --advertise-client-urls: 客户端通告地址
      --listen-peer-urls: 集群通信监听地址
      --initial-advertise-peer-urls: 集群通信通告地址
    
    集群配置:
      --initial-cluster: 初始集群成员
      --initial-cluster-state: 集群状态 (new/existing)
      --initial-cluster-token: 集群令牌
    
    安全配置:
      --cert-file: 服务器证书
      --key-file: 服务器密钥
      --client-cert-auth: 启用客户端证书认证
      --trusted-ca-file: 客户端CA证书
      --peer-cert-file: 集群通信证书
      --peer-key-file: 集群通信密钥
    
    性能配置:
      --heartbeat-interval: 心跳间隔 (默认100ms)
      --election-timeout: 选举超时 (默认1000ms)
      --snapshot-count: 快照触发阈值 (默认100000)
      --quota-backend-bytes: 后端存储配额 (默认2GB)
```

**etcd集群配置示例**:

```bash
# etcd节点1
etcd \
  --name=etcd-1 \
  --data-dir=/var/lib/etcd \
  --listen-client-urls=https://192.168.1.10:2379 \
  --advertise-client-urls=https://192.168.1.10:2379 \
  --listen-peer-urls=https://192.168.1.10:2380 \
  --initial-advertise-peer-urls=https://192.168.1.10:2380 \
  --initial-cluster=etcd-1=https://192.168.1.10:2380,etcd-2=https://192.168.1.11:2380,etcd-3=https://192.168.1.12:2380 \
  --initial-cluster-state=new \
  --initial-cluster-token=etcd-cluster-1 \
  --cert-file=/etc/etcd/pki/server.crt \
  --key-file=/etc/etcd/pki/server.key \
  --client-cert-auth=true \
  --trusted-ca-file=/etc/etcd/pki/ca.crt \
  --peer-cert-file=/etc/etcd/pki/peer.crt \
  --peer-key-file=/etc/etcd/pki/peer.key \
  --peer-client-cert-auth=true \
  --peer-trusted-ca-file=/etc/etcd/pki/ca.crt
```

**etcd运维命令**:

```bash
# 设置etcdctl环境变量
export ETCDCTL_API=3
export ETCDCTL_ENDPOINTS=https://192.168.1.10:2379,https://192.168.1.11:2379,https://192.168.1.12:2379
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key

# 检查集群健康
etcdctl endpoint health

# 查看成员列表
etcdctl member list

# 查看集群状态
etcdctl endpoint status --write-out=table

# 备份etcd
etcdctl snapshot save /backup/etcd-snapshot-$(date +%Y%m%d-%H%M%S).db

# 恢复etcd (危险操作)
etcdctl snapshot restore snapshot.db \
  --name etcd-1 \
  --initial-cluster etcd-1=https://192.168.1.10:2380 \
  --initial-advertise-peer-urls https://192.168.1.10:2380 \
  --data-dir /var/lib/etcd-restored

# 碎片整理
etcdctl defrag --cluster

# 查看etcd数据大小
etcdctl endpoint status --write-out="json" | python -m json.tool
```

---

## 4. kube-controller-manager

```yaml
kube_controller_manager:
  作用:
    - 运行控制器
    - 维护集群期望状态
    - 响应集群变化
  
  内置控制器:
    Node Controller:
      - 监控节点健康
      - 节点状态更新
      - Pod驱逐
    
    Replication Controller:
      - 维护Pod副本数
      - 替换失败Pod
    
    Endpoints Controller:
      - 填充Endpoints对象
      - 连接Service和Pod
    
    Service Account Controller:
      - 创建默认ServiceAccount
      - 生成Token
    
    Namespace Controller:
      - 监听Namespace删除
      - 清理Namespace资源
    
    Deployment Controller:
      - 管理Deployment
      - 滚动更新
      - 回滚
    
    StatefulSet Controller:
      - 管理有状态应用
      - 顺序部署/删除
      - 持久化标识
    
    DaemonSet Controller:
      - 每个节点运行Pod
      - 节点增删自动调整
    
    Job Controller:
      - 运行一次性任务
      - 并行执行
    
    CronJob Controller:
      - 定时任务
      - Cron表达式
  
  配置参数:
    基础配置:
      --kubeconfig: kubeconfig文件路径
      --leader-elect: 启用Leader选举
      --leader-elect-lease-duration: Leader租约时长
    
    控制器配置:
      --controllers: 启用的控制器列表 (*表示所有)
      --node-monitor-period: 节点监控周期 (默认5s)
      --node-monitor-grace-period: 节点失联宽限期 (默认40s)
      --pod-eviction-timeout: Pod驱逐超时 (默认5m)
    
    资源配置:
      --concurrent-deployment-syncs: Deployment并发同步数
      --concurrent-replicaset-syncs: ReplicaSet并发同步数
      --concurrent-service-syncs: Service并发同步数
```

**Controller Manager配置**:

```yaml
# /etc/kubernetes/manifests/kube-controller-manager.yaml
apiVersion: v1
kind: Pod
metadata:
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - name: kube-controller-manager
    image: registry.k8s.io/kube-controller-manager:v1.28.0
    command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --cluster-cidr=10.244.0.0/16
    - --cluster-name=kubernetes
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/controller-manager.conf
    - --leader-elect=true
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --use-service-account-credentials=true
    # 节点监控配置
    - --node-monitor-period=5s
    - --node-monitor-grace-period=40s
    - --pod-eviction-timeout=5m0s
    # 性能优化
    - --concurrent-deployment-syncs=5
    - --concurrent-replicaset-syncs=5
    - --concurrent-service-syncs=2
    volumeMounts:
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /etc/kubernetes/controller-manager.conf
      name: kubeconfig
      readOnly: true
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/controller-manager.conf
      type: FileOrCreate
    name: kubeconfig
```

---

## 5. kube-scheduler

```yaml
kube_scheduler:
  作用:
    - 为新创建的Pod选择节点
    - 考虑资源需求、约束、亲和性
    - 实现公平调度
  
  调度流程:
    1. 预选 (Predicate):
      - 过滤不符合条件的节点
      - 检查资源是否充足
      - 检查节点选择器
      - 检查污点/容忍
    
    2. 优选 (Priority):
      - 对预选节点打分
      - 资源平衡
      - 镜像本地性
      - 亲和性/反亲和性
    
    3. 绑定 (Bind):
      - 选择得分最高的节点
      - 更新etcd
  
  调度策略:
    资源调度:
      - CPU请求/限制
      - 内存请求/限制
      - 临时存储
      - 扩展资源 (GPU)
    
    亲和性调度:
      NodeAffinity: 节点亲和性
      PodAffinity: Pod亲和性
      PodAntiAffinity: Pod反亲和性
    
    污点和容忍:
      Taint: 节点拒绝Pod
      Toleration: Pod容忍污点
    
    拓扑域:
      - 故障域 (zone)
      - 主机域 (hostname)
      - 自定义域
  
  配置参数:
    基础配置:
      --kubeconfig: kubeconfig文件
      --leader-elect: Leader选举
      --bind-address: 监听地址
    
    调度配置:
      --config: 调度器配置文件
      --feature-gates: 功能开关
```

**Scheduler配置示例**:

```yaml
# scheduler-config.yaml
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
clientConnection:
  kubeconfig: /etc/kubernetes/scheduler.conf
leaderElection:
  leaderElect: true
profiles:
- schedulerName: default-scheduler
  plugins:
    # 预选插件
    filter:
      enabled:
      - name: NodeResourcesFit
      - name: NodeAffinity
      - name: PodTopologySpread
      - name: TaintToleration
    # 优选插件
    score:
      enabled:
      - name: NodeResourcesBalancedAllocation
        weight: 1
      - name: ImageLocality
        weight: 1
      - name: InterPodAffinity
        weight: 1
```

---

## 6. kubelet

```yaml
kubelet:
  作用:
    - 节点代理
    - 管理Pod和容器
    - 上报节点和Pod状态
    - 容器健康检查
  
  核心功能:
    Pod管理:
      - 接收PodSpec
      - 创建/删除容器
      - 挂载卷
      - 网络配置
    
    容器生命周期:
      - 启动容器
      - 停止容器
      - 重启失败容器
      - 执行生命周期钩子
    
    健康检查:
      Liveness Probe: 存活探针
      Readiness Probe: 就绪探针
      Startup Probe: 启动探针
    
    资源管理:
      - 资源预留
      - Pod QoS
      - 资源限制
      - 驱逐策略
    
    卷管理:
      - 挂载卷
      - 卷清理
      - Secret/ConfigMap
  
  配置参数:
    基础配置:
      --config: kubelet配置文件
      --kubeconfig: kubeconfig文件
      --container-runtime-endpoint: CRI端点
    
    节点配置:
      --hostname-override: 覆盖主机名
      --node-ip: 节点IP
      --node-labels: 节点标签
    
    资源配置:
      --kube-reserved: Kubernetes组件预留资源
      --system-reserved: 系统进程预留资源
      --eviction-hard: 硬驱逐阈值
      --eviction-soft: 软驱逐阈值
    
    网络配置:
      --network-plugin: 网络插件
      --cni-conf-dir: CNI配置目录
      --cni-bin-dir: CNI二进制目录
```

**Kubelet配置**:

```yaml
# /var/lib/kubelet/config.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
address: 0.0.0.0
port: 10250
readOnlyPort: 0
authentication:
  anonymous:
    enabled: false
  webhook:
    enabled: true
  x509:
    clientCAFile: /etc/kubernetes/pki/ca.crt
authorization:
  mode: Webhook
cgroupDriver: systemd
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerLogMaxSize: 10Mi
containerLogMaxFiles: 5
# 资源预留
kubeReserved:
  cpu: "500m"
  memory: "1Gi"
  ephemeral-storage: "1Gi"
systemReserved:
  cpu: "500m"
  memory: "1Gi"
  ephemeral-storage: "1Gi"
# 驱逐策略
evictionHard:
  memory.available: "100Mi"
  nodefs.available: "10%"
  nodefs.inodesFree: "5%"
  imagefs.available: "15%"
evictionSoft:
  memory.available: "200Mi"
  nodefs.available: "15%"
evictionSoftGracePeriod:
  memory.available: "1m30s"
  nodefs.available: "2m"
# 资源管理
maxPods: 110
podPidsLimit: -1
# 容器运行时
containerRuntimeEndpoint: unix:///var/run/containerd/containerd.sock
```

---

## 7. kube-proxy

```yaml
kube_proxy:
  作用:
    - 实现Service抽象
    - 负载均衡
    - 网络代理
  
  代理模式:
    userspace (已废弃):
      - 用户空间代理
      - 性能差
      - 不推荐
    
    iptables:
      - 基于iptables规则
      - 随机负载均衡
      - 性能中等
      - 默认模式
    
    ipvs (推荐):
      - 基于内核IPVS
      - 支持多种负载均衡算法
      - 性能最好
      - 推荐生产环境
  
  负载均衡算法 (IPVS模式):
    rr: Round Robin (轮询)
    lc: Least Connection (最少连接)
    dh: Destination Hashing
    sh: Source Hashing
    sed: Shortest Expected Delay
    nq: Never Queue
  
  配置参数:
    --proxy-mode: 代理模式 (iptables/ipvs)
    --cluster-cidr: 集群Pod CIDR
    --kubeconfig: kubeconfig文件
    --ipvs-scheduler: IPVS调度算法
```

**Kube-proxy配置 (IPVS模式)**:

```yaml
# /var/lib/kube-proxy/config.yaml
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
bindAddress: 0.0.0.0
clientConnection:
  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
clusterCIDR: 10.244.0.0/16
mode: ipvs
ipvs:
  scheduler: rr
  syncPeriod: 30s
  minSyncPeriod: 5s
iptables:
  masqueradeAll: false
  masqueradeBit: 14
  minSyncPeriod: 0s
  syncPeriod: 30s
```

```bash
# 启用IPVS模块
modprobe ip_vs
modprobe ip_vs_rr
modprobe ip_vs_wrr
modprobe ip_vs_sh
modprobe nf_conntrack

# 验证IPVS规则
ipvsadm -Ln
```

---

## 8. 组件通信与认证

```yaml
Component_Communication:
  通信方式:
    kubectl -> API Server:
      - TLS加密
      - 客户端证书认证
      - 或Bearer Token
    
    kubelet -> API Server:
      - TLS加密
      - 客户端证书认证
      - 双向认证
    
    API Server -> kubelet:
      - TLS加密
      - API Server作为客户端
      - kubelet验证请求
    
    API Server -> etcd:
      - TLS加密
      - 双向证书认证
      - 客户端证书
  
  证书管理:
    证书类型:
      - CA证书: 集群根证书
      - API Server证书
      - Kubelet证书
      - etcd证书
      - Front Proxy证书
      - Service Account密钥对
    
    证书路径:
      /etc/kubernetes/pki/:
        - ca.crt / ca.key
        - apiserver.crt / apiserver.key
        - apiserver-kubelet-client.crt/key
        - front-proxy-ca.crt / front-proxy-ca.key
        - front-proxy-client.crt/key
        - sa.pub / sa.key
      
      /etc/kubernetes/pki/etcd/:
        - ca.crt / ca.key
        - server.crt / server.key
        - peer.crt / peer.key
        - healthcheck-client.crt/key
        - apiserver-etcd-client.crt/key
    
    证书续期:
      # 查看证书过期时间
      kubeadm certs check-expiration
      
      # 续期所有证书
      kubeadm certs renew all
      
      # 续期特定证书
      kubeadm certs renew apiserver
```

---

## 9. 组件监控与日志

```bash
# ========================================
# 组件监控
# ========================================

# 查看组件状态
kubectl get componentstatuses

# 查看API Server日志
journalctl -u kube-apiserver -f

# 查看Controller Manager日志
kubectl logs -n kube-system kube-controller-manager-master01

# 查看Scheduler日志
kubectl logs -n kube-system kube-scheduler-master01

# 查看kubelet日志
journalctl -u kubelet -f

# 查看kube-proxy日志
kubectl logs -n kube-system kube-proxy-xxxxx

# ========================================
# Prometheus监控
# ========================================

# API Server指标
curl -k https://localhost:6443/metrics

# Controller Manager指标
curl -k https://localhost:10257/metrics

# Scheduler指标
curl -k https://localhost:10259/metrics

# Kubelet指标
curl -k https://localhost:10250/metrics

# Kube-proxy指标
curl http://localhost:10256/metrics
```

---

## 10. 性能调优

```yaml
Performance_Tuning:
  API Server:
    并发优化:
      --max-requests-inflight=800
      --max-mutating-requests-inflight=400
    
    Watch缓存:
      --watch-cache-sizes: 调整Watch缓存大小
    
    etcd优化:
      --etcd-compaction-interval: 压缩间隔
  
  etcd:
    存储优化:
      --quota-backend-bytes=8GB  # 增加存储配额
      定期压缩和碎片整理
    
    网络优化:
      --heartbeat-interval=100ms
      --election-timeout=1000ms
      使用SSD存储
      专用网络
  
  Kubelet:
    并发优化:
      --max-pods=110  # 每节点最大Pod数
      --pod-max-pids=-1  # Pod进程数限制
    
    镜像拉取:
      --serialize-image-pulls=false  # 并行拉取
      --image-pull-progress-deadline=2m
    
    驱逐优化:
      合理设置eviction阈值
      预留足够资源
  
  Kube-proxy:
    IPVS模式:
      mode: ipvs
      启用conntrack调优
    
    内核参数:
      net.ipv4.ip_forward=1
      net.bridge.bridge-nf-call-iptables=1
      net.ipv4.conf.all.forwarding=1
      net.netfilter.nf_conntrack_max=1000000
```

---

## 相关文档

- [Kubernetes集群部署](01_集群部署.md)
- [Kubernetes应用部署](03_应用部署.md)
- [Kubernetes资源管理](04_资源管理.md)
- [Kubernetes故障排查](05_故障排查.md)
- [Kubernetes高可用架构](../../01_虚拟化部署/05_高可用容灾/02_Kubernetes高可用架构.md)

---

**更新时间**: 2025-10-19  
**文档版本**: v1.0  
**状态**: ✅ 生产就绪
