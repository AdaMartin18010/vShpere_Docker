# Kubernetes集群部署

> **返回**: [Kubernetes部署目录](README.md) | [容器化部署首页](../README.md) | [部署指南首页](../../00_索引导航/README.md)

---

## 📋 目录

- [Kubernetes集群部署](#kubernetes集群部署)
  - [📋 目录](#-目录)
  - [1. Kubernetes概述](#1-kubernetes概述)
  - [2. 部署前准备](#2-部署前准备)
  - [3. kubeadm部署](#3-kubeadm部署)
    - [3.1 单Master节点部署](#31-单master节点部署)
    - [3.2 高可用集群部署](#32-高可用集群部署)
  - [4. 二进制部署](#4-二进制部署)
  - [5. 云厂商托管Kubernetes](#5-云厂商托管kubernetes)
  - [6. 轻量级Kubernetes](#6-轻量级kubernetes)
  - [7. 集群验证](#7-集群验证)
  - [8. 部署最佳实践](#8-部署最佳实践)
  - [相关文档](#相关文档)

---

## 1. Kubernetes概述

```yaml
Kubernetes_Overview:
  定义:
    - 容器编排平台
    - 自动化部署、扩展和管理容器化应用
    - Google开源，CNCF托管
    - 希腊语：舵手、飞行员
  
  核心架构:
    Control Plane (控制平面):
      kube-apiserver:
        - 集群API入口
        - RESTful API
        - 认证、授权、准入控制
      
      etcd:
        - 分布式键值存储
        - 集群数据持久化
        - 一致性保证
      
      kube-scheduler:
        - Pod调度器
        - 资源匹配
        - 调度策略
      
      kube-controller-manager:
        - 控制器管理器
        - Node Controller
        - Replication Controller
        - Endpoints Controller
        - Service Account Controller
      
      cloud-controller-manager (可选):
        - 云平台集成
        - Node、Route、Service管理
    
    Node (工作节点):
      kubelet:
        - 节点代理
        - Pod生命周期管理
        - 容器健康检查
      
      kube-proxy:
        - 网络代理
        - 服务负载均衡
        - iptables/ipvs规则
      
      Container Runtime:
        - Docker
        - containerd (推荐)
        - CRI-O
  
  核心概念:
    Pod: 最小部署单元
    Deployment: 无状态应用部署
    StatefulSet: 有状态应用部署
    DaemonSet: 每个节点一个Pod
    Service: 服务发现和负载均衡
    Ingress: HTTP/HTTPS路由
    ConfigMap: 配置管理
    Secret: 密钥管理
    PersistentVolume: 持久化存储
    Namespace: 命名空间隔离
  
  版本说明:
    当前稳定版: v1.28
    推荐版本: v1.27.x (LTS)
    支持周期: 约14个月
    升级策略: 小版本逐步升级
```

---

## 2. 部署前准备

```yaml
Pre_Deployment_Checklist:
  硬件要求:
    Master节点:
      最小配置:
        CPU: 2核
        内存: 4GB
        磁盘: 50GB
      
      推荐配置:
        CPU: 4核+
        内存: 8GB+
        磁盘: 100GB+ SSD
    
    Worker节点:
      最小配置:
        CPU: 2核
        内存: 4GB
        磁盘: 50GB
      
      推荐配置:
        CPU: 8核+
        内存: 16GB+
        磁盘: 200GB+ SSD
    
    etcd节点 (独立部署时):
      CPU: 2核+
      内存: 8GB+
      磁盘: 50GB+ SSD (低延迟)
  
  操作系统要求:
    推荐系统:
      - Ubuntu 20.04 LTS / 22.04 LTS
      - CentOS Stream 8 / 9
      - RHEL 8 / 9
      - Rocky Linux 8 / 9
      - 麒麟 V10
      - openEuler 20.03 LTS / 22.03 LTS
    
    内核要求:
      最低: 4.19
      推荐: 5.4+
  
  网络要求:
    节点间网络:
      - 延迟 < 10ms (同数据中心)
      - 带宽 >= 1Gbps
      - 所有节点互通
    
    端口要求:
      Master节点:
        - 6443: kube-apiserver
        - 2379-2380: etcd
        - 10250: kubelet
        - 10251: kube-scheduler
        - 10252: kube-controller-manager
      
      Worker节点:
        - 10250: kubelet
        - 30000-32767: NodePort Services
    
    Pod网络:
      - 10.244.0.0/16 (Flannel默认)
      - 192.168.0.0/16 (Calico默认)
      - 可自定义
    
    Service网络:
      - 10.96.0.0/12 (默认)
      - 可自定义
  
  软件要求:
    容器运行时:
      - containerd >= 1.6 (推荐)
      - Docker >= 20.10
      - CRI-O >= 1.24
    
    必需工具:
      - kubeadm
      - kubelet
      - kubectl
    
    可选工具:
      - Helm >= 3.0
      - ctr / crictl
```

**系统初始化脚本**:

```bash
#!/bin/bash
# ========================================
# Kubernetes节点系统初始化脚本
# ========================================

set -e

echo "===== Kubernetes节点初始化 ====="

# 1. 关闭防火墙 (或配置规则)
systemctl stop firewalld
systemctl disable firewalld

# 2. 关闭SELinux
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# 3. 关闭swap
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# 4. 配置内核参数
cat <<EOF | tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter

cat <<EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sysctl --system

# 5. 配置时间同步
yum install -y chrony
systemctl enable chronyd
systemctl start chronyd

# 6. 配置主机名和hosts
# 需要手动设置
# hostnamectl set-hostname k8s-master01
# cat >> /etc/hosts << EOF
# 192.168.1.10 k8s-master01
# 192.168.1.11 k8s-master02
# 192.168.1.12 k8s-master03
# 192.168.1.20 k8s-node01
# EOF

echo "✅ 系统初始化完成！"
echo "请手动配置主机名和hosts文件"
```

---

## 3. kubeadm部署

### 3.1 单Master节点部署

```bash
#!/bin/bash
# ========================================
# kubeadm单Master节点部署脚本 (Ubuntu/Debian)
# ========================================

set -e

K8S_VERSION="1.28"
CONTAINERD_VERSION="1.7.8"

echo "===== Kubernetes单Master节点部署 ====="

# ========================================
# 步骤1: 安装containerd
# ========================================

echo "➤ 安装containerd..."

# 安装依赖
apt-get update
apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release

# 下载containerd
wget https://github.com/containerd/containerd/releases/download/v${CONTAINERD_VERSION}/containerd-${CONTAINERD_VERSION}-linux-amd64.tar.gz
tar Cxzvf /usr/local containerd-${CONTAINERD_VERSION}-linux-amd64.tar.gz

# 安装systemd service
mkdir -p /usr/local/lib/systemd/system
wget -O /usr/local/lib/systemd/system/containerd.service \
  https://raw.githubusercontent.com/containerd/containerd/main/containerd.service

systemctl daemon-reload
systemctl enable --now containerd

# 配置containerd
mkdir -p /etc/containerd
containerd config default | tee /etc/containerd/config.toml

# 修改配置使用systemd cgroup
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml

# 重启containerd
systemctl restart containerd

echo "✅ containerd安装完成"

# ========================================
# 步骤2: 安装runc
# ========================================

echo "➤ 安装runc..."
wget https://github.com/opencontainers/runc/releases/download/v1.1.10/runc.amd64
install -m 755 runc.amd64 /usr/local/sbin/runc
echo "✅ runc安装完成"

# ========================================
# 步骤3: 安装CNI插件
# ========================================

echo "➤ 安装CNI插件..."
wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz
mkdir -p /opt/cni/bin
tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.3.0.tgz
echo "✅ CNI插件安装完成"

# ========================================
# 步骤4: 安装kubeadm、kubelet、kubectl
# ========================================

echo "➤ 安装kubeadm、kubelet、kubectl..."

# 添加Kubernetes apt源
curl -fsSL https://pkgs.k8s.io/core:/stable:/v${K8S_VERSION}/deb/Release.key | \
  gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v${K8S_VERSION}/deb/ /" | \
  tee /etc/apt/sources.list.d/kubernetes.list

# 安装
apt-get update
apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl

# 启动kubelet
systemctl enable kubelet

echo "✅ kubeadm、kubelet、kubectl安装完成"

# ========================================
# 步骤5: 初始化Master节点
# ========================================

echo "➤ 初始化Kubernetes Master节点..."

kubeadm init \
  --pod-network-cidr=10.244.0.0/16 \
  --service-cidr=10.96.0.0/12 \
  --kubernetes-version=v${K8S_VERSION}.0

echo "✅ Master节点初始化完成"

# ========================================
# 步骤6: 配置kubectl
# ========================================

echo "➤ 配置kubectl..."

mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

echo "✅ kubectl配置完成"

# ========================================
# 步骤7: 安装CNI网络插件 (Flannel)
# ========================================

echo "➤ 安装Flannel CNI..."

kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

echo "✅ Flannel CNI安装完成"

# ========================================
# 步骤8: 验证集群
# ========================================

echo "➤ 验证集群状态..."
sleep 30
kubectl get nodes
kubectl get pods -A

echo ""
echo "========================================="
echo "✅ Kubernetes单Master节点部署完成！"
echo "========================================="
echo ""
echo "集群信息:"
kubectl cluster-info
echo ""
echo "Worker节点加入命令:"
kubeadm token create --print-join-command
echo ""
echo "========================================="
```

**CentOS/RHEL版本安装脚本**:

```bash
#!/bin/bash
# ========================================
# kubeadm单Master节点部署脚本 (CentOS/RHEL)
# ========================================

set -e

K8S_VERSION="1.28"

echo "===== Kubernetes单Master节点部署 (CentOS/RHEL) ====="

# 1. 安装containerd
echo "➤ 安装containerd..."
yum install -y yum-utils
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum install -y containerd.io

# 配置containerd
mkdir -p /etc/containerd
containerd config default | tee /etc/containerd/config.toml
sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml

systemctl enable --now containerd

# 2. 添加Kubernetes yum源
cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://pkgs.k8s.io/core:/stable:/v${K8S_VERSION}/rpm/
enabled=1
gpgcheck=1
gpgkey=https://pkgs.k8s.io/core:/stable:/v${K8S_VERSION}/rpm/repodata/repomd.xml.key
EOF

# 3. 安装kubeadm、kubelet、kubectl
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable kubelet

# 4. 初始化Master节点
kubeadm init \
  --pod-network-cidr=10.244.0.0/16 \
  --service-cidr=10.96.0.0/12 \
  --kubernetes-version=v${K8S_VERSION}.0

# 5. 配置kubectl
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

# 6. 安装Flannel
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

echo "✅ Kubernetes部署完成！"
kubectl get nodes
```

### 3.2 高可用集群部署

```yaml
# ========================================
# 高可用集群架构
# ========================================

HA_Architecture:
  拓扑结构:
    负载均衡层:
      - HAProxy + Keepalived
      - 或云厂商LB (AWS ELB, Azure LB)
      - VIP: 192.168.1.100
    
    Master节点:
      - k8s-master01: 192.168.1.10
      - k8s-master02: 192.168.1.11
      - k8s-master03: 192.168.1.12
    
    Worker节点:
      - k8s-node01: 192.168.1.20
      - k8s-node02: 192.168.1.21
      - k8s-node03: 192.168.1.22
    
    etcd集群:
      - 与Master节点部署 (堆叠模式)
      - 或独立部署 (外部etcd)
  
  高可用要点:
    - 奇数个Master节点 (3/5/7)
    - etcd集群 (3/5节点)
    - 负载均衡器高可用
    - 多个Worker节点
```

**HAProxy + Keepalived配置**:

```bash
# ========================================
# HAProxy + Keepalived 部署 (两台LB服务器)
# ========================================

# 安装HAProxy和Keepalived
yum install -y haproxy keepalived

# ========================================
# HAProxy配置 (/etc/haproxy/haproxy.cfg)
# ========================================

cat > /etc/haproxy/haproxy.cfg << 'EOF'
global
    log /dev/log local0
    log /dev/log local1 notice
    chroot /var/lib/haproxy
    stats socket /run/haproxy/admin.sock mode 660 level admin
    stats timeout 30s
    user haproxy
    group haproxy
    daemon

defaults
    log     global
    mode    tcp
    option  tcplog
    option  dontlognull
    timeout connect 5000
    timeout client  50000
    timeout server  50000

frontend k8s-apiserver
    bind *:6443
    mode tcp
    option tcplog
    default_backend k8s-master-nodes

backend k8s-master-nodes
    mode tcp
    balance roundrobin
    option tcp-check
    server master01 192.168.1.10:6443 check inter 2000 rise 2 fall 3
    server master02 192.168.1.11:6443 check inter 2000 rise 2 fall 3
    server master03 192.168.1.12:6443 check inter 2000 rise 2 fall 3

listen stats
    bind *:9999
    mode http
    stats enable
    stats uri /haproxy-stats
    stats refresh 30s
    stats admin if TRUE
EOF

# 启动HAProxy
systemctl enable haproxy
systemctl start haproxy

# ========================================
# Keepalived配置 (/etc/keepalived/keepalived.conf)
# ========================================

# 主LB服务器配置
cat > /etc/keepalived/keepalived.conf << 'EOF'
! Configuration File for keepalived

global_defs {
   router_id LB01
}

vrrp_script check_haproxy {
    script "/usr/bin/killall -0 haproxy"
    interval 2
    weight 2
}

vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.1.100
    }
    track_script {
        check_haproxy
    }
}
EOF

# 备LB服务器配置 (修改state为BACKUP, priority为90)

# 启动Keepalived
systemctl enable keepalived
systemctl start keepalived

# 验证VIP
ip addr show eth0
```

**高可用集群初始化**:

```bash
#!/bin/bash
# ========================================
# 高可用Kubernetes集群初始化
# ========================================

LOAD_BALANCER_DNS="k8s-lb.example.com"
LOAD_BALANCER_IP="192.168.1.100"
LOAD_BALANCER_PORT="6443"
POD_SUBNET="10.244.0.0/16"
SERVICE_SUBNET="10.96.0.0/12"
K8S_VERSION="1.28.0"

# ========================================
# 第一个Master节点初始化
# ========================================

cat > kubeadm-config.yaml << EOF
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: v${K8S_VERSION}
controlPlaneEndpoint: "${LOAD_BALANCER_IP}:${LOAD_BALANCER_PORT}"
networking:
  podSubnet: ${POD_SUBNET}
  serviceSubnet: ${SERVICE_SUBNET}
apiServer:
  certSANs:
    - "${LOAD_BALANCER_IP}"
    - "${LOAD_BALANCER_DNS}"
    - "192.168.1.10"
    - "192.168.1.11"
    - "192.168.1.12"
    - "k8s-master01"
    - "k8s-master02"
    - "k8s-master03"
etcd:
  local:
    dataDir: /var/lib/etcd
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.1.10
  bindPort: 6443
EOF

# 初始化第一个Master
kubeadm init --config=kubeadm-config.yaml --upload-certs

# 保存输出的join命令

# 配置kubectl
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

# 安装CNI
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

# ========================================
# 其他Master节点加入
# ========================================

# 在master02和master03上执行kubeadm init输出的join命令
# kubeadm join 192.168.1.100:6443 --token ... \
#   --discovery-token-ca-cert-hash sha256:... \
#   --control-plane --certificate-key ...

# ========================================
# Worker节点加入
# ========================================

# 在worker节点上执行
# kubeadm join 192.168.1.100:6443 --token ... \
#   --discovery-token-ca-cert-hash sha256:...

echo "✅ 高可用Kubernetes集群部署完成！"
kubectl get nodes
kubectl get pods -A
```

---

## 4. 二进制部署

```yaml
Binary_Deployment_Overview:
  优势:
    - 完全可控
    - 自定义配置
    - 深入理解
    - 灵活性高
  
  劣势:
    - 复杂度高
    - 维护成本高
    - 升级困难
  
  适用场景:
    - 学习研究
    - 特殊定制需求
    - 对集群有深入控制需求
  
  部署步骤概览:
    1. 下载二进制文件
    2. 生成证书
    3. 配置etcd集群
    4. 配置kube-apiserver
    5. 配置kube-controller-manager
    6. 配置kube-scheduler
    7. 配置kubelet
    8. 配置kube-proxy
    9. 配置CNI网络
```

**二进制部署脚本骨架** (完整脚本较长，这里提供结构):

```bash
#!/bin/bash
# ========================================
# Kubernetes二进制部署脚本 (简化版)
# ========================================

# 1. 下载二进制文件
K8S_VERSION="1.28.0"
wget https://dl.k8s.io/v${K8S_VERSION}/kubernetes-server-linux-amd64.tar.gz
tar -xzf kubernetes-server-linux-amd64.tar.gz

# 2. 生成证书 (使用cfssl工具)
# 详见完整脚本...

# 3. 部署etcd集群
# 详见完整脚本...

# 4. 部署Master组件
# - kube-apiserver
# - kube-controller-manager
# - kube-scheduler

# 5. 部署Node组件
# - kubelet
# - kube-proxy

# 6. 部署CNI网络插件

echo "二进制部署完成"
```

---

## 5. 云厂商托管Kubernetes

```yaml
Managed_Kubernetes:
  AWS_EKS:
    特点:
      - 完全托管的控制平面
      - 自动升级和补丁
      - 集成AWS服务
    
    部署:
      使用eksctl:
        bash
        eksctl create cluster \
          --name my-cluster \
          --region us-west-2 \
          --nodegroup-name standard-workers \
          --node-type t3.medium \
          --nodes 3 \
          --nodes-min 1 \
          --nodes-max 4
    
    成本:
      - 控制平面: $0.10/小时
      - Worker节点: EC2定价
  
  Azure_AKS:
    特点:
      - 托管控制平面
      - 免费控制平面
      - Azure DevOps集成
    
    部署:
      bash
      az aks create \
        --resource-group myResourceGroup \
        --name myAKSCluster \
        --node-count 3 \
        --enable-addons monitoring \
        --generate-ssh-keys
    
    成本:
      - 控制平面: 免费
      - Worker节点: VM定价
  
  Google_GKE:
    特点:
      - 最早的托管K8s
      - 自动修复和升级
      - 区域集群
    
    部署:
      bash
      gcloud container clusters create my-cluster \
        --zone us-central1-a \
        --num-nodes 3 \
        --machine-type n1-standard-2
    
    成本:
      - 控制平面: $0.10/小时 (Autopilot免费)
      - Worker节点: GCE定价
  
  阿里云_ACK:
    特点:
      - 完全托管
      - 安全容器
      - 中国区域优化
    
    部署:
      通过控制台或CLI
    
    成本:
      - 专有版: ¥0.42/小时
      - 托管版: 免费
  
  腾讯云_TKE:
    部署: 通过控制台或TKE CLI
    成本: 托管版免费
  
  华为云_CCE:
    部署: 通过控制台或CLI
    成本: 托管版免费
```

---

## 6. 轻量级Kubernetes

```yaml
Lightweight_Kubernetes:
  K3s:
    特点:
      - 单二进制文件 < 100MB
      - 适合边缘、IoT、CI
      - 包含Traefik、LocalPath
    
    部署:
      bash
      # Server节点
      curl -sfL https://get.k3s.io | sh -
      
      # Agent节点
      curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 \
        K3S_TOKEN=mynodetoken sh -
    
    适用场景:
      - 边缘计算
      - 开发测试
      - 资源受限环境
  
  MicroK8s:
    特点:
      - Snap包管理
      - 快速安装
      - Canonical维护
    
    部署:
      bash
      sudo snap install microk8s --classic
      sudo microk8s enable dns storage
    
    适用场景:
      - 开发环境
      - CI/CD
      - Ubuntu系统
  
  Kind (Kubernetes in Docker):
    特点:
      - Docker容器中运行K8s
      - 快速创建/销毁
      - CI测试
    
    部署:
      bash
      kind create cluster --name my-cluster
    
    适用场景:
      - 本地开发
      - CI测试
      - 学习实验
  
  Minikube:
    特点:
      - 单机Kubernetes
      - 多种驱动 (Docker, VirtualBox, KVM)
      - 丰富插件
    
    部署:
      bash
      minikube start --cpus=4 --memory=8192
    
    适用场景:
      - 本地开发
      - 学习K8s
      - 快速实验
```

---

## 7. 集群验证

```bash
#!/bin/bash
# ========================================
# Kubernetes集群验证脚本
# ========================================

echo "===== Kubernetes集群验证 ====="

# 1. 检查节点状态
echo -e "\n➤ 节点状态:"
kubectl get nodes -o wide

# 2. 检查系统Pod
echo -e "\n➤ 系统Pod状态:"
kubectl get pods -n kube-system

# 3. 检查组件健康
echo -e "\n➤ 组件健康状态:"
kubectl get cs

# 4. 检查集群信息
echo -e "\n➤ 集群信息:"
kubectl cluster-info

# 5. 测试DNS
echo -e "\n➤ 测试DNS:"
kubectl run test-dns --image=busybox:1.28 --rm -it --restart=Never -- nslookup kubernetes.default

# 6. 测试Pod网络
echo -e "\n➤ 测试Pod创建:"
kubectl run nginx --image=nginx:alpine
sleep 10
kubectl get pod nginx
kubectl delete pod nginx

# 7. 测试Service
echo -e "\n➤ 测试Service:"
kubectl create deployment nginx --image=nginx:alpine --replicas=2
kubectl expose deployment nginx --port=80
sleep 10
kubectl get svc nginx
kubectl delete svc nginx
kubectl delete deployment nginx

# 8. 检查资源使用
echo -e "\n➤ 节点资源使用:"
kubectl top nodes

echo -e "\n✅ 集群验证完成！"
```

---

## 8. 部署最佳实践

```yaml
Deployment_Best_Practices:
  规划阶段:
    ✅ 容量规划:
      - 预估Pod数量
      - 预估资源需求
      - 预留30%冗余
    
    ✅ 网络规划:
      - Pod CIDR不与现有网络冲突
      - Service CIDR独立规划
      - 考虑未来扩展
    
    ✅ 高可用设计:
      - 至少3个Master节点
      - 跨可用区部署
      - 负载均衡器冗余
  
  安装阶段:
    ✅ 版本选择:
      - 使用稳定版本
      - 避免.0版本
      - 查看Release Notes
    
    ✅ 组件配置:
      - 合理的资源限制
      - 启用审计日志
      - 配置备份策略
    
    ✅ 安全加固:
      - RBAC权限控制
      - Pod Security Policy
      - Network Policy
      - Secret加密
  
  运维阶段:
    ✅ 监控告警:
      - 部署Prometheus
      - 配置Grafana
      - 设置告警规则
    
    ✅ 日志管理:
      - 集中式日志 (EFK)
      - 日志轮转
      - 日志查询
    
    ✅ 备份策略:
      - etcd定期备份
      - 配置文件备份
      - PV数据备份
    
    ✅ 升级策略:
      - 测试环境验证
      - 滚动升级
      - 回滚计划
```

---

## 相关文档

- [Kubernetes核心组件](02_核心组件.md)
- [Kubernetes应用部署](03_应用部署.md)
- [Kubernetes资源管理](04_资源管理.md)
- [Kubernetes高可用架构](../../01_虚拟化部署/05_高可用容灾/02_Kubernetes高可用架构.md)
- [容器网络配置](../03_容器网络/README.md)
- [容器存储配置](../04_容器存储/README.md)

---

**更新时间**: 2025-10-19  
**文档版本**: v1.0  
**状态**: ✅ 生产就绪
