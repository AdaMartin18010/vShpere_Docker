# å­˜å‚¨æ€§èƒ½ä¼˜åŒ–ç»¼åˆæŒ‡å—

> **è¿”å›**: [å­˜å‚¨æ¶æ„ç›®å½•](README.md) | [è™šæ‹ŸåŒ–éƒ¨ç½²é¦–é¡µ](../README.md) | [éƒ¨ç½²æŒ‡å—é¦–é¡µ](../../00_ç´¢å¼•å¯¼èˆª/README.md)

---

## ğŸ“‹ ç›®å½•

- [å­˜å‚¨æ€§èƒ½ä¼˜åŒ–ç»¼åˆæŒ‡å—](#å­˜å‚¨æ€§èƒ½ä¼˜åŒ–ç»¼åˆæŒ‡å—)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ€§èƒ½ä¼˜åŒ–æ¦‚è¿°](#æ€§èƒ½ä¼˜åŒ–æ¦‚è¿°)
  - [ç¡¬ä»¶å±‚æ€§èƒ½ä¼˜åŒ–](#ç¡¬ä»¶å±‚æ€§èƒ½ä¼˜åŒ–)
  - [æ“ä½œç³»ç»Ÿå±‚ä¼˜åŒ–](#æ“ä½œç³»ç»Ÿå±‚ä¼˜åŒ–)
  - [è™šæ‹ŸåŒ–å±‚ä¼˜åŒ–](#è™šæ‹ŸåŒ–å±‚ä¼˜åŒ–)
  - [ç½‘ç»œå±‚ä¼˜åŒ–](#ç½‘ç»œå±‚ä¼˜åŒ–)
  - [å­˜å‚¨åè®®ä¼˜åŒ–](#å­˜å‚¨åè®®ä¼˜åŒ–)
  - [åº”ç”¨å±‚ä¼˜åŒ–](#åº”ç”¨å±‚ä¼˜åŒ–)
  - [æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†](#æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†)
  - [ç›‘æ§ä¸è¯Šæ–­](#ç›‘æ§ä¸è¯Šæ–­)
  - [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
  - [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)

---

## æ€§èƒ½ä¼˜åŒ–æ¦‚è¿°

```yaml
æ€§èƒ½æŒ‡æ ‡ä½“ç³»:
  IOPS (æ¯ç§’IOæ“ä½œæ•°):
    å®šä¹‰: Input/Output Operations Per Second
    ç±»å‹:
      éšæœºè¯»IOPS: æ•°æ®åº“æŸ¥è¯¢
      éšæœºå†™IOPS: æ•°æ®åº“å†™å…¥
      é¡ºåºè¯»IOPS: å¤§æ–‡ä»¶è¯»å–
      é¡ºåºå†™IOPS: æ—¥å¿—å†™å…¥
    
    æ€§èƒ½åŸºå‡†:
      HDD (7.2K RPM): 100-200 IOPS
      HDD (10K RPM): 150-300 IOPS
      HDD (15K RPM): 200-400 IOPS
      SATA SSD: 50K-100K IOPS
      NVMe SSD: 500K-1M+ IOPS
  
  å»¶è¿Ÿ (Latency):
    å®šä¹‰: IOè¯·æ±‚å“åº”æ—¶é—´
    å•ä½: æ¯«ç§’ (ms) æˆ–å¾®ç§’ (Î¼s)
    
    æ€§èƒ½åŸºå‡†:
      HDD: 5-10ms
      SATA SSD: 0.1-0.5ms
      NVMe SSD: 0.01-0.1ms (10-100Î¼s)
    
    å½±å“å› ç´ :
      - ç£ç›˜ç±»å‹
      - é˜Ÿåˆ—æ·±åº¦
      - ç½‘ç»œå»¶è¿Ÿ (SAN/NAS)
      - æ§åˆ¶å™¨æ€§èƒ½
  
  ååé‡ (Throughput):
    å®šä¹‰: æ¯ç§’ä¼ è¾“æ•°æ®é‡
    å•ä½: MB/s æˆ– GB/s
    
    æ€§èƒ½åŸºå‡†:
      HDD (å•ç›˜): 100-200 MB/s
      SATA SSD: 500-600 MB/s
      NVMe SSD: 3000-7000 MB/s
      10GbEç½‘ç»œ: ~1.2 GB/s
      25GbEç½‘ç»œ: ~3 GB/s
  
  é˜Ÿåˆ—æ·±åº¦ (Queue Depth):
    å®šä¹‰: åŒæ—¶å¤„ç†çš„IOè¯·æ±‚æ•°
    å½±å“: æ›´é«˜QDé€šå¸¸æå‡IOPS
    
    æ¨èå€¼:
      HDD: 4-32
      SSD: 32-128
      NVMe: 128-256

æ€§èƒ½ä¼˜åŒ–å±‚æ¬¡:
  L1 - ç¡¬ä»¶å±‚:
    ä¼˜å…ˆçº§: æœ€é«˜
    æŠ•èµ„: æœ€å¤§
    æ•ˆæœ: æœ€æ˜¾è‘—
    æªæ–½:
      âœ… å‡çº§åˆ°SSD/NVMe
      âœ… å¢åŠ å†…å­˜
      âœ… å‡çº§ç½‘ç»œåˆ°10/25GbE
      âœ… ä½¿ç”¨RAIDæ§åˆ¶å™¨
  
  L2 - æ“ä½œç³»ç»Ÿå±‚:
    ä¼˜å…ˆçº§: é«˜
    æŠ•èµ„: ä½
    æ•ˆæœ: æ˜¾è‘—
    æªæ–½:
      âœ… æ–‡ä»¶ç³»ç»Ÿé€‰æ‹©ä¸è°ƒä¼˜
      âœ… IOè°ƒåº¦å™¨ä¼˜åŒ–
      âœ… å†…æ ¸å‚æ•°è°ƒä¼˜
      âœ… å…³é—­ä¸å¿…è¦æœåŠ¡
  
  L3 - è™šæ‹ŸåŒ–å±‚:
    ä¼˜å…ˆçº§: é«˜
    æŠ•èµ„: ä½
    æ•ˆæœ: æ˜¾è‘—
    æªæ–½:
      âœ… è™šæ‹Ÿç£ç›˜æ ¼å¼ä¼˜åŒ–
      âœ… è™šæ‹Ÿæ§åˆ¶å™¨é€‰æ‹©
      âœ… å­˜å‚¨ç­–ç•¥é…ç½®
      âœ… èµ„æºåˆ†é…ä¼˜åŒ–
  
  L4 - ç½‘ç»œå±‚:
    ä¼˜å…ˆçº§: ä¸­
    æŠ•èµ„: ä¸­
    æ•ˆæœ: ä¸­ç­‰
    æªæ–½:
      âœ… Jumbo Frame
      âœ… ç½‘ç»œéš”ç¦»
      âœ… è´Ÿè½½å‡è¡¡
      âœ… QoSé…ç½®
  
  L5 - åè®®å±‚:
    ä¼˜å…ˆçº§: ä¸­
    æŠ•èµ„: ä½
    æ•ˆæœ: ä¸­ç­‰
    æªæ–½:
      âœ… iSCSIå‚æ•°è°ƒä¼˜
      âœ… NFSæŒ‚è½½é€‰é¡¹
      âœ… å¤šè·¯å¾„é…ç½®
  
  L6 - åº”ç”¨å±‚:
    ä¼˜å…ˆçº§: ä¸­
    æŠ•èµ„: ä½
    æ•ˆæœ: åº”ç”¨ç›¸å…³
    æªæ–½:
      âœ… æ•°æ®åº“è°ƒä¼˜
      âœ… ç¼“å­˜ç­–ç•¥
      âœ… æ‰¹é‡æ“ä½œ
      âœ… å¼‚æ­¥IO

æ€§èƒ½ä¼˜åŒ–åŸåˆ™:
  1. æµ‹é‡å…ˆäºä¼˜åŒ–:
     ä½¿ç”¨å·¥å…·å»ºç«‹æ€§èƒ½åŸºå‡†
     è¯†åˆ«ç“¶é¢ˆ
  
  2. ä»åº•å±‚åˆ°ä¸Šå±‚:
     ç¡¬ä»¶ â†’ æ“ä½œç³»ç»Ÿ â†’ åº”ç”¨
     åº•å±‚ä¼˜åŒ–æ•ˆæœæœ€æ˜æ˜¾
  
  3. æ¸è¿›å¼ä¼˜åŒ–:
     ä¸€æ¬¡æ”¹å˜ä¸€ä¸ªå˜é‡
     è®°å½•æ¯æ¬¡å˜åŒ–çš„æ•ˆæœ
  
  4. æŠ•èµ„å›æŠ¥ç‡:
     ä¼˜å…ˆä½æˆæœ¬é«˜æ”¶ç›Šä¼˜åŒ–
     è¯„ä¼°ç¡¬ä»¶å‡çº§æˆæœ¬
  
  5. æŒç»­ç›‘æ§:
     å»ºç«‹ç›‘æ§ä½“ç³»
     å®šæœŸæ€§èƒ½è¯„ä¼°
```

---

## ç¡¬ä»¶å±‚æ€§èƒ½ä¼˜åŒ–

```yaml
ç£ç›˜é€‰å‹ä¸é…ç½®:
  HDDä¼˜åŒ–:
    é€‰å‹:
      è½¬é€Ÿ: 10K/15K RPMä¼˜äº7.2K
      æ¥å£: SASä¼˜äºSATA
      ç¼“å­˜: 128MB-256MB
    
    RAIDé…ç½®:
      RAID10: æœ€ä½³æ€§èƒ½+å†—ä½™
      RAID5: è¯»æ€§èƒ½è‰¯å¥½
      RAID6: 2ä¸ªç£ç›˜å®¹é”™
      é¿å…: RAID5å†™æ€§èƒ½å·®
    
    ä¼˜åŒ–å»ºè®®:
      âœ… çŸ­å†²ç¨‹ (Short Stroking)
        ä»…ä½¿ç”¨å¤–åœˆç£é“ (æ›´å¿«)
      âœ… åˆ†æ•£è´Ÿè½½
        ä¸åŒå·¥ä½œè´Ÿè½½åˆ†ä¸åŒç£ç›˜ç»„
      âœ… é¢„è¯»å–
        é¡ºåºè¯»å–åœºæ™¯
  
  SSDä¼˜åŒ–:
    é€‰å‹:
      æ¥å£: NVMe > SAS > SATA
      NANDç±»å‹: SLC > MLC > TLC > QLC
      è¿‡åº¦é…ç½®: 20-30%
      è€ä¹…æ€§: 3+ DWPD (å†™å¯†é›†)
    
    é…ç½®:
      RAID:
        RAID0: æœ€é«˜æ€§èƒ½ (æ— å†—ä½™)
        RAID10: æ€§èƒ½+å†—ä½™
        é¿å…: RAID5/6 (å†™æ”¾å¤§)
      
      Trimæ”¯æŒ:
        å®šæœŸTrimé‡Šæ”¾ç©ºé—´
        ä¿æŒæ€§èƒ½ç¨³å®š
    
    ä¼˜åŒ–å»ºè®®:
      âœ… é¢„ç•™ç©ºé—´
        ä¿æŒ20%+ è‡ªç”±ç©ºé—´
      âœ… ç£¨æŸå‡è¡¡
        ç›‘æ§å†™å…¥é‡
      âœ… é˜Ÿåˆ—æ·±åº¦
        è®¾ç½®64-128
  
  NVMeä¼˜åŒ–:
    é€‰å‹:
      æ¥å£: PCIe 4.0 > 3.0
      é€šé“: x4é€šé“
      é˜Ÿåˆ—: æ”¯æŒå¤šé˜Ÿåˆ—
    
    é…ç½®:
      ç›´è¿CPU:
        é¿å…PCIe switch
        é™ä½å»¶è¿Ÿ
      
      ä¸­æ–­ç»‘å®š:
        CPUäº²å’Œæ€§
        é¿å…ä¸­æ–­é£æš´
    
    ä¼˜åŒ–å»ºè®®:
      âœ… ä½¿ç”¨æœ€æ–°é©±åŠ¨
      âœ… å¯ç”¨å¤šé˜Ÿåˆ—
      âœ… è°ƒæ•´é˜Ÿåˆ—æ·±åº¦

å†…å­˜ä¼˜åŒ–:
  å®¹é‡è§„åˆ’:
    æ“ä½œç³»ç»Ÿ: 16GBåŸºç¡€
    è™šæ‹ŸåŒ–: 4-8GB/VM
    Ceph: 4-8GB/OSD
    vSAN: 32GB/TBå®¹é‡
    æ•°æ®åº“ç¼“å­˜: åº”ç”¨éœ€æ±‚
  
  æ€§èƒ½é…ç½®:
    é¢‘ç‡: DDR4-3200+ æˆ– DDR5
    é€šé“: å¤šé€šé“ (4/6/8é€šé“)
    ECC: ç”Ÿäº§ç¯å¢ƒæ¨è
    NUMA: å¯ç”¨NUMAæ„ŸçŸ¥
  
  ä¼˜åŒ–å»ºè®®:
    âœ… å¯ç”¨å¤§é¡µå†…å­˜ (HugePages)
    âœ… ç¦ç”¨äº¤æ¢ (Swap)
    âœ… å†…å­˜å¯¹é½
    âœ… NUMAç»‘å®š

CPUä¼˜åŒ–:
  é€‰å‹:
    æ ¸å¿ƒæ•°: æ›´å¤šæ ¸å¿ƒ (æ¨ªå‘æ‰©å±•)
    é¢‘ç‡: é«˜é¢‘ç‡ (å•çº¿ç¨‹æ€§èƒ½)
    ç¼“å­˜: L3ç¼“å­˜è¶Šå¤§è¶Šå¥½
    
    æ¨è:
      Intel Xeon Gold/Platinum
      AMD EPYC 7003/9004ç³»åˆ—
  
  é…ç½®:
    è™šæ‹ŸåŒ–: å¯ç”¨VT-x/AMD-V, EPT/RVI
    è¶…çº¿ç¨‹: å¯ç”¨ (å¤§å¤šæ•°åœºæ™¯)
    Turbo Boost: å¯ç”¨
    C-States: ç¦ç”¨ (ä½å»¶è¿Ÿ) æˆ– å¯ç”¨ (èŠ‚èƒ½)
  
  ä¼˜åŒ–å»ºè®®:
    âœ… CPUäº²å’Œæ€§ (taskset)
    âœ… ä¸­æ–­ç»‘å®š (irqbalance)
    âœ… NUMAç»‘å®š

å­˜å‚¨æ§åˆ¶å™¨:
  HBAæ¨¡å¼ (æ¨è):
    ç±»å‹: LSI 9300/9400ç³»åˆ—
    åŠŸèƒ½: ç›´é€šï¼Œæ— RAID
    ç”¨é€”: Ceph, vSAN
    æ€§èƒ½: æœ€ä½³
  
  RAIDæ¨¡å¼:
    ç±»å‹: Dell PERC, HPE Smart Array
    ç¼“å­˜: 2-8GB, ç”µæ± ä¿æŠ¤
    å†™ç­–ç•¥: Write-Back (æ€§èƒ½)
    è¯»ç­–ç•¥: Read-Ahead (é¡ºåº)
  
  é˜Ÿåˆ—æ·±åº¦:
    HBA: é»˜è®¤å³å¯
    RAID: å¢åŠ åˆ°256-512
    
    é…ç½®ç¤ºä¾‹ (Linux):
      echo 256 > /sys/block/sda/device/queue_depth

ç½‘ç»œç¡¬ä»¶:
  ç½‘å¡:
    é€Ÿç‡: 10GbE (æœ€ä½), 25GbE (æ¨è)
    é˜Ÿåˆ—: å¤šé˜Ÿåˆ—æ”¯æŒ
    å¸è½½: TSO, LRO, RSS
    
    æ¨èå‹å·:
      Intel X710 (10GbE)
      Mellanox ConnectX-5/6 (25/100GbE)
  
  äº¤æ¢æœº:
    ç¼“å†²: æ·±ç¼“å†² (large buffer)
    å»¶è¿Ÿ: ä½å»¶è¿Ÿ (<5Î¼s)
    Jumbo Frame: æ”¯æŒ
    
    æ¨è:
      Cisco Nexus
      Arista (ä½å»¶è¿Ÿ)
      Mellanox Spectrum
```

---

## æ“ä½œç³»ç»Ÿå±‚ä¼˜åŒ–

```yaml
æ–‡ä»¶ç³»ç»Ÿé€‰æ‹©:
  XFS (æ¨èå­˜å‚¨æœåŠ¡å™¨):
    ä¼˜åŠ¿:
      âœ… å¤§æ–‡ä»¶æ€§èƒ½ä¼˜ç§€
      âœ… å¹¶å‘æ€§èƒ½å¥½
      âœ… æ—¥å¿—å‹æ–‡ä»¶ç³»ç»Ÿ
      âœ… åœ¨çº¿æ‰©å±•
    
    é€‚ç”¨: Ceph, NFSæœåŠ¡å™¨
    
    ä¼˜åŒ–æŒ‚è½½é€‰é¡¹:
      noatime,nodiratime: ä¸æ›´æ–°è®¿é—®æ—¶é—´
      nobarrier: ç¦ç”¨barrier (æœ‰UPS)
      inode64: 64ä½inode
      logbufs=8: å¢åŠ æ—¥å¿—ç¼“å†²
      
      ç¤ºä¾‹:
        mount -o noatime,nodiratime,nobarrier,inode64,logbufs=8 /dev/sdb1 /data
  
  ext4:
    ä¼˜åŠ¿:
      âœ… ç¨³å®šæˆç†Ÿ
      âœ… å¹¿æ³›æ”¯æŒ
      âœ… å°æ–‡ä»¶æ€§èƒ½å¥½
    
    é€‚ç”¨: é€šç”¨åœºæ™¯
    
    ä¼˜åŒ–æŒ‚è½½é€‰é¡¹:
      noatime,nodiratime
      data=writeback: æå‡å†™æ€§èƒ½ (å®‰å…¨æ€§é™ä½)
      commit=60: å»¶é•¿æäº¤é—´éš”
      
      ç¤ºä¾‹:
        mount -o noatime,data=writeback,commit=60 /dev/sdb1 /data
  
  Btrfs:
    ä¼˜åŠ¿:
      âœ… å¿«ç…§
      âœ… å‹ç¼©
      âœ… COW
    
    åŠ£åŠ¿:
      âš ï¸ æ€§èƒ½è¾ƒXFS/ext4ä½
      âš ï¸ RAID5/6ä¸ç¨³å®š
    
    é€‚ç”¨: å¤‡ä»½åœºæ™¯
  
  ZFS:
    ä¼˜åŠ¿:
      âœ… æ•°æ®å®Œæ•´æ€§
      âœ… å‹ç¼©
      âœ… å¿«ç…§
      âœ… ARCç¼“å­˜
    
    åŠ£åŠ¿:
      âš ï¸ å†…å­˜æ¶ˆè€—å¤§
      âš ï¸ éLinuxåŸç”Ÿ
    
    é€‚ç”¨: FreeBSD/TrueNAS

IOè°ƒåº¦å™¨:
  None (æ¨èSSD/NVMe):
    ç‰¹ç‚¹: æ— è°ƒåº¦ï¼Œç›´æ¥ä¸‹å‘
    é€‚ç”¨: SSD, NVMe
    é…ç½®:
      echo none > /sys/block/nvme0n1/queue/scheduler
  
  mq-deadline (æ¨èHDD):
    ç‰¹ç‚¹: å¤šé˜Ÿåˆ—ï¼Œdeadlineä¿è¯
    é€‚ç”¨: HDD, æ··åˆè´Ÿè½½
    é…ç½®:
      echo mq-deadline > /sys/block/sda/queue/scheduler
  
  BFQ (é¢„ç®—å…¬å¹³é˜Ÿåˆ—):
    ç‰¹ç‚¹: ä½å»¶è¿Ÿï¼Œå…¬å¹³
    é€‚ç”¨: æ¡Œé¢ï¼Œäº¤äº’å¼
    ä¸æ¨è: æœåŠ¡å™¨
  
  Kyber:
    ç‰¹ç‚¹: è‡ªé€‚åº”
    é€‚ç”¨: é€šç”¨

å†…æ ¸å‚æ•°è°ƒä¼˜:
```

```bash
#!/bin/bash
# å­˜å‚¨æ€§èƒ½å†…æ ¸å‚æ•°ä¼˜åŒ–è„šæœ¬

cat >> /etc/sysctl.conf <<'EOF'

# ====================
# å­˜å‚¨æ€§èƒ½ä¼˜åŒ–
# ====================

# è™šæ‹Ÿå†…å­˜
vm.dirty_ratio = 15                    # è„é¡µæ¯”ä¾‹è§¦å‘å†™å›
vm.dirty_background_ratio = 5          # åå°å†™å›æ¯”ä¾‹
vm.dirty_expire_centisecs = 3000       # è„é¡µè¿‡æœŸæ—¶é—´ (30ç§’)
vm.dirty_writeback_centisecs = 500     # å†™å›é—´éš” (5ç§’)
vm.swappiness = 10                     # é™ä½swapä½¿ç”¨
vm.vfs_cache_pressure = 50             # inode/dentryç¼“å­˜å‹åŠ›

# å—è®¾å¤‡
vm.block_dump = 0                      # ç¦ç”¨å—dump (æ€§èƒ½)

# å†…å­˜
vm.min_free_kbytes = 524288            # æœ€å°ç©ºé—²å†…å­˜ (512MB)
vm.overcommit_memory = 1               # å…è®¸å†…å­˜è¿‡åº¦åˆ†é…
vm.overcommit_ratio = 50               # è¿‡åº¦åˆ†é…æ¯”ä¾‹

# ç½‘ç»œ (å­˜å‚¨ç½‘ç»œ)
net.core.rmem_max = 134217728          # æœ€å¤§æ¥æ”¶ç¼“å†² (128MB)
net.core.wmem_max = 134217728          # æœ€å¤§å‘é€ç¼“å†²
net.core.rmem_default = 33554432       # é»˜è®¤æ¥æ”¶ç¼“å†² (32MB)
net.core.wmem_default = 33554432       # é»˜è®¤å‘é€ç¼“å†²
net.ipv4.tcp_rmem = 4096 87380 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728
net.ipv4.tcp_mem = 134217728 134217728 134217728

# TCPä¼˜åŒ–
net.ipv4.tcp_window_scaling = 1        # å¯ç”¨çª—å£æ‰©å±•
net.ipv4.tcp_timestamps = 1            # å¯ç”¨æ—¶é—´æˆ³
net.ipv4.tcp_sack = 1                  # å¯ç”¨SACK
net.ipv4.tcp_no_metrics_save = 1       # ä¸ä¿å­˜metrics
net.core.netdev_max_backlog = 10000    # ç½‘ç»œè®¾å¤‡é˜Ÿåˆ—

# æ–‡ä»¶ç³»ç»Ÿ
fs.file-max = 2097152                  # æœ€å¤§æ–‡ä»¶å¥æŸ„
fs.aio-max-nr = 1048576                # å¼‚æ­¥IO

# HugePages (å¯é€‰, æ ¹æ®å†…å­˜å¤§å°)
# vm.nr_hugepages = 1024               # 2GB (2MBÃ—1024)

EOF

# åº”ç”¨é…ç½®
sysctl -p

echo "å†…æ ¸å‚æ•°ä¼˜åŒ–å®Œæˆ"
```

```yaml
ç³»ç»ŸæœåŠ¡ä¼˜åŒ–:
  ç¦ç”¨ä¸å¿…è¦æœåŠ¡:
    systemctl disable firewalld        # æˆ–é…ç½®è§„åˆ™
    systemctl disable postfix
    systemctl disable bluetooth
    systemctl disable cups
  
  ä¿ç•™å¿…è¦æœåŠ¡:
    âœ… sshd
    âœ… chronyd/ntpd
    âœ… rsyslog

ç£ç›˜é¢„è¯»ä¼˜åŒ–:
  æŸ¥çœ‹å½“å‰å€¼:
    blockdev --getra /dev/sda
  
  è®¾ç½®é¢„è¯» (KB):
    # HDD: 4096-8192 (4-8MB)
    blockdev --setra 4096 /dev/sda
    
    # SSD: 256-1024 (256KB-1MB)
    blockdev --setra 512 /dev/sdb
    
    # NVMe: 128-512 (128-512KB)
    blockdev --setra 256 /dev/nvme0n1
  
  æ°¸ä¹…é…ç½®:
    # /etc/udev/rules.d/60-readahead.rules
    ACTION=="add|change", KERNEL=="sd[a-z]", ATTR{queue/read_ahead_kb}="4096"
    ACTION=="add|change", KERNEL=="nvme[0-9]n[0-9]", ATTR{queue/read_ahead_kb}="256"

é˜Ÿåˆ—æ·±åº¦:
  æŸ¥çœ‹:
    cat /sys/block/sda/device/queue_depth
  
  è®¾ç½®:
    echo 256 > /sys/block/sda/device/queue_depth
  
  æ¨èå€¼:
    HDD: 32
    SSD: 128
    NVMe: 256

SSDä¼˜åŒ–:
  Trimæ”¯æŒ:
    # æ£€æŸ¥æ”¯æŒ
    lsblk --discard
    
    # æ‰‹åŠ¨Trim
    fstrim -v /
    
    # å®šæœŸTrim (cron)
    0 2 * * 0 /sbin/fstrim -av
  
  å…³é—­ç£ç›˜è°ƒåº¦:
    echo none > /sys/block/sdb/queue/scheduler
  
  æ ‡è®°ä¸ºSSD:
    echo 0 > /sys/block/sdb/queue/rotational
```

---

## è™šæ‹ŸåŒ–å±‚ä¼˜åŒ–

```yaml
VMware vSphereä¼˜åŒ–:
  è™šæ‹Ÿç£ç›˜æ ¼å¼:
    Thick Eager Zeroed:
      æ€§èƒ½: æœ€ä½³
      åŸå› : é¢„åˆ†é…+å½’é›¶
      é€‚ç”¨: ç”Ÿäº§æ•°æ®åº“
    
    Thick Lazy Zeroed:
      æ€§èƒ½: è‰¯å¥½
      åŸå› : é¢„åˆ†é…ï¼ŒæŒ‰éœ€å½’é›¶
      é€‚ç”¨: é€šç”¨è™šæ‹Ÿæœº
    
    Thin:
      æ€§èƒ½: è¾ƒå·®
      åŸå› : æŒ‰éœ€åˆ†é…ï¼Œå…ƒæ•°æ®å¼€é”€
      é€‚ç”¨: å¼€å‘æµ‹è¯•
  
  è™šæ‹ŸSCSIæ§åˆ¶å™¨:
    é€‰æ‹©:
      LSI Logic Parallel (è€æ—§)
      LSI Logic SAS (é€šç”¨)
      VMware Paravirtual (PVSCSI) âœ… æ¨è
    
    PVSCSIä¼˜åŠ¿:
      âœ… é™ä½CPUå¼€é”€
      âœ… æ›´é«˜ååé‡
      âœ… æ›´é«˜IOPS
      âœ… æ”¯æŒ256ä¸ªé˜Ÿåˆ—
    
    é…ç½®:
      é˜Ÿåˆ—æ·±åº¦: 256
      ç¯å½¢ç¼“å†²: 64
  
  å­˜å‚¨ç­–ç•¥ (vSAN):
    é«˜æ€§èƒ½:
      FTT=1, RAID-5, ç£ç›˜æ¡å¸¦=4
      å¯¹è±¡ç©ºé—´é¢„ç•™=100%
      é—ªå­˜è¯»ç¼“å­˜=100%
    
    å¹³è¡¡:
      FTT=1, RAID-1, ç£ç›˜æ¡å¸¦=1
      å¯¹è±¡ç©ºé—´é¢„ç•™=0%
    
    å®¹é‡ä¼˜åŒ–:
      FTT=2, RAID-6
      é‡å¤æ•°æ®åˆ é™¤+å‹ç¼©
  
  é«˜çº§å‚æ•°:
    Disk.SchedNumReqOutstanding: 256
      è¯´æ˜: æ¯ç£ç›˜é˜Ÿåˆ—æ·±åº¦
      é»˜è®¤: 32
      æ¨è: 128-256 (SSD)
    
    Disk.DiskMaxIOSize: 4096
      è¯´æ˜: æœ€å¤§IOå¤§å° (KB)
      é»˜è®¤: 32768
      æ¨è: ä¿æŒé»˜è®¤ (å¤§æ–‡ä»¶)
    
    NFS.MaxQueueDepth: 128
      è¯´æ˜: NFSé˜Ÿåˆ—æ·±åº¦
      é»˜è®¤: 64
      æ¨è: 128
  
  CPU/å†…å­˜ä¼˜åŒ–:
    CPUé¢„ç•™: å…³é”®VMé¢„ç•™CPU
    å†…å­˜é¢„ç•™: æ•°æ®åº“VMé¢„ç•™å†…å­˜
    NUMA: å¯ç”¨NUMAè°ƒåº¦
    å»¶è¿Ÿæ•æ„Ÿåº¦: é«˜æ€§èƒ½VMè®¾ç½®"é«˜"

KVMä¼˜åŒ–:
  virtioé©±åŠ¨:
    virtio-blk:
      ç±»å‹: å—è®¾å¤‡
      æ€§èƒ½: ä¼˜ç§€
      æ¨è: âœ…
    
    virtio-scsi:
      ç±»å‹: SCSIæ§åˆ¶å™¨
      åŠŸèƒ½: æ›´å¤šç‰¹æ€§ (Trim, ç£ç›˜çƒ­æ’æ‹”)
      æ€§èƒ½: ä¼˜ç§€
      æ¨è: âœ… (ç”Ÿäº§ç¯å¢ƒ)
  
  ç¼“å­˜æ¨¡å¼:
    none:
      ç‰¹ç‚¹: ç›´æ¥IOï¼Œç»•è¿‡å®¿ä¸»ç¼“å­˜
      æ€§èƒ½: æœ€ä½³ (å…±äº«å­˜å‚¨)
      æ•°æ®å®‰å…¨: æœ€é«˜
      æ¨è: âœ… ç”Ÿäº§ç¯å¢ƒ
    
    writethrough:
      ç‰¹ç‚¹: è¯»ç¼“å­˜ï¼Œå†™ç›´é€š
      æ€§èƒ½: è¯»å¿«ï¼Œå†™æ…¢
      æ¨è: æœ¬åœ°å­˜å‚¨
    
    writeback:
      ç‰¹ç‚¹: è¯»å†™éƒ½ç¼“å­˜
      æ€§èƒ½: æœ€å¿«
      é£é™©: æ–­ç”µæ•°æ®ä¸¢å¤±
      æ¨è: ä»…æµ‹è¯•
  
  IOçº¿ç¨‹:
    # å¯ç”¨å¤šé˜Ÿåˆ—
    <driver name='qemu' type='raw' cache='none' io='native' iothread='1'/>
    <disk type='file' device='disk'>
      <driver name='qemu' type='raw' cache='none' io='native' queues='4'/>
      ...
    </disk>
  
  CPUå›ºå®š:
    <vcpu placement='static' cpuset='2-5'>4</vcpu>
    <cputune>
      <vcpupin vcpu='0' cpuset='2'/>
      <vcpupin vcpu='1' cpuset='3'/>
      <vcpupin vcpu='2' cpuset='4'/>
      <vcpupin vcpu='3' cpuset='5'/>
    </cputune>

Hyper-Vä¼˜åŒ–:
  è™šæ‹Ÿç¡¬ç›˜:
    VHDX (æ¨è):
      ä¼˜åŠ¿: æ›´å¤§å®¹é‡, æ›´å¥½æ€§èƒ½
      æ ¼å¼: å›ºå®š > åŠ¨æ€
    
    Pass-throughç£ç›˜:
      æ€§èƒ½: æœ€ä½³
      ç”¨é€”: æ•°æ®åº“
  
  å­˜å‚¨QoS:
    æœ€å°IOPS: ä¿è¯æ€§èƒ½
    æœ€å¤§IOPS: é˜²æ­¢äº‰ç”¨
  
  ä¼˜åŒ–:
    ç¦ç”¨è™šæ‹Ÿè½¯ç›˜
    ä½¿ç”¨SCSIæ§åˆ¶å™¨ (è€ŒéIDE)
    å¯ç”¨é›†æˆæœåŠ¡
```

---

## ç½‘ç»œå±‚ä¼˜åŒ–

```yaml
Jumbo Frameé…ç½®:
  MTUè®¾ç½®:
    æ ‡å‡†: 1500
    Jumbo Frame: 9000
    
    å¥½å¤„:
      âœ… å‡å°‘CPUå¼€é”€ 20-30%
      âœ… æå‡ååé‡ 10-20%
      âœ… é™ä½å»¶è¿Ÿ
  
  é…ç½®è¦æ±‚:
    âœ… ç«¯åˆ°ç«¯æ”¯æŒ
      å®¢æˆ·ç«¯ MTU 9000
      äº¤æ¢æœº MTU 9216
      å­˜å‚¨æœåŠ¡å™¨ MTU 9000
  
  Linuxé…ç½®:
    ä¸´æ—¶:
      ip link set eth1 mtu 9000
    
    æ°¸ä¹… (NetworkManager):
      nmcli connection modify eth1 802-3-ethernet.mtu 9000
    
    æ°¸ä¹… (Netplan):
      network:
        ethernets:
          eth1:
            mtu: 9000
  
  VMwareé…ç½®:
    vDS:
      ç¼–è¾‘vDS â†’ é«˜çº§ â†’ MTU: 9000
    
    VMkernel:
      esxcli network ip interface set -i vmk1 -m 9000
  
  éªŒè¯:
    Linux:
      ping -M do -s 8972 <target-ip>
      # 8972 = 9000 - 28 (IP+ICMP header)
    
    Windows:
      ping -f -l 8972 <target-ip>

ç½‘ç»œéš”ç¦»:
  VLANè§„åˆ’:
    VLAN 10: ç®¡ç†ç½‘ç»œ (1GbE)
    VLAN 20: å­˜å‚¨ç½‘ç»œ (10/25GbE)
    VLAN 30: vMotionç½‘ç»œ (10GbE)
    VLAN 40: è™šæ‹Ÿæœºç½‘ç»œ (10GbE)
  
  ç‰©ç†éš”ç¦»:
    å­˜å‚¨: ä¸“ç”¨äº¤æ¢æœº
    ä¸šåŠ¡: ç‹¬ç«‹äº¤æ¢æœº
    å¤‡ä»½: ç‹¬ç«‹ç½‘æ®µ

ç½‘å¡ç»‘å®š (Bonding/Teaming):
  æ¨¡å¼é€‰æ‹©:
    Mode 0 (Balance-RR):
      ç‰¹ç‚¹: è½®è¯¢
      æ€§èƒ½: æœ€é«˜
      é™åˆ¶: éœ€è¦äº¤æ¢æœºé…ç½®
    
    Mode 1 (Active-Backup):
      ç‰¹ç‚¹: ä¸»å¤‡
      æ€§èƒ½: å•é“¾è·¯
      ä¼˜åŠ¿: æ— äº¤æ¢æœºè¦æ±‚
    
    Mode 4 (LACP 802.3ad):
      ç‰¹ç‚¹: åŠ¨æ€èšåˆ
      æ€§èƒ½: é«˜
      æ¨è: âœ… ç”Ÿäº§ç¯å¢ƒ
  
  Linuxé…ç½® (LACP):
    # /etc/network/interfaces (Debian/Ubuntu)
    auto bond0
    iface bond0 inet static
        address 192.168.20.10
        netmask 255.255.255.0
        bond-mode 802.3ad
        bond-miimon 100
        bond-lacp-rate fast
        bond-slaves eth2 eth3
  
  VMwareé…ç½® (LACP):
    vDS â†’ LACP â†’ æ–°å»º
      æ¨¡å¼: Active
      è´Ÿè½½å‡è¡¡: åŸºäºIPå“ˆå¸Œ

ç½‘å¡é˜Ÿåˆ—ä¼˜åŒ–:
  å¤šé˜Ÿåˆ— (RSS - Receive Side Scaling):
    æŸ¥çœ‹é˜Ÿåˆ—æ•°:
      ethtool -l eth0
    
    è®¾ç½®é˜Ÿåˆ—æ•°:
      ethtool -L eth0 combined 8
    
    æ¨è: é˜Ÿåˆ—æ•° = CPUæ ¸å¿ƒæ•° (æœ€å¤š16)
  
  ä¸­æ–­ç»‘å®š:
    æŸ¥çœ‹ä¸­æ–­:
      cat /proc/interrupts | grep eth0
    
    ç»‘å®šåˆ°ç‰¹å®šCPU:
      echo 2 > /proc/irq/<IRQ>/smp_affinity_list
    
    è‡ªåŠ¨å¹³è¡¡:
      systemctl start irqbalance

TCP/IPè°ƒä¼˜:
  æ‹¥å¡æ§åˆ¶:
    æŸ¥çœ‹:
      sysctl net.ipv4.tcp_congestion_control
    
    è®¾ç½®:
      # BBR (æ¨è, å†…æ ¸4.9+)
      sysctl -w net.ipv4.tcp_congestion_control=bbr
      sysctl -w net.core.default_qdisc=fq
  
  çª—å£å¤§å°:
    net.ipv4.tcp_window_scaling = 1
    net.ipv4.tcp_rmem = 4096 87380 134217728
    net.ipv4.tcp_wmem = 4096 65536 134217728
  
  å¿«é€Ÿæ‰“å¼€:
    net.ipv4.tcp_fastopen = 3
```

---

## å­˜å‚¨åè®®ä¼˜åŒ–

```yaml
iSCSIä¼˜åŒ–:
  Initiatorä¼˜åŒ–:
    é˜Ÿåˆ—æ·±åº¦:
      æŸ¥çœ‹:
        cat /sys/class/iscsi_host/host*/device/session*/iscsi_session*/target*/*/queue_depth
      
      è®¾ç½®:
        echo 128 > /sys/class/scsi_disk/*/device/queue_depth
    
    æ›¿æ¢è¶…æ—¶:
      node.session.timeo.replacement_timeout = 15
    
    ç™»å½•è¶…æ—¶:
      node.conn[0].timeo.login_timeout = 15
      node.conn[0].timeo.logout_timeout = 15
    
    NOPè¶…æ—¶:
      node.conn[0].timeo.noop_out_interval = 5
      node.conn[0].timeo.noop_out_timeout = 5
  
  Targetä¼˜åŒ–:
    # TGT
    tgtadm --op update --mode target --tid 1 \
      --name MaxRecvDataSegmentLength --value 262144
    
    tgtadm --op update --mode target --tid 1 \
      --name FirstBurstLength --value 262144
  
  ESXi iSCSIä¼˜åŒ–:
    esxcli system settings advanced set \
      -o /Disk/QFullSampleSize -i 128
    
    esxcli system settings advanced set \
      -o /Disk/SchedNumReqOutstanding -i 256

NFSä¼˜åŒ–:
  æŒ‚è½½é€‰é¡¹:
    rsize/wsize:
      æ¨è: 131072 (128KB) æˆ– 262144 (256KB)
      
      mount -o rsize=262144,wsize=262144 ...
    
    é”™è¯¯å¤„ç†:
      hard,intr,timeo=600,retrans=2
    
    åè®®:
      tcp (æ¨è)
      vers=3 æˆ– vers=4.1
    
    å®Œæ•´ç¤ºä¾‹:
      mount -t nfs -o rw,hard,intr,rsize=262144,wsize=262144,tcp,timeo=600,vers=3 \
        192.168.20.10:/export/vmware /mnt/vmware
  
  æœåŠ¡å™¨ç«¯ä¼˜åŒ–:
    NFSçº¿ç¨‹æ•°:
      # æ¨è: 2-4 Ã— CPUæ ¸å¿ƒæ•°
      echo 32 > /proc/fs/nfsd/threads
    
    å¼‚æ­¥å†™å…¥ (è°¨æ…):
      /etc/exports:
        /export/data *(rw,async,no_subtree_check)
  
  ESXi NFSä¼˜åŒ–:
    esxcli system settings advanced set \
      -o /NFS/MaxQueueDepth -i 128
    
    esxcli system settings advanced set \
      -o /NFS/SendBufferSize -i 262144

vSANä¼˜åŒ–:
  å­˜å‚¨ç­–ç•¥:
    ç£ç›˜æ¡å¸¦æ•°: 1 (é»˜è®¤) â†’ 4 (é«˜æ€§èƒ½)
    å¯¹è±¡ç©ºé—´é¢„ç•™: 0% â†’ 100% (åšç½®å¤‡)
    é—ªå­˜è¯»ç¼“å­˜: 0% â†’ 100% (å…³é”®VM)
  
  é‡åŒæ­¥é™æµ:
    é™ä½é‡å»ºä¼˜å…ˆçº§ï¼Œé¿å…å½±å“ä¸šåŠ¡
    é…ç½®: 40-60 IOPSé™åˆ¶
  
  é‡å¤æ•°æ®åˆ é™¤+å‹ç¼©:
    å…¨é—ªå­˜æ¨èå¯ç”¨
    èŠ‚çœå®¹é‡50-70%
    CPUå¼€é”€10-15%

Cephä¼˜åŒ–:
  OSD:
    bluestore_cache_size: 4GB (HDD) / 8GB (SSD)
    osd_op_num_threads_per_shard: 2
    osd_op_num_shards: 8
  
  å®¢æˆ·ç«¯ (RBD):
    rbd_cache: true
    rbd_cache_size: 33554432  # 32MB
    rbd_cache_max_dirty: 25165824
  
  PG autoscale:
    ceph osd pool set <pool> pg_autoscale_mode on
```

---

## åº”ç”¨å±‚ä¼˜åŒ–

```yaml
æ•°æ®åº“ä¼˜åŒ–:
  MySQL/MariaDB:
    InnoDBé…ç½®:
      innodb_buffer_pool_size: 70-80%å†…å­˜
      innodb_log_file_size: 256MB-2GB
      innodb_flush_method: O_DIRECT
      innodb_io_capacity: 2000 (HDD) / 20000 (SSD)
      innodb_read_io_threads: 8
      innodb_write_io_threads: 8
    
    å­˜å‚¨:
      æ¨è: SSD/NVMe
      æ–‡ä»¶ç³»ç»Ÿ: XFS (noatime)
      æŒ‚è½½: nobarrier (æœ‰UPS)
  
  PostgreSQL:
    é…ç½®:
      shared_buffers: 25%å†…å­˜
      effective_cache_size: 50-75%å†…å­˜
      work_mem: æ ¹æ®è¿æ¥æ•°
      maintenance_work_mem: 1-2GB
      wal_buffers: 16MB
      checkpoint_completion_target: 0.9
      random_page_cost: 1.1 (SSD) / 4.0 (HDD)
    
    å­˜å‚¨:
      æ•°æ®ç›®å½•: SSD/NVMe
      WALç›®å½•: ç‹¬ç«‹é«˜é€Ÿç›˜
      æ–‡ä»¶ç³»ç»Ÿ: XFS
  
  MongoDB:
    é…ç½®:
      storage.wiredTiger.engineConfig.cacheSizeGB: 50%å†…å­˜
      storage.directoryPerDB: true
    
    å­˜å‚¨:
      æ¨è: SSD/NVMe
      æ–‡ä»¶ç³»ç»Ÿ: XFS
      RAID: RAID10

è™šæ‹Ÿæœºä¼˜åŒ–:
  ç£ç›˜IOä¼˜å…ˆçº§:
    VMware:
      shares: High (2000) / Normal (1000) / Low (500)
    
    KVM:
      <iotune>
        <total_iops_sec>5000</total_iops_sec>
      </iotune>
  
  è™šæ‹Ÿæœºæ”¾ç½®:
    åäº²å’Œæ€§: åˆ†æ•£åˆ°ä¸åŒä¸»æœº
    å­˜å‚¨DRS: è‡ªåŠ¨è´Ÿè½½å‡è¡¡
    NUMAç»‘å®š: å¤§å†…å­˜VM

å®¹å™¨ä¼˜åŒ–:
  Docker:
    å­˜å‚¨é©±åŠ¨:
      æ¨è: overlay2
      é…ç½®: /etc/docker/daemon.json
        {
          "storage-driver": "overlay2",
          "storage-opts": [
            "overlay2.override_kernel_check=true"
          ]
        }
  
  Kubernetes:
    å­˜å‚¨ç±»:
      é€‰æ‹©æ€§èƒ½ä¼˜åŒ–çš„StorageClass
      æ”¯æŒæ‰©å±•: allowVolumeExpansion
    
    PVå›æ”¶ç­–ç•¥:
      reclaimPolicy: Retain (é¿å…è¯¯åˆ )
```

---

## æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†

```bash
#!/bin/bash
# å­˜å‚¨æ€§èƒ½æµ‹è¯•å·¥å…·é›†

echo "========================================="
echo "  å­˜å‚¨æ€§èƒ½æµ‹è¯•"
echo "========================================="
echo ""

# 1. FIO - æœ€å…¨é¢çš„å­˜å‚¨æµ‹è¯•å·¥å…·
echo "=== FIOæµ‹è¯• ==="

# éšæœºè¯»IOPSæµ‹è¯•
fio --name=randread --ioengine=libaio --iodepth=32 --rw=randread \
    --bs=4k --direct=1 --size=10G --numjobs=4 --runtime=60 \
    --group_reporting --filename=/dev/sdb

# éšæœºå†™IOPSæµ‹è¯•
fio --name=randwrite --ioengine=libaio --iodepth=32 --rw=randwrite \
    --bs=4k --direct=1 --size=10G --numjobs=4 --runtime=60 \
    --group_reporting --filename=/dev/sdb

# é¡ºåºè¯»ååé‡æµ‹è¯•
fio --name=seqread --ioengine=libaio --iodepth=32 --rw=read \
    --bs=1m --direct=1 --size=10G --numjobs=1 --runtime=60 \
    --group_reporting --filename=/dev/sdb

# æ··åˆè¯»å†™æµ‹è¯• (70%è¯» 30%å†™)
fio --name=randrw --ioengine=libaio --iodepth=32 --rw=randrw \
    --rwmixread=70 --bs=4k --direct=1 --size=10G --numjobs=4 \
    --runtime=60 --group_reporting --filename=/dev/sdb

# 2. dd - ç®€å•ååé‡æµ‹è¯•
echo ""
echo "=== ddæµ‹è¯• ==="
dd if=/dev/zero of=/mnt/testfile bs=1M count=10240 conv=fdatasync
rm -f /mnt/testfile

# 3. iozone - æ–‡ä»¶ç³»ç»Ÿæµ‹è¯•
echo ""
echo "=== IOzoneæµ‹è¯• ==="
iozone -a -s 10G -r 4k -i 0 -i 1 -i 2 -f /mnt/iozone-test

# 4. sysbench - æ•°æ®åº“åœºæ™¯æµ‹è¯•
echo ""
echo "=== Sysbenchæ–‡ä»¶IOæµ‹è¯• ==="
sysbench fileio --file-total-size=10G prepare
sysbench fileio --file-total-size=10G --file-test-mode=rndrw \
  --time=60 --max-requests=0 run
sysbench fileio --file-total-size=10G cleanup

# 5. ç½‘ç»œå­˜å‚¨æµ‹è¯• (iperf3)
echo ""
echo "=== ç½‘ç»œå¸¦å®½æµ‹è¯• ==="
# åœ¨å­˜å‚¨æœåŠ¡å™¨è¿è¡Œ: iperf3 -s
iperf3 -c 192.168.20.10 -t 60

# 6. NFSæ€§èƒ½æµ‹è¯•
echo ""
echo "=== NFSæ€§èƒ½æµ‹è¯• ==="
time dd if=/dev/zero of=/mnt/nfs/testfile bs=1M count=5120
time dd if=/mnt/nfs/testfile of=/dev/null bs=1M
rm -f /mnt/nfs/testfile

# 7. iSCSIæ€§èƒ½æµ‹è¯•
echo ""
echo "=== iSCSIæ€§èƒ½æµ‹è¯• ==="
fio --name=iscsi-test --ioengine=libaio --iodepth=128 --rw=randread \
    --bs=4k --direct=1 --size=10G --numjobs=4 --runtime=60 \
    --group_reporting --filename=/dev/disk/by-path/ip-*-iscsi-*-lun-0

echo ""
echo "========================================="
echo "  æµ‹è¯•å®Œæˆ"
echo "========================================="
```

**æ€§èƒ½åŸºå‡†å‚è€ƒ**:

```yaml
IOPSåŸºå‡†:
  HDD (7.2K):
    éšæœºè¯»: 100-150 IOPS
    éšæœºå†™: 80-120 IOPS
  
  SSD (SATA):
    éšæœºè¯»: 80K-100K IOPS
    éšæœºå†™: 60K-80K IOPS
  
  NVMe SSD:
    éšæœºè¯»: 500K-1M IOPS
    éšæœºå†™: 300K-800K IOPS

å»¶è¿ŸåŸºå‡†:
  HDD: 5-10ms
  SATA SSD: 0.1-0.5ms
  NVMe SSD: 0.01-0.1ms

ååé‡åŸºå‡†:
  HDD (å•ç›˜): 150-200 MB/s
  SATA SSD: 500-600 MB/s
  NVMe SSD: 3000-7000 MB/s
  10GbEç½‘ç»œ: 1100-1200 MB/s
  25GbEç½‘ç»œ: 2800-3000 MB/s

ç½‘ç»œå»¶è¿Ÿ:
  åŒæœºæ¶: <0.1ms
  åŒäº¤æ¢æœº: <1ms
  è·¨äº¤æ¢æœº: 1-5ms
```

---

## ç›‘æ§ä¸è¯Šæ–­

```bash
#!/bin/bash
# å­˜å‚¨æ€§èƒ½ç›‘æ§è„šæœ¬

echo "========================================="
echo "  å­˜å‚¨æ€§èƒ½å®æ—¶ç›‘æ§"
echo "========================================="
echo ""

# 1. iostat - IOç»Ÿè®¡
echo "=== iostat (5ç§’é—´éš”) ==="
iostat -xz 5 3

# 2. iotop - IOè¿›ç¨‹ç›‘æ§
echo ""
echo "=== iotop (å®æ—¶IO) ==="
iotop -oP -d 5 -n 3

# 3. dstat - ç»¼åˆç›‘æ§
echo ""
echo "=== dstat ==="
dstat -cdngy --disk-util --fs 5 3

# 4. sar - ç³»ç»Ÿæ´»åŠ¨æŠ¥å‘Š
echo ""
echo "=== sar (ç£ç›˜IO) ==="
sar -d 5 3

# 5. vmstat - è™šæ‹Ÿå†…å­˜ç»Ÿè®¡
echo ""
echo "=== vmstat ==="
vmstat 5 3

# 6. ç£ç›˜SMARTå¥åº·
echo ""
echo "=== SMARTå¥åº·çŠ¶æ€ ==="
for disk in /dev/sd?; do
    echo "Disk: $disk"
    smartctl -H $disk
    smartctl -A $disk | grep -E "Reallocated_Sector_Ct|Current_Pending_Sector|Offline_Uncorrectable"
done

# 7. æŸ¥çœ‹IOç­‰å¾…
echo ""
echo "=== è¿›ç¨‹IOç­‰å¾… ==="
ps aux | awk '$8 == "D" {print}'

# 8. å—è®¾å¤‡é˜Ÿåˆ—æ·±åº¦
echo ""
echo "=== é˜Ÿåˆ—æ·±åº¦ ==="
for dev in /sys/block/sd?; do
    echo "$(basename $dev): $(cat $dev/device/queue_depth)"
done

# 9. NFSç»Ÿè®¡ (å¦‚æœä½¿ç”¨NFS)
if mount | grep -q nfs; then
    echo ""
    echo "=== NFSç»Ÿè®¡ ==="
    nfsstat -c
    nfsstat -m
fi

# 10. ç½‘ç»œç»Ÿè®¡
echo ""
echo "=== ç½‘ç»œç»Ÿè®¡ ==="
netstat -i
ss -s

echo ""
echo "========================================="
echo "  ç›‘æ§å®Œæˆ"
echo "========================================="
```

**ç›‘æ§æŒ‡æ ‡è§£è¯»**:

```yaml
iostatå…³é”®æŒ‡æ ‡:
  %util:
    è¯´æ˜: è®¾å¤‡åˆ©ç”¨ç‡
    è­¦å‘Š: >80%
    ä¸¥é‡: >95%
  
  await:
    è¯´æ˜: å¹³å‡ç­‰å¾…æ—¶é—´ (ms)
    æ­£å¸¸: HDD <10ms, SSD <1ms
    è­¦å‘Š: HDD >20ms, SSD >5ms
  
  svctm:
    è¯´æ˜: å¹³å‡æœåŠ¡æ—¶é—´ (ms)
    æ³¨æ„: æ–°ç‰ˆæœ¬å·²å¼ƒç”¨
  
  r/s, w/s:
    è¯´æ˜: æ¯ç§’è¯»å†™æ“ä½œæ•°
    å¯¹æ¯”: ä¸è®¾å¤‡è§„æ ¼

iotopæŒ‡æ ‡:
  DISK READ/WRITE:
    è¯´æ˜: å®é™…ç£ç›˜è¯»å†™
    ç”¨é€”: è¯†åˆ«é«˜IOè¿›ç¨‹
  
  SWAPIN:
    è­¦å‘Š: >0 (è¡¨ç¤ºå†…å­˜ä¸è¶³)

ç›‘æ§å‘Šè­¦é˜ˆå€¼:
  IOPS:
    è­¦å‘Š: >è®¾å¤‡é¢å®šå€¼80%
    ä¸¥é‡: >è®¾å¤‡é¢å®šå€¼95%
  
  å»¶è¿Ÿ:
    HDD:
      è­¦å‘Š: >15ms
      ä¸¥é‡: >30ms
    SSD:
      è­¦å‘Š: >2ms
      ä¸¥é‡: >10ms
  
  é˜Ÿåˆ—æ·±åº¦:
    è­¦å‘Š: æŒç»­æ»¡è½½
    ä¸¥é‡: æŒç»­æ»¡è½½+é«˜å»¶è¿Ÿ
  
  ç£ç›˜åˆ©ç”¨ç‡:
    è­¦å‘Š: >80%
    ä¸¥é‡: >90%
  
  å®¹é‡:
    è­¦å‘Š: >75%
    ä¸¥é‡: >85%
```

---

## æ•…éšœæ’æŸ¥

```yaml
å¸¸è§æ€§èƒ½é—®é¢˜:
  é—®é¢˜1: ç£ç›˜IOé«˜å»¶è¿Ÿ
    ç°è±¡:
      iostatæ˜¾ç¤ºé«˜await
      åº”ç”¨å“åº”æ…¢
    
    æ’æŸ¥:
      1. è¯†åˆ«é«˜IOè¿›ç¨‹
         iotop -oP
      
      2. æ£€æŸ¥ç£ç›˜å¥åº·
         smartctl -a /dev/sda
      
      3. æŸ¥çœ‹é˜Ÿåˆ—æ·±åº¦
         cat /sys/block/sda/device/queue_depth
      
      4. æ£€æŸ¥RAIDçŠ¶æ€
         MegaCli -LDInfo -Lall -aALL
    
    è§£å†³:
      - ä¼˜åŒ–åº”ç”¨æŸ¥è¯¢
      - å¢åŠ ç¼“å­˜
      - æ›´æ¢æ…¢ç›˜
      - å‡çº§åˆ°SSD
  
  é—®é¢˜2: IOPSè¾¾åˆ°ç“¶é¢ˆ
    ç°è±¡:
      IOPSä¸å†å¢é•¿
      é˜Ÿåˆ—æ·±åº¦æŒç»­é«˜
    
    æ’æŸ¥:
      1. ç¡®è®¤ç£ç›˜è§„æ ¼
      2. æ£€æŸ¥æ§åˆ¶å™¨é™åˆ¶
      3. æŸ¥çœ‹ç½‘ç»œå¸¦å®½ (SAN/NAS)
      4. æ£€æŸ¥CPUè´Ÿè½½
    
    è§£å†³:
      - å¢åŠ ç£ç›˜æ•°é‡ (RAID0/10)
      - å‡çº§åˆ°æ›´å¿«ç£ç›˜
      - å¢åŠ é˜Ÿåˆ—æ·±åº¦
      - åˆ†æ•£è´Ÿè½½
  
  é—®é¢˜3: ç½‘ç»œå­˜å‚¨æ€§èƒ½å·®
    ç°è±¡:
      NFS/iSCSIå»¶è¿Ÿé«˜
      ååé‡ä½
    
    æ’æŸ¥:
      1. æµ‹è¯•ç½‘ç»œå»¶è¿Ÿ
         ping -c 100 <storage-ip>
      
      2. æµ‹è¯•å¸¦å®½
         iperf3 -c <storage-ip>
      
      3. æ£€æŸ¥MTU
         ip link show
      
      4. æŸ¥çœ‹ä¸¢åŒ…
         netstat -i
    
    è§£å†³:
      - å¯ç”¨Jumbo Frame
      - å‡çº§ç½‘ç»œåˆ°10/25GbE
      - æ£€æŸ¥äº¤æ¢æœºé…ç½®
      - ä¼˜åŒ–TCPå‚æ•°
  
  é—®é¢˜4: è™šæ‹ŸæœºIOæ€§èƒ½å·®
    ç°è±¡:
      VMå†…IOPSä½
      åº”ç”¨æ…¢
    
    æ’æŸ¥:
      1. æ£€æŸ¥è™šæ‹Ÿç£ç›˜ç±»å‹
      2. æŸ¥çœ‹å­˜å‚¨ç­–ç•¥
      3. æ£€æŸ¥å…±äº«äº‰ç”¨
      4. æŸ¥çœ‹å¿«ç…§é“¾
    
    è§£å†³:
      - ä½¿ç”¨Thick Eager Zeroed
      - å¯ç”¨PVSCSI (VMware)
      - åˆ é™¤æ—§å¿«ç…§
      - è¿ç§»åˆ°æ€§èƒ½æ›´å¥½å­˜å‚¨
  
  é—®é¢˜5: æ•°æ®åº“IOç­‰å¾…é«˜
    ç°è±¡:
      æ•°æ®åº“æ…¢æŸ¥è¯¢
      IO waité«˜
    
    æ’æŸ¥:
      1. åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—
      2. æ£€æŸ¥ç´¢å¼•
      3. æŸ¥çœ‹IOæ¨¡å¼
         iostat -x 1
      
      4. æ£€æŸ¥ç¼“å†²æ± å‘½ä¸­ç‡
    
    è§£å†³:
      - ä¼˜åŒ–SQLæŸ¥è¯¢
      - æ·»åŠ ç´¢å¼•
      - å¢åŠ ç¼“å†²æ± 
      - æ•°æ®åˆ†åŒº
      - ä½¿ç”¨SSD

è¯Šæ–­å·¥å…·:
  å®æ—¶ç›‘æ§:
    iostat -xz 1
    iotop -oP
    atop
  
  å†å²æ•°æ®:
    sar -d
    Grafana + Prometheus
  
  æ·±åº¦åˆ†æ:
    blktrace / blkparse
    strace -e trace=file
    perf record / perf report
  
  ç£ç›˜å¥åº·:
    smartctl -a /dev/sda
    badblocks -sv /dev/sda
```

---

## ç›¸å…³æ–‡æ¡£

- [å­˜å‚¨ç±»å‹ä¸é€‰å‹æ ‡å‡†](01_å­˜å‚¨ç±»å‹ä¸é€‰å‹æ ‡å‡†.md)
- [iSCSIé…ç½®ä¸ä¼˜åŒ–](02_iSCSIé…ç½®ä¸ä¼˜åŒ–.md)
- [NFSé…ç½®ä¸ä¼˜åŒ–](03_NFSé…ç½®ä¸ä¼˜åŒ–.md)
- [VMware vSANé…ç½®](04_VMware_vSANé…ç½®.md)
- [Cephåˆ†å¸ƒå¼å­˜å‚¨](05_Cephåˆ†å¸ƒå¼å­˜å‚¨.md)
- [å­˜å‚¨å®¹ç¾ä¸å¤‡ä»½](07_å­˜å‚¨å®¹ç¾ä¸å¤‡ä»½.md)

---

**æ›´æ–°æ—¶é—´**: 2025-10-19  
**æ–‡æ¡£ç‰ˆæœ¬**: v3.0  
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
