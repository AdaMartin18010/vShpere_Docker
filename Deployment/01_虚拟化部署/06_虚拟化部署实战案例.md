# è™šæ‹ŸåŒ–éƒ¨ç½²å®Œæ•´å®æˆ˜æ¡ˆä¾‹

> **è¿”å›**: [è™šæ‹ŸåŒ–éƒ¨ç½²é¦–é¡µ](README.md) | [éƒ¨ç½²æŒ‡å—é¦–é¡µ](../00_ç´¢å¼•å¯¼èˆª/README.md)

---

## ğŸ“‹ ç›®å½•

- [è™šæ‹ŸåŒ–éƒ¨ç½²å®Œæ•´å®æˆ˜æ¡ˆä¾‹](#è™šæ‹ŸåŒ–éƒ¨ç½²å®Œæ•´å®æˆ˜æ¡ˆä¾‹)
  - [ğŸ“‹ ç›®å½•](#-ç›®å½•)
  - [æ¡ˆä¾‹æ¦‚è¿°](#æ¡ˆä¾‹æ¦‚è¿°)
  - [æ¡ˆä¾‹ä¸€: ä¸­å°ä¼ä¸šVMware vSphereéƒ¨ç½²](#æ¡ˆä¾‹ä¸€-ä¸­å°ä¼ä¸švmware-vsphereéƒ¨ç½²)
    - [ä¸šåŠ¡éœ€æ±‚åˆ†æ](#ä¸šåŠ¡éœ€æ±‚åˆ†æ)
    - [ç¡¬ä»¶é€‰å‹ä¸é‡‡è´­](#ç¡¬ä»¶é€‰å‹ä¸é‡‡è´­)
    - [éƒ¨ç½²å®æ–½æ­¥éª¤](#éƒ¨ç½²å®æ–½æ­¥éª¤)
    - [é…ç½®éªŒè¯ä¸æµ‹è¯•](#é…ç½®éªŒè¯ä¸æµ‹è¯•)
  - [æ¡ˆä¾‹äºŒ: äº’è”ç½‘å…¬å¸KVMè™šæ‹ŸåŒ–é›†ç¾¤](#æ¡ˆä¾‹äºŒ-äº’è”ç½‘å…¬å¸kvmè™šæ‹ŸåŒ–é›†ç¾¤)
    - [ä¸šåŠ¡éœ€æ±‚åˆ†æ](#ä¸šåŠ¡éœ€æ±‚åˆ†æ-1)
    - [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
    - [éƒ¨ç½²å®æ–½](#éƒ¨ç½²å®æ–½)
    - [è‡ªåŠ¨åŒ–è¿ç»´](#è‡ªåŠ¨åŒ–è¿ç»´)
  - [æ¡ˆä¾‹ä¸‰: é‡‘èè¡Œä¸šè¶…èåˆHCIæ–¹æ¡ˆ](#æ¡ˆä¾‹ä¸‰-é‡‘èè¡Œä¸šè¶…èåˆhciæ–¹æ¡ˆ)
    - [ä¸šåŠ¡éœ€æ±‚åˆ†æ](#ä¸šåŠ¡éœ€æ±‚åˆ†æ-2)
    - [vSANæ¶æ„è®¾è®¡](#vsanæ¶æ„è®¾è®¡)
    - [éƒ¨ç½²å®æ–½](#éƒ¨ç½²å®æ–½-1)
    - [é«˜å¯ç”¨éªŒè¯](#é«˜å¯ç”¨éªŒè¯)
  - [æ¡ˆä¾‹å››: æ··åˆäº‘è™šæ‹ŸåŒ–æ¶æ„](#æ¡ˆä¾‹å››-æ··åˆäº‘è™šæ‹ŸåŒ–æ¶æ„)
    - [ä¸šåŠ¡åœºæ™¯](#ä¸šåŠ¡åœºæ™¯)
    - [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡-1)
    - [éƒ¨ç½²å®æ–½](#éƒ¨ç½²å®æ–½-2)
  - [å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)
  - [æœ€ä½³å®è·µæ€»ç»“](#æœ€ä½³å®è·µæ€»ç»“)
    - [ç¡¬ä»¶é€‰å‹](#ç¡¬ä»¶é€‰å‹)
    - [è½¯ä»¶é…ç½®](#è½¯ä»¶é…ç½®)
    - [è¿ç»´ç®¡ç†](#è¿ç»´ç®¡ç†)
    - [å®‰å…¨åŠ å›º](#å®‰å…¨åŠ å›º)

---

## æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›4ä¸ªçœŸå®çš„è™šæ‹ŸåŒ–éƒ¨ç½²æ¡ˆä¾‹ï¼Œæ¶µç›–ä¸åŒè§„æ¨¡å’Œéœ€æ±‚åœºæ™¯ï¼š

| æ¡ˆä¾‹ | é€‚ç”¨åœºæ™¯ | è§„æ¨¡ | æŠ€æœ¯æ ˆ | é¢„ç®— |
|------|---------|------|--------|------|
| æ¡ˆä¾‹ä¸€ | ä¸­å°ä¼ä¸š | 50-100 VM | VMware vSphere | Â¥50ä¸‡ |
| æ¡ˆä¾‹äºŒ | äº’è”ç½‘å…¬å¸ | 500+ VM | KVM + Ceph | Â¥200ä¸‡ |
| æ¡ˆä¾‹ä¸‰ | é‡‘èè¡Œä¸š | 200 VM | vSAN HCI | Â¥350ä¸‡ |
| æ¡ˆä¾‹å›› | æ··åˆäº‘ | 300 VM | VMware + å…¬æœ‰äº‘ | Â¥150ä¸‡ |

---

## æ¡ˆä¾‹ä¸€: ä¸­å°ä¼ä¸šVMware vSphereéƒ¨ç½²

### ä¸šåŠ¡éœ€æ±‚åˆ†æ

**ä¼ä¸šèƒŒæ™¯**:

- åˆ¶é€ ä¸šä¼ä¸šï¼Œå‘˜å·¥500äºº
- ç°æœ‰åº”ç”¨: ERPã€OAã€CRMã€æ–‡ä»¶æœåŠ¡å™¨
- ç›®æ ‡: æ•´åˆ20å°ç‰©ç†æœåŠ¡å™¨åˆ°è™šæ‹ŸåŒ–å¹³å°
- é¢„æœŸVMæ•°é‡: 80å°

**æŠ€æœ¯éœ€æ±‚**:

```yaml
æ€§èƒ½è¦æ±‚:
  CPUæ€»æ ¸å¿ƒ: 200+ vCPU
  å†…å­˜æ€»é‡: 800GB+
  å­˜å‚¨å®¹é‡: 50TB (åŸå§‹)
  ç½‘ç»œå¸¦å®½: 10Gbps

å¯ç”¨æ€§è¦æ±‚:
  ä¸šåŠ¡è¿ç»­æ€§: 99.9%
  è®¡åˆ’å†…åœæœº: <4å°æ—¶/æœˆ
  æ•°æ®å¤‡ä»½: æ¯æ—¥å¤‡ä»½
  æ¢å¤æ—¶é—´: <4å°æ—¶

å®‰å…¨è¦æ±‚:
  ç½‘ç»œéš”ç¦»: VLANéš”ç¦»
  æ•°æ®åŠ å¯†: é™æ€åŠ å¯†
  è®¿é—®æ§åˆ¶: RBAC
  å®¡è®¡æ—¥å¿—: å®Œæ•´å®¡è®¡
```

### ç¡¬ä»¶é€‰å‹ä¸é‡‡è´­

**ä¸»æœºé…ç½®** (3å°Dell PowerEdge R750):

```yaml
æœåŠ¡å™¨é…ç½®:
  å‹å·: Dell PowerEdge R750
  æ•°é‡: 3å°
  
  CPUé…ç½®:
    å‹å·: 2x Intel Xeon Silver 4316 (20æ ¸ 2.3GHz)
    æ€»æ ¸å¿ƒ: 40æ ¸80çº¿ç¨‹/å°
    è™šæ‹ŸåŒ–ç‰¹æ€§: VT-x, VT-d, EPT
  
  å†…å­˜é…ç½®:
    å®¹é‡: 512GB DDR4-3200 ECC RDIMM
    é…ç½®: 16x 32GB (å¡«æ»¡æ‰€æœ‰é€šé“)
    é¢„ç•™æ‰©å±•: å¯æ‰©å±•è‡³1TB
  
  å­˜å‚¨é…ç½®:
    ç³»ç»Ÿç›˜: 2x 480GB SATA SSD (RAID1)
    ç¼“å­˜ç›˜: 2x 1.6TB NVMe SSD (vSANç¼“å­˜å±‚)
    å®¹é‡ç›˜: 6x 4TB SATA SSD (vSANå®¹é‡å±‚)
    RAIDå¡: PERC H755 (HBAæ¨¡å¼ç”¨äºvSAN)
  
  ç½‘ç»œé…ç½®:
    ç®¡ç†ç½‘ç»œ: 2x 1GbE (æ¿è½½, å†—ä½™)
    ä¸šåŠ¡ç½‘ç»œ: 2x 10GbE SFP+ (PCIeç½‘å¡, å†—ä½™)
    vMotionç½‘ç»œ: ä½¿ç”¨10GbEæ¥å£
    vSANç½‘ç»œ: ä½¿ç”¨10GbEæ¥å£
  
  ç”µæº: 2x 1100W ç™½é‡‘çº§å†—ä½™ç”µæº
  
  å•å°æˆæœ¬: Â¥95,000
  æ€»æˆæœ¬: Â¥285,000
```

**ç½‘ç»œè®¾å¤‡**:

```yaml
æ ¸å¿ƒäº¤æ¢æœº:
  å‹å·: Dell N3248TE-ON
  è§„æ ¼: 48x 1GbE + 4x 10GbE SFP+
  æ•°é‡: 2å° (å †å )
  æˆæœ¬: Â¥45,000
  
æ¥å…¥äº¤æ¢æœº:
  å‹å·: Dell N1548P
  è§„æ ¼: 48x 1GbE PoE+
  æ•°é‡: 3å°
  æˆæœ¬: Â¥30,000

ç½‘ç»œé…ä»¶:
  10Gå…‰çº¤æ¨¡å—: 12ä¸ª SFP+ SR
  ä¸‡å…†å…‰çº¤: 20ç±³ OM3
  ç½‘çº¿: Cat6A
  æˆæœ¬: Â¥15,000
```

**å­˜å‚¨ä¸å¤‡ä»½**:

```yaml
å¤‡ä»½å­˜å‚¨:
  å‹å·: Synology RS3621xs+
  é…ç½®: 12ç›˜ä½NAS
  ç¡¬ç›˜: 12x 8TB SATA HDD (RAID6)
  å¯ç”¨å®¹é‡: 80TB
  ç½‘ç»œ: 4x 1GbE (é“¾è·¯èšåˆ)
  æˆæœ¬: Â¥80,000

UPS:
  å‹å·: APC Smart-UPS SRT 10KVA
  æ•°é‡: 2å°
  æˆæœ¬: Â¥60,000
```

**è½¯ä»¶è®¸å¯**:

```yaml
VMwareè®¸å¯:
  vSphere Standard: 6 CPUè®¸å¯
  vCenter Standard: 1å®ä¾‹
  vSAN Standard: 6 CPUè®¸å¯
  æˆæœ¬: Â¥120,000

å¤‡ä»½è½¯ä»¶:
  Veeam Backup & Replication Standard
  è®¸å¯: 100 VM
  æˆæœ¬: Â¥45,000
```

**æ€»æˆæœ¬æ±‡æ€»**:

```text
ä¸»æœº: Â¥285,000
ç½‘ç»œ: Â¥90,000
å­˜å‚¨: Â¥80,000
UPS: Â¥60,000
è½¯ä»¶: Â¥165,000
å®æ–½: Â¥50,000
============
æ€»è®¡: Â¥730,000
```

### éƒ¨ç½²å®æ–½æ­¥éª¤

**é˜¶æ®µ1: ç¡¬ä»¶éƒ¨ç½² (ç¬¬1-2å¤©)**:

```bash
# Day 1: ç¡¬ä»¶å®‰è£…
1. æœºæŸœè§„åˆ’ä¸è®¾å¤‡ä¸Šæ¶
   - æœåŠ¡å™¨: U1-U6 (æ¯å°2U)
   - äº¤æ¢æœº: U40-U42
   - NAS: U38-U39
   - UPS: ç‹¬ç«‹æœºæŸœ

2. ç½‘ç»œå¸ƒçº¿
   - ç®¡ç†ç½‘ç»œ (VLAN 10): è¿æ¥åˆ°ç®¡ç†äº¤æ¢æœº
   - ä¸šåŠ¡ç½‘ç»œ (VLAN 20-50): 10GbEä¸‡å…†è¿æ¥
   - vMotion (VLAN 100): 10GbEä¸“ç”¨VLAN
   - vSAN (VLAN 200): 10GbEä¸“ç”¨VLAN

3. ç”µæºè¿æ¥
   - åŒç”µæºåˆ†åˆ«è¿æ¥ä¸¤å°UPS
   - éªŒè¯ç”µæºå†—ä½™

# Day 2: BIOSé…ç½®
esxcli system settings advanced list
```

**BIOSå…³é”®é…ç½®**:

```yaml
è™šæ‹ŸåŒ–è®¾ç½®:
  Intel VT-x: Enabled
  Intel VT-d: Enabled
  SR-IOV: Enabled (å¦‚éœ€PCIeç›´é€š)

ç”µæºç®¡ç†:
  Power Profile: Maximum Performance
  C-States: Disabled
  P-States: Disabled
  Turbo Boost: Enabled

å†…å­˜è®¾ç½®:
  Node Interleaving: Disabled (å¯ç”¨NUMA)
  Memory Operating Mode: Optimizer Mode
  Memory Patrol Scrub: Enabled

å¯åŠ¨é€‰é¡¹:
  Boot Mode: UEFI
  Secure Boot: Disabled
```

**é˜¶æ®µ2: ESXiå®‰è£… (ç¬¬3å¤©)**:

```bash
# 1. å‡†å¤‡ESXiå®‰è£…ä»‹è´¨
# ä¸‹è½½ESXi 8.0 U2 ISO
# ä½¿ç”¨Rufusåˆ¶ä½œUSBå¯åŠ¨ç›˜

# 2. å®‰è£…ESXi (æ¯å°ä¸»æœº)
# - é€‰æ‹©å®‰è£…ç£ç›˜: RAID1 (2x 480GB SSD)
# - è®¾ç½®ç®¡ç†å‘˜å¯†ç 
# - é…ç½®ç®¡ç†ç½‘ç»œ:
#   ESXi-01: 192.168.10.11/24
#   ESXi-02: 192.168.10.12/24
#   ESXi-03: 192.168.10.13/24
#   Gateway: 192.168.10.1
#   DNS: 192.168.10.53

# 3. å®‰è£…åé…ç½® (SSHç™»å½•æ¯å°ä¸»æœº)
# å¯ç”¨SSHå’ŒShell
vim-cmd hostsvc/enable_ssh
vim-cmd hostsvc/enable_esx_shell

# é…ç½®NTP
esxcli system ntp set --server=ntp.aliyun.com --server=ntp1.aliyun.com
esxcli system ntp set --enabled=yes
esxcli system ntp start

# è®¾ç½®ä¸»æœºå
esxcli system hostname set --fqdn=esxi-01.company.local

# æ·»åŠ DNSæœåŠ¡å™¨
esxcli network ip dns server add --server=192.168.10.53
esxcli network ip dns search add --domain=company.local
```

**é˜¶æ®µ3: vCenteréƒ¨ç½² (ç¬¬4å¤©)**:

```bash
# 1. éƒ¨ç½²vCenter Server Appliance (VCSA)
# ä½¿ç”¨ä»»æ„ESXiä¸»æœºéƒ¨ç½²

# ä»Windowsç®¡ç†æœºæ‰§è¡Œ:
# æŒ‚è½½VCSA ISO
# è¿è¡Œ: vcsa-deploy\win32\installer.exe

# éƒ¨ç½²å‚æ•°:
VCSA_CONFIG = {
    "target_esxi": "192.168.10.11",
    "appliance_name": "vcenter.company.local",
    "vm_size": "small",  # small: 10ä¸»æœº/100VM
    "storage_size": "default",  # 740GB
    "network": {
        "ip": "192.168.10.10",
        "prefix": "24",
        "gateway": "192.168.10.1",
        "dns": "192.168.10.53",
        "fqdn": "vcenter.company.local"
    },
    "sso": {
        "domain": "vsphere.local",
        "password": "Strong@Pass123",
        "site_name": "Company-DC"
    }
}

# 2. è®¿é—®vCenterç®¡ç†ç•Œé¢
# https://vcenter.company.local:443
# ç”¨æˆ·: administrator@vsphere.local
```

**é˜¶æ®µ4: æ•°æ®ä¸­å¿ƒå’Œé›†ç¾¤é…ç½® (ç¬¬4å¤©)**:

```yaml
# åœ¨vCenterä¸­é…ç½®:

1. åˆ›å»ºæ•°æ®ä¸­å¿ƒ:
   åç§°: Company-DC
   ä½ç½®: Datacenter-01

2. åˆ›å»ºé›†ç¾¤:
   åç§°: Prod-Cluster
   ä½ç½®: Company-DC
   
   å¯ç”¨åŠŸèƒ½:
     vSphere HA:
       å‡†å…¥æ§åˆ¶: ä¸»æœºæ•…éšœå®¹é”™æ•°: 1
       ä¸»æœºç›‘æ§: å·²å¯ç”¨
       VMç›‘æ§: å·²å¯ç”¨
     
     vSphere DRS:
       è‡ªåŠ¨åŒ–çº§åˆ«: å…¨è‡ªåŠ¨
       è¿ç§»é˜ˆå€¼: ä¿å®ˆ
       VMåˆ†å¸ƒ: å·²å¯ç”¨
     
     vSAN:
       åç»­é…ç½®

3. æ·»åŠ ä¸»æœºåˆ°é›†ç¾¤:
   - æ·»åŠ esxi-01.company.local (192.168.10.11)
   - æ·»åŠ esxi-02.company.local (192.168.10.12)
   - æ·»åŠ esxi-03.company.local (192.168.10.13)
   - ç»´æŠ¤æ¨¡å¼: å¦
```

**é˜¶æ®µ5: ç½‘ç»œé…ç½® (ç¬¬5å¤©)**:

```yaml
# åˆ†å¸ƒå¼äº¤æ¢æœºé…ç½®

1. åˆ›å»ºåˆ†å¸ƒå¼äº¤æ¢æœº:
   åç§°: DSwitch-Prod
   ç‰ˆæœ¬: 8.0.0
   ä¸Šè¡Œé“¾è·¯: 4ä¸ª (2x 1GbEç®¡ç† + 2x 10GbEä¸šåŠ¡)
   MTU: 9000 (å¯ç”¨Jumbo Frame)

2. æ·»åŠ ä¸»æœºåˆ°DSwitch:
   - æ·»åŠ æ‰€æœ‰3å°ESXiä¸»æœº
   - é…ç½®ç‰©ç†é€‚é…å™¨æ˜ å°„:
     vmnic0 -> Uplink1 (1GbE ç®¡ç†)
     vmnic1 -> Uplink2 (1GbE ç®¡ç†å†—ä½™)
     vmnic2 -> Uplink3 (10GbE ä¸šåŠ¡)
     vmnic3 -> Uplink4 (10GbE ä¸šåŠ¡å†—ä½™)

3. åˆ›å»ºç«¯å£ç»„:
   
   ç®¡ç†ç½‘ç»œ (å·²å­˜åœ¨ - è¿ç§»åˆ°DSwitch):
     åç§°: PG-Management
     VLAN: 10
     ç»‘å®š: vmnic0, vmnic1
     è´Ÿè½½å‡è¡¡: Route based on originating virtual port
   
   vMotionç½‘ç»œ:
     åç§°: PG-vMotion
     VLAN: 100
     ç»‘å®š: vmnic2, vmnic3
     è´Ÿè½½å‡è¡¡: Route based on physical NIC load
     æ³¨æ„: å‹¾é€‰"å¯ç”¨vMotionæµé‡"
   
   vSANç½‘ç»œ:
     åç§°: PG-vSAN
     VLAN: 200
     ç»‘å®š: vmnic2, vmnic3
     è´Ÿè½½å‡è¡¡: Route based on physical NIC load
     æ³¨æ„: å‹¾é€‰"å¯ç”¨vSANæµé‡"
   
   ç”Ÿäº§ä¸šåŠ¡ç½‘ç»œ:
     åç§°: PG-Production
     VLAN: 20
     ç»‘å®š: vmnic2, vmnic3
     è´Ÿè½½å‡è¡¡: Route based on originating virtual port
   
   æµ‹è¯•ç½‘ç»œ:
     åç§°: PG-Test
     VLAN: 30
     ç»‘å®š: vmnic2, vmnic3
   
   DMZç½‘ç»œ:
     åç§°: PG-DMZ
     VLAN: 50
     ç»‘å®š: vmnic2, vmnic3

4. é…ç½®VMkernelé€‚é…å™¨:
   
   æ¯å°ä¸»æœºåˆ›å»º:
     vmk1 - vMotion:
       IP: 192.168.100.11/24 (esxi-01)
       IP: 192.168.100.12/24 (esxi-02)
       IP: 192.168.100.13/24 (esxi-03)
       ç«¯å£ç»„: PG-vMotion
       æœåŠ¡: vMotion
     
     vmk2 - vSAN:
       IP: 192.168.200.11/24 (esxi-01)
       IP: 192.168.200.12/24 (esxi-02)
       IP: 192.168.200.13/24 (esxi-03)
       ç«¯å£ç»„: PG-vSAN
       æœåŠ¡: vSAN
```

**äº¤æ¢æœºVLANé…ç½®** (Ciscoç¤ºä¾‹):

```cisco
! æ ¸å¿ƒäº¤æ¢æœºé…ç½®
enable
configure terminal

! åˆ›å»ºVLANs
vlan 10
 name Management
vlan 20
 name Production
vlan 30
 name Test
vlan 50
 name DMZ
vlan 100
 name vMotion
vlan 200
 name vSAN

! é…ç½®Trunkç«¯å£è¿æ¥ESXiä¸»æœº
interface range GigabitEthernet1/0/1-6
 description ESXi-Hosts-1GbE
 switchport mode trunk
 switchport trunk native vlan 999
 switchport trunk allowed vlan 10,20,30,50,100,200
 spanning-tree portfast trunk

interface range TenGigabitEthernet1/0/1-6
 description ESXi-Hosts-10GbE
 switchport mode trunk
 switchport trunk native vlan 999
 switchport trunk allowed vlan 10,20,30,50,100,200
 mtu 9000
 spanning-tree portfast trunk

! å¯ç”¨Jumbo Frame
system mtu jumbo 9000

! ä¿å­˜é…ç½®
end
write memory
```

**é˜¶æ®µ6: vSANé…ç½® (ç¬¬6å¤©)**:

```yaml
# vSANé›†ç¾¤é…ç½®

1. å‡†å¤‡ç£ç›˜:
   æ¯å°ä¸»æœºç£ç›˜ç»„:
     ç¼“å­˜å±‚: 2x 1.6TB NVMe SSD
     å®¹é‡å±‚: 6x 4TB SATA SSD
   
   éªŒè¯ç£ç›˜:
     - æ£€æŸ¥ç£ç›˜æ˜¯å¦è¢«è¯†åˆ«
     - ç¡®è®¤HBAæ¨¡å¼ (ä¸ä½¿ç”¨RAID)
     - éªŒè¯SSDæ ‡è®°æ­£ç¡®

2. å¯ç”¨vSAN:
   é›†ç¾¤ -> é…ç½® -> vSAN -> æœåŠ¡
   - å‹¾é€‰"å¯ç”¨vSAN"
   - ç±»å‹: å•ç«™ç‚¹é›†ç¾¤
   - å»é‡å’Œå‹ç¼©: å¯ç”¨
   - åŠ å¯†: å¯ç”¨ (ä½¿ç”¨vCenterå¯†é’¥)

3. åˆ›å»ºç£ç›˜ç»„:
   æ¯å°ä¸»æœº:
     ç£ç›˜ç»„1:
       ç¼“å­˜: 1x 1.6TB NVMe
       å®¹é‡: 3x 4TB SATA SSD
     
     ç£ç›˜ç»„2:
       ç¼“å­˜: 1x 1.6TB NVMe
       å®¹é‡: 3x 4TB SATA SSD

4. vSANåŸå§‹å®¹é‡è®¡ç®—:
   å®¹é‡ç›˜æ€»é‡: 3å° x 6å— x 4TB = 72TB
   å»é‡å‹ç¼©æ¯”: çº¦1.5x
   RAIDå®¹é”™: FTT=1 RAID1 (50%ç©ºé—´)
   å®é™…å¯ç”¨: 72TB x 1.5 / 2 = ~54TB

5. åˆ›å»ºå­˜å‚¨ç­–ç•¥:
   
   ç­–ç•¥1 - ç”Ÿäº§å…³é”®ä¸šåŠ¡:
     åç§°: vSAN-Production-FTT1
     æ•…éšœå®¹å¿: FTT=1 (RAID1é•œåƒ)
     æ¯å¯¹è±¡ç£ç›˜æ¡å¸¦æ•°: 1
     å¯¹è±¡ç©ºé—´é¢„ç•™: 50% (åšç½®å¤‡)
     é—ªå­˜è¯»å–ç¼“å­˜é¢„ç•™: 10%
   
   ç­–ç•¥2 - ä¸€èˆ¬ä¸šåŠ¡:
     åç§°: vSAN-Standard-FTT1
     æ•…éšœå®¹å¿: FTT=1 (RAID1é•œåƒ)
     æ¯å¯¹è±¡ç£ç›˜æ¡å¸¦æ•°: 1
     å¯¹è±¡ç©ºé—´é¢„ç•™: 0% (ç²¾ç®€ç½®å¤‡)
   
   ç­–ç•¥3 - æµ‹è¯•å¼€å‘:
     åç§°: vSAN-Test-FTT0
     æ•…éšœå®¹å¿: FTT=0 (æ— å†—ä½™)
     å¯¹è±¡ç©ºé—´é¢„ç•™: 0%

6. åˆ›å»ºvSANæ•°æ®å­˜å‚¨:
   åç§°: vsanDatastore
   å®¹é‡: ä¼šè‡ªåŠ¨æ˜¾ç¤ºå¯ç”¨å®¹é‡
   é»˜è®¤ç­–ç•¥: vSAN-Standard-FTT1
```

**é˜¶æ®µ7: è™šæ‹Ÿæœºæ¨¡æ¿åˆ›å»º (ç¬¬7å¤©)**:

```bash
# 1. åˆ›å»ºWindows Server 2022æ¨¡æ¿

# åˆ›å»ºæ–°è™šæ‹Ÿæœº:
VM_CONFIG_WIN = {
    "name": "Template-Win2022",
    "guest_os": "Microsoft Windows Server 2022 (64-bit)",
    "cpu": 2,
    "memory": 4096,  # MB
    "disk": 60,  # GB
    "network": "PG-Production",
    "datastore": "vsanDatastore",
    "storage_policy": "vSAN-Standard-FTT1"
}

# å®‰è£…Windows Server 2022:
# - æŒ‚è½½ISO
# - å®‰è£…æ“ä½œç³»ç»Ÿ
# - æ¿€æ´»Windows
# - å®‰è£…VMware Tools
# - è¿è¡ŒWindows Update

# ç³»ç»Ÿä¼˜åŒ–:
# ç¦ç”¨IPv6 (å¦‚ä¸ä½¿ç”¨)
Disable-NetAdapterBinding -Name "*" -ComponentID ms_tcpip6

# ç¦ç”¨ä¼‘çœ 
powercfg /h off

# è®¾ç½®ç”µæºè®¡åˆ’ä¸ºé«˜æ€§èƒ½
powercfg /s 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c

# ä¼˜åŒ–æœåŠ¡
Get-Service -Name "wuauserv" | Set-Service -StartupType Manual

# è¿è¡ŒSysprep:
C:\Windows\System32\Sysprep\sysprep.exe /oobe /generalize /shutdown

# è½¬æ¢ä¸ºæ¨¡æ¿:
# å³é”®VM -> æ¨¡æ¿ -> è½¬æ¢ä¸ºæ¨¡æ¿


# 2. åˆ›å»ºLinux (Rocky Linux 9) æ¨¡æ¿

VM_CONFIG_LINUX = {
    "name": "Template-Rocky9",
    "guest_os": "Red Hat Enterprise Linux 9 (64-bit)",
    "cpu": 2,
    "memory": 2048,
    "disk": 30,
    "network": "PG-Production",
    "datastore": "vsanDatastore"
}

# å®‰è£…Rocky Linux 9
# æœ€å°åŒ–å®‰è£… + æ ‡å‡†ç³»ç»Ÿå·¥å…·

# SSHç™»å½•åæ‰§è¡Œä¼˜åŒ–è„šæœ¬:
cat > /root/vm-optimize.sh << 'EOF'
#!/bin/bash

# æ›´æ–°ç³»ç»Ÿ
dnf update -y

# å®‰è£…å¿…è¦å·¥å…·
dnf install -y \
    vim \
    wget \
    curl \
    net-tools \
    bind-utils \
    open-vm-tools \
    perl

# å¯ç”¨open-vm-tools
systemctl enable --now vmtoolsd

# é…ç½®ç½‘ç»œ
nmcli connection modify ens192 connection.autoconnect yes

# ç¦ç”¨SELinux (å¯é€‰)
sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config

# é…ç½®æ—¶é—´åŒæ­¥
timedatectl set-timezone Asia/Shanghai
systemctl enable --now chronyd

# å†…æ ¸å‚æ•°ä¼˜åŒ–
cat >> /etc/sysctl.conf << 'SYSCTL'
# ç½‘ç»œä¼˜åŒ–
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.tcp_max_syn_backlog = 8192
net.ipv4.tcp_tw_reuse = 1
net.core.somaxconn = 32768

# æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
fs.file-max = 2097152
SYSCTL

sysctl -p

# èµ„æºé™åˆ¶
cat >> /etc/security/limits.conf << 'LIMITS'
* soft nofile 65536
* hard nofile 65536
* soft nproc 65536
* hard nproc 65536
LIMITS

# æ¸…ç†å†å²
history -c
rm -f /root/.bash_history
rm -f /home/*/.bash_history

echo "VMä¼˜åŒ–å®Œæˆ!"
EOF

chmod +x /root/vm-optimize.sh
/root/vm-optimize.sh

# å…³æœºå‰æ¸…ç†
virt-sysprep operations (æ‰‹åŠ¨):
- æ¸…ç†ç½‘ç»œé…ç½®ä¸­çš„MACåœ°å€
- æ¸…ç†machine-id
- æ¸…ç†SSHä¸»æœºå¯†é’¥

rm -f /etc/ssh/ssh_host_*
echo -n > /etc/machine-id
poweroff

# è½¬æ¢ä¸ºæ¨¡æ¿ (vCenterç•Œé¢æ“ä½œ)
```

### é…ç½®éªŒè¯ä¸æµ‹è¯•

**åŠŸèƒ½éªŒè¯æ¸…å•**:

```yaml
# é˜¶æ®µ1: åŸºç¡€åŠŸèƒ½éªŒè¯

1. vSphere HAæµ‹è¯•:
   æµ‹è¯•æ­¥éª¤:
     - åœ¨é›†ç¾¤ä¸­åˆ›å»ºæµ‹è¯•VM
     - æ¨¡æ‹Ÿä¸»æœºæ•…éšœ (æ‹”ç”µæº/å…³æœº)
     - éªŒè¯VMåœ¨å…¶ä»–ä¸»æœºè‡ªåŠ¨é‡å¯
     - æ—¶é—´: <5åˆ†é’Ÿ
   
   é¢„æœŸç»“æœ:
     âœ… VMåœ¨æ•…éšœåè‡ªåŠ¨é‡å¯
     âœ… é‡å¯æ—¶é—´ < 3åˆ†é’Ÿ
     âœ… ä¸šåŠ¡æ•°æ®æ— ä¸¢å¤±

2. vSphere DRSæµ‹è¯•:
   æµ‹è¯•æ­¥éª¤:
     - åœ¨ä¸€å°ä¸»æœºåˆ›å»ºå¤šä¸ªVMè´Ÿè½½
     - è§‚å¯ŸDRSè‡ªåŠ¨è´Ÿè½½å‡è¡¡
     - æ‰‹åŠ¨è§¦å‘vMotionè¿ç§»
   
   é¢„æœŸç»“æœ:
     âœ… DRSè‡ªåŠ¨å‡è¡¡è´Ÿè½½
     âœ… vMotionè¿ç§»æˆåŠŸ
     âœ… è¿ç§»è¿‡ç¨‹VMæ— æ„ŸçŸ¥

3. vSANå­˜å‚¨æµ‹è¯•:
   æµ‹è¯•æ­¥éª¤:
     - ä½¿ç”¨fioæµ‹è¯•IOPSå’Œå»¶è¿Ÿ
     - æ¨¡æ‹Ÿç£ç›˜æ•…éšœ (ç§»é™¤ä¸€å—ç›˜)
     - éªŒè¯æ•°æ®æ¢å¤
   
   æ€§èƒ½åŸºå‡†:
     éšæœºè¯»IOPS: >50,000
     éšæœºå†™IOPS: >30,000
     å»¶è¿Ÿ: <5ms
   
   é¢„æœŸç»“æœ:
     âœ… æ€§èƒ½ç¬¦åˆé¢„æœŸ
     âœ… ç£ç›˜æ•…éšœåæ•°æ®è‡ªåŠ¨æ¢å¤
     âœ… æ— æ•°æ®ä¸¢å¤±

4. ç½‘ç»œæ€§èƒ½æµ‹è¯•:
   æµ‹è¯•æ­¥éª¤:
     - ä½¿ç”¨iperf3æµ‹è¯•VMé—´ç½‘ç»œå¸¦å®½
     - æµ‹è¯•vMotionè¿ç§»é€Ÿåº¦
   
   é¢„æœŸç»“æœ:
     VMé—´å¸¦å®½: >9 Gbps (10GbEç½‘ç»œ)
     vMotioné€Ÿåº¦: >800 MB/s
```

**æ€§èƒ½æµ‹è¯•è„šæœ¬**:

```bash
# åœ¨Linux VMä¸­è¿è¡Œæ€§èƒ½æµ‹è¯•

#!/bin/bash
# storage-benchmark.sh

echo "=== vSANå­˜å‚¨æ€§èƒ½æµ‹è¯• ==="

# å®‰è£…fio
dnf install -y fio

# éšæœºè¯»æµ‹è¯•
echo "1. éšæœºè¯»IOPSæµ‹è¯• (4Kå—)"
fio --name=randread --ioengine=libaio --direct=1 --bs=4k --iodepth=64 \
    --rw=randread --size=10G --numjobs=4 --runtime=60 --group_reporting

# éšæœºå†™æµ‹è¯•
echo "2. éšæœºå†™IOPSæµ‹è¯• (4Kå—)"
fio --name=randwrite --ioengine=libaio --direct=1 --bs=4k --iodepth=64 \
    --rw=randwrite --size=10G --numjobs=4 --runtime=60 --group_reporting

# é¡ºåºè¯»æµ‹è¯•
echo "3. é¡ºåºè¯»å¸¦å®½æµ‹è¯• (1Må—)"
fio --name=seqread --ioengine=libaio --direct=1 --bs=1m --iodepth=32 \
    --rw=read --size=10G --runtime=60 --group_reporting

# é¡ºåºå†™æµ‹è¯•
echo "4. é¡ºåºå†™å¸¦å®½æµ‹è¯• (1Må—)"
fio --name=seqwrite --ioengine=libaio --direct=1 --bs=1m --iodepth=32 \
    --rw=write --size=10G --runtime=60 --group_reporting

echo "æ€§èƒ½æµ‹è¯•å®Œæˆ!"

# ç½‘ç»œæ€§èƒ½æµ‹è¯•
# åœ¨ä¸€å°VMè¿è¡ŒæœåŠ¡å™¨ç«¯:
iperf3 -s

# åœ¨å¦ä¸€å°VMè¿è¡Œå®¢æˆ·ç«¯:
iperf3 -c <server-ip> -t 60 -P 10
```

---

## æ¡ˆä¾‹äºŒ: äº’è”ç½‘å…¬å¸KVMè™šæ‹ŸåŒ–é›†ç¾¤

### ä¸šåŠ¡éœ€æ±‚åˆ†æ

**ä¼ä¸šèƒŒæ™¯**:

- äº’è”ç½‘æ¸¸æˆå…¬å¸
- æ—¥æ´»ç”¨æˆ·100ä¸‡+
- å¾®æœåŠ¡æ¶æ„,å®¹å™¨åŒ–éƒ¨ç½²
- éœ€è¦å¤§è§„æ¨¡è™šæ‹ŸåŒ–æ”¯æ’‘

**æŠ€æœ¯éœ€æ±‚**:

```yaml
è§„æ¨¡è¦æ±‚:
  ç‰©ç†ä¸»æœº: 20å°
  è™šæ‹Ÿæœºæ•°é‡: 500+
  å®¹å™¨èŠ‚ç‚¹: 100+

æ€§èƒ½è¦æ±‚:
  CPU: 2000+ vCPU
  å†…å­˜: 10TB+
  å­˜å‚¨: 500TB (Cephåˆ†å¸ƒå¼å­˜å‚¨)
  ç½‘ç»œ: 25Gbps

ç‰¹æ®Šéœ€æ±‚:
  å¼€æºæ–¹æ¡ˆ: é™ä½è®¸å¯æˆæœ¬
  è‡ªåŠ¨åŒ–: Ansible/Terraform
  ç›‘æ§: Prometheus + Grafana
  CI/CDé›†æˆ: Jenkins/GitLab
```

### æ¶æ„è®¾è®¡

**é›†ç¾¤æ¶æ„**:

```yaml
è®¡ç®—èŠ‚ç‚¹æ± :
  Webåº”ç”¨æ± :
    èŠ‚ç‚¹: 10å°
    è§„æ ¼: 2x AMD EPYC 7543 (32æ ¸) + 512GBå†…å­˜
    ç”¨é€”: Webåº”ç”¨VM
  
  æ•°æ®åº“æ± :
    èŠ‚ç‚¹: 5å°
    è§„æ ¼: 2x AMD EPYC 7643 (48æ ¸) + 1TBå†…å­˜
    ç”¨é€”: æ•°æ®åº“VM (MySQL/Redis)
  
  å®¹å™¨èŠ‚ç‚¹æ± :
    èŠ‚ç‚¹: 5å°
    è§„æ ¼: 2x AMD EPYC 7543 + 256GBå†…å­˜
    ç”¨é€”: Kubernetes WorkerèŠ‚ç‚¹

Cephå­˜å‚¨é›†ç¾¤:
  OSDèŠ‚ç‚¹: å¤ç”¨è®¡ç®—èŠ‚ç‚¹
  æ¯èŠ‚ç‚¹: 12x 4TB NVMe SSD
  æ€»å®¹é‡: 20èŠ‚ç‚¹ x 12 x 4TB = 960TBåŸå§‹
  å¯ç”¨å®¹é‡: ~320TB (3å‰¯æœ¬)
  
  MONèŠ‚ç‚¹: 3å°ç‹¬ç«‹èŠ‚ç‚¹
  MGRèŠ‚ç‚¹: ä¸MONå…±ç”¨
  
ç½‘ç»œæ¶æ„:
  ç®¡ç†ç½‘ç»œ: 1GbE
  ä¸šåŠ¡ç½‘ç»œ: 25GbE (åŒé“¾è·¯å†—ä½™)
  å­˜å‚¨ç½‘ç»œ: 25GbE (ä¸“ç”¨)
  
ç®¡ç†èŠ‚ç‚¹:
  KVMç®¡ç†: 3å° (WebVirtMgr/oVirt)
  Ansible: 1å°
  ç›‘æ§: 3å° (Prometheus HA)
```

### éƒ¨ç½²å®æ–½

**é˜¶æ®µ1: æ“ä½œç³»ç»Ÿéƒ¨ç½² (ä½¿ç”¨PXEè‡ªåŠ¨åŒ–)**:

```bash
# PXEæœåŠ¡å™¨é…ç½® (åœ¨ç®¡ç†èŠ‚ç‚¹)

# 1. å®‰è£…DHCP + TFTP + HTTPæœåŠ¡
dnf install -y dhcp-server tftp-server httpd syslinux

# 2. é…ç½®DHCP
cat > /etc/dhcp/dhcpd.conf << 'EOF'
subnet 192.168.10.0 netmask 255.255.255.0 {
    range 192.168.10.100 192.168.10.200;
    option routers 192.168.10.1;
    option domain-name-servers 192.168.10.53;
    next-server 192.168.10.5;  # TFTPæœåŠ¡å™¨IP
    filename "pxelinux.0";
}
EOF

# 3. å‡†å¤‡å®‰è£…é•œåƒ
mkdir -p /var/www/html/rocky9
mount -o loop Rocky-9.3-x86_64-dvd.iso /mnt
cp -r /mnt/* /var/www/html/rocky9/
umount /mnt

# 4. é…ç½®Kickstartè‡ªåŠ¨å®‰è£…
cat > /var/www/html/rocky9-ks.cfg << 'EOF'
# Rocky Linux 9 Kickstart for KVM Host

# ç³»ç»Ÿè¯­è¨€å’Œé”®ç›˜
lang en_US.UTF-8
keyboard us
timezone Asia/Shanghai --utc

# ç½‘ç»œé…ç½®
network --bootproto=dhcp --device=enp1s0 --onboot=on --ipv6=auto
network --hostname=kvm-node.cluster.local

# å®‰è£…æ¨¡å¼
text
install
url --url=http://192.168.10.5/rocky9/

# ç£ç›˜åˆ†åŒº
clearpart --all --initlabel
part /boot/efi --fstype=efi --size=512
part /boot --fstype=xfs --size=1024
part pv.01 --size=1 --grow
volgroup vg_system pv.01
logvol / --fstype=xfs --vgname=vg_system --name=lv_root --size=51200
logvol /var --fstype=xfs --vgname=vg_system --name=lv_var --size=20480
logvol swap --vgname=vg_system --name=lv_swap --size=16384

# è½¯ä»¶åŒ…é€‰æ‹©
%packages
@^minimal-environment
@virtualization-host-environment
@virtualization-platform
vim
wget
git
%end

# å®‰è£…åè„šæœ¬
%post
# å¯ç”¨åµŒå¥—è™šæ‹ŸåŒ–
echo "options kvm_intel nested=1" > /etc/modprobe.d/kvm-nested.conf

# ä¼˜åŒ–å†…æ ¸å‚æ•°
cat >> /etc/sysctl.conf << 'SYSCTL'
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
vm.swappiness = 10
vm.overcommit_memory = 1
SYSCTL

# ç¦ç”¨é˜²ç«å¢™ (æµ‹è¯•ç¯å¢ƒ)
systemctl disable firewalld

# å¯ç”¨libvirtd
systemctl enable libvirtd

# é…ç½®SSHå¯†é’¥ (ç”¨äºAnsibleç®¡ç†)
mkdir -p /root/.ssh
cat >> /root/.ssh/authorized_keys << 'SSH_KEY'
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABA... ansible-ç®¡ç†å¯†é’¥
SSH_KEY
chmod 600 /root/.ssh/authorized_keys

%end

reboot
EOF

# 5. å¯åŠ¨æœåŠ¡
systemctl enable --now dhcpd tftp httpd

# 6. æ‰¹é‡éƒ¨ç½²æ‰€æœ‰èŠ‚ç‚¹ (ç½‘ç»œPXEå¯åŠ¨)
```

**é˜¶æ®µ2: KVMä¸»æœºé…ç½® (Ansibleè‡ªåŠ¨åŒ–)**:

```yaml
# ansible/kvm-setup.yml

---
- name: KVMä¸»æœºæ ‡å‡†åŒ–é…ç½®
  hosts: kvm_hosts
  become: yes
  
  vars:
    bridge_interface: br0
    physical_interface: enp1s0
    storage_network_interface: enp2s0
  
  tasks:
    - name: å®‰è£…è™šæ‹ŸåŒ–è½¯ä»¶åŒ…
      dnf:
        name:
          - qemu-kvm
          - libvirt
          - libvirt-daemon-kvm
          - virt-install
          - virt-manager
          - virt-top
          - libguestfs-tools
          - python3-libvirt
        state: latest
    
    - name: å¯ç”¨å¹¶å¯åŠ¨libvirtd
      systemd:
        name: libvirtd
        enabled: yes
        state: started
    
    - name: é…ç½®ç½‘æ¡¥æ¥å£
      template:
        src: templates/ifcfg-br0.j2
        dest: /etc/sysconfig/network-scripts/ifcfg-{{ bridge_interface }}
      notify: restart network
    
    - name: é…ç½®ç‰©ç†æ¥å£
      template:
        src: templates/ifcfg-eth.j2
        dest: /etc/sysconfig/network-scripts/ifcfg-{{ physical_interface }}
      notify: restart network
    
    - name: é…ç½®libvirtç½‘ç»œ
      copy:
        content: |
          <network>
            <name>br0</name>
            <forward mode="bridge"/>
            <bridge name="br0"/>
          </network>
        dest: /tmp/br0.xml
    
    - name: å®šä¹‰libvirtç½‘ç»œ
      command: virsh net-define /tmp/br0.xml
      ignore_errors: yes
    
    - name: å¯åŠ¨libvirtç½‘ç»œ
      command: virsh net-start br0
      ignore_errors: yes
    
    - name: è®¾ç½®libvirtç½‘ç»œè‡ªå¯åŠ¨
      command: virsh net-autostart br0
    
    - name: åˆ›å»ºVMå­˜å‚¨æ± 
      command: |
        virsh pool-define-as local-pool dir - - - - "/var/lib/libvirt/images"
        virsh pool-build local-pool
        virsh pool-start local-pool
        virsh pool-autostart local-pool
      ignore_errors: yes
    
    - name: é…ç½®KVM CPUæ€§èƒ½æ¨¡å¼
      lineinfile:
        path: /etc/default/grub
        regexp: '^GRUB_CMDLINE_LINUX='
        line: 'GRUB_CMDLINE_LINUX="intel_iommu=on iommu=pt default_hugepagesz=1G hugepagesz=1G hugepages=32"'
      notify: rebuild grub
    
    - name: ä¼˜åŒ–KVMå‚æ•°
      blockinfile:
        path: /etc/sysctl.d/99-kvm.conf
        create: yes
        block: |
          # KVMä¼˜åŒ–
          vm.nr_hugepages = 4096
          vm.hugetlb_shm_group = 36
          kernel.sched_migration_cost_ns = 5000000
          kernel.sched_autogroup_enabled = 0
    
    - name: åº”ç”¨sysctlå‚æ•°
      command: sysctl -p /etc/sysctl.d/99-kvm.conf
  
  handlers:
    - name: restart network
      systemd:
        name: NetworkManager
        state: restarted
    
    - name: rebuild grub
      command: grub2-mkconfig -o /boot/grub2/grub.cfg

# æ‰§è¡Œéƒ¨ç½²:
# ansible-playbook -i inventory/production kvm-setup.yml
```

**é˜¶æ®µ3: Cephå­˜å‚¨é›†ç¾¤éƒ¨ç½²**:

```bash
# ä½¿ç”¨cephadméƒ¨ç½²Ceph Quincy

# 1. åœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å®‰è£…cephadm
dnf install -y centos-release-ceph-quincy
dnf install -y cephadm

# 2. åˆå§‹åŒ–Cephé›†ç¾¤
cephadm bootstrap \
  --mon-ip 192.168.10.11 \
  --cluster-network 192.168.20.0/24 \
  --public-network 192.168.10.0/24

# è¾“å‡º:
# Ceph Dashboard: https://192.168.10.11:8443/
# User: admin
# Password: <ç”Ÿæˆçš„å¯†ç >

# 3. æ·»åŠ å…¶ä»–èŠ‚ç‚¹
# å¤åˆ¶SSHå…¬é’¥åˆ°æ‰€æœ‰èŠ‚ç‚¹
ssh-copy-id root@192.168.10.12
ssh-copy-id root@192.168.10.13
# ... å…¶ä»–èŠ‚ç‚¹

# æ·»åŠ ä¸»æœºåˆ°é›†ç¾¤
ceph orch host add kvm-node-02 192.168.10.12
ceph orch host add kvm-node-03 192.168.10.13
# ... æ·»åŠ æ‰€æœ‰20å°èŠ‚ç‚¹

# 4. éƒ¨ç½²MONå®ˆæŠ¤è¿›ç¨‹ (è‡³å°‘3ä¸ª)
ceph orch apply mon --placement="kvm-node-01,kvm-node-02,kvm-node-03"

# 5. éƒ¨ç½²MGRå®ˆæŠ¤è¿›ç¨‹
ceph orch apply mgr --placement="kvm-node-01,kvm-node-02,kvm-node-03"

# 6. æ·»åŠ OSD (åœ¨æ¯ä¸ªèŠ‚ç‚¹æ·»åŠ 12å—NVMe SSD)
# è‡ªåŠ¨å‘ç°å¹¶æ·»åŠ æ‰€æœ‰å¯ç”¨ç£ç›˜
ceph orch apply osd --all-available-devices

# æˆ–æ‰‹åŠ¨æ·»åŠ ç‰¹å®šç£ç›˜:
for node in kvm-node-{01..20}; do
  for disk in nvme{0..11}n1; do
    ceph orch daemon add osd $node:/dev/$disk
  done
done

# 7. åˆ›å»ºRBDå­˜å‚¨æ± 
ceph osd pool create kvm-pool 128 128
ceph osd pool set kvm-pool size 3  # 3å‰¯æœ¬
ceph osd pool set kvm-pool min_size 2
ceph osd pool application enable kvm-pool rbd

# 8. åˆ›å»ºCeph RBDå®¢æˆ·ç«¯å¯†é’¥
ceph auth get-or-create client.kvm \
  mon 'allow r' \
  osd 'allow class-read object_prefix rbd_children, allow rwx pool=kvm-pool' \
  -o /etc/ceph/ceph.client.kvm.keyring

# 9. åœ¨KVMä¸»æœºé…ç½®Ceph
# åˆ†å‘é…ç½®æ–‡ä»¶åˆ°æ‰€æœ‰KVMä¸»æœº
for node in kvm-node-{01..20}; do
  scp /etc/ceph/ceph.conf $node:/etc/ceph/
  scp /etc/ceph/ceph.client.kvm.keyring $node:/etc/ceph/
done

# 10. éªŒè¯Cephé›†ç¾¤çŠ¶æ€
ceph -s
# é¢„æœŸè¾“å‡º:
#   cluster:
#     id:     xxx
#     health: HEALTH_OK
#   services:
#     mon: 3 daemons
#     mgr: 3 daemons
#     osd: 240 osds: 240 up, 240 in
#   data:
#     pools:   1 pools, 128 pgs
#     objects: 0 objects, 0 B
#     usage:   960 TB used, 0 B / 960 TB avail
```

### è‡ªåŠ¨åŒ–è¿ç»´

**VMè‡ªåŠ¨åŒ–åˆ›å»ºè„šæœ¬**:

```bash
#!/bin/bash
# create-vm-from-ceph.sh
# ä»Ceph RBDåˆ›å»ºKVMè™šæ‹Ÿæœº

VM_NAME=$1
VM_VCPU=${2:-4}
VM_MEMORY=${3:-8192}  # MB
VM_DISK=${4:-50}      # GB

if [ -z "$VM_NAME" ]; then
    echo "ç”¨æ³•: $0 <VMåç§°> [vCPUæ•°] [å†…å­˜MB] [ç£ç›˜GB]"
    exit 1
fi

echo "åˆ›å»ºè™šæ‹Ÿæœº: $VM_NAME"
echo "  vCPU: $VM_VCPU"
echo "  å†…å­˜: ${VM_MEMORY}MB"
echo "  ç£ç›˜: ${VM_DISK}GB"

# 1. åˆ›å»ºCeph RBDå·
echo "åˆ›å»ºCeph RBDå·..."
rbd create kvm-pool/${VM_NAME}-disk --size=${VM_DISK}G

# 2. æ˜ å°„RBDå·
rbd map kvm-pool/${VM_NAME}-disk

# 3. ä½¿ç”¨virt-installåˆ›å»ºVM
echo "åˆ›å»ºè™šæ‹Ÿæœº..."
virt-install \
  --name ${VM_NAME} \
  --virt-type kvm \
  --vcpus ${VM_VCPU} \
  --memory ${VM_MEMORY} \
  --disk path=/dev/rbd/kvm-pool/${VM_NAME}-disk,bus=virtio,cache=writeback \
  --network bridge=br0,model=virtio \
  --graphics vnc,listen=0.0.0.0 \
  --cdrom /var/lib/libvirt/images/Rocky-9.3-x86_64-dvd.iso \
  --os-variant rhel9.0 \
  --noautoconsole

echo "è™šæ‹Ÿæœº $VM_NAME åˆ›å»ºæˆåŠŸ!"
echo "ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹VNCç«¯å£:"
echo "  virsh vncdisplay $VM_NAME"
```

---

## æ¡ˆä¾‹ä¸‰: é‡‘èè¡Œä¸šè¶…èåˆHCIæ–¹æ¡ˆ

### ä¸šåŠ¡éœ€æ±‚åˆ†æ

**åˆè§„è¦æ±‚**:

```yaml
é‡‘èè¡Œä¸šç‰¹æ®Šè¦æ±‚:
  ç­‰ä¿ä¸‰çº§: å¿…é¡»æ»¡è¶³
  æ•°æ®åŠ å¯†: é™æ€+ä¼ è¾“åŠ å¯†
  å®¡è®¡æ—¥å¿—: å®Œæ•´æ“ä½œå®¡è®¡
  å®¹ç¾è¦æ±‚: åŒåŸåŒæ´» + å¼‚åœ°ç¾å¤‡
  å¯ç”¨æ€§: 99.99% (å¹´åœæœº<53åˆ†é’Ÿ)
  
ä¸šåŠ¡ç³»ç»Ÿ:
  æ ¸å¿ƒç³»ç»Ÿ: è´¦åŠ¡ã€æ”¯ä»˜ã€é£æ§
  æ¸ é“ç³»ç»Ÿ: ç½‘é“¶ã€æ‰‹æœºé“¶è¡Œã€ATM
  ç®¡ç†ç³»ç»Ÿ: CRMã€OAã€BIåˆ†æ
```

### vSANæ¶æ„è®¾è®¡

```yaml
åŒæ•°æ®ä¸­å¿ƒæ¶æ„:

ä¸»æ•°æ®ä¸­å¿ƒ (DC1):
  è®¡ç®—+å­˜å‚¨èŠ‚ç‚¹: 6å°
  è§„æ ¼: Dell PowerEdge R750
  CPU: 2x Intel Xeon Gold 6346 (16æ ¸)
  å†…å­˜: 768GB DDR4 ECC
  å­˜å‚¨: 2x 1.6TB NVMe (ç¼“å­˜) + 8x 3.84TB SAS SSD (å®¹é‡)
  ç½‘ç»œ: 4x 25GbE

å¤‡æ•°æ®ä¸­å¿ƒ (DC2):
  è®¡ç®—+å­˜å‚¨èŠ‚ç‚¹: 6å°
  é…ç½®åŒDC1

vSANé…ç½®:
  ç±»å‹: vSANå»¶ä¼¸é›†ç¾¤ (Stretched Cluster)
  æ•…éšœåŸŸ: DC1 (ä¸») + DC2 (è¾…) + è§è¯èŠ‚ç‚¹
  è§è¯èŠ‚ç‚¹: æ”¾ç½®åœ¨ç¬¬ä¸‰åœ° (äº‘ç«¯æˆ–ç¬¬ä¸‰æœºæˆ¿)
  æ•°æ®ä¿æŠ¤: FTT=1 RAID1 (ä¸»è¾…å„ä¸€ä»½å‰¯æœ¬)
  ç½‘ç»œå»¶è¿Ÿè¦æ±‚: <5ms (DC1 <-> DC2)
```

### éƒ¨ç½²å®æ–½

è¯¦ç»†é…ç½®å’ŒéªŒè¯è¿‡ç¨‹ç•¥ï¼Œå‚è€ƒæ¡ˆä¾‹ä¸€çš„éƒ¨ç½²æµç¨‹ï¼Œé¢å¤–æ³¨æ„ï¼š

```yaml
é‡‘èè¡Œä¸šé¢å¤–é…ç½®:

1. æ•°æ®åŠ å¯†:
   - vSANåŠ å¯†: å¯ç”¨
   - VMåŠ å¯†: å¯¹æ ¸å¿ƒä¸šåŠ¡VMå¯ç”¨
   - å¯†é’¥ç®¡ç†: å¤–éƒ¨KMS (å¦‚HyTrust/Thales)

2. ç½‘ç»œéš”ç¦»:
   - æ ¸å¿ƒåŒº: ä¸å‡ºäº’è”ç½‘
   - DMZåŒº: ä¸¥æ ¼ACLæ§åˆ¶
   - ç®¡ç†åŒº: è·³æ¿æœº+å ¡å’æœº

3. å®¡è®¡æ—¥å¿—:
   - vCenteræ“ä½œæ—¥å¿—: è½¬å‘åˆ°SIEM
   - ESXiç³»ç»Ÿæ—¥å¿—: é›†ä¸­æ”¶é›†
   - VMå®¡è®¡: å¼€å¯vCenter Change Tracking

4. å®¹ç¾æ¼”ç»ƒ:
   - é¢‘ç‡: æ¯å­£åº¦
   - ç±»å‹: è®¡åˆ’åˆ‡æ¢ + æ•…éšœåˆ‡æ¢
   - RTOç›®æ ‡: <30åˆ†é’Ÿ
   - RPOç›®æ ‡: <15åˆ†é’Ÿ
```

### é«˜å¯ç”¨éªŒè¯

```yaml
æµ‹è¯•åœºæ™¯1: å•å°ä¸»æœºæ•…éšœ
  æ“ä½œ: å…³é—­DC1ä¸€å°ä¸»æœº
  é¢„æœŸ: VMåœ¨å…¶ä»–ä¸»æœºé‡å¯ (<3åˆ†é’Ÿ)
  å®é™…: é€šè¿‡ âœ…

æµ‹è¯•åœºæ™¯2: å­˜å‚¨è®¾å¤‡æ•…éšœ
  æ“ä½œ: æ‹”é™¤ä¸€å—SSD
  é¢„æœŸ: vSANè‡ªåŠ¨é‡å»ºæ•°æ®
  å®é™…: é€šè¿‡ âœ…

æµ‹è¯•åœºæ™¯3: æ•°æ®ä¸­å¿ƒæ•…éšœ
  æ“ä½œ: æ–­å¼€DC1æ‰€æœ‰ç½‘ç»œ
  é¢„æœŸ: ä¸šåŠ¡åˆ‡æ¢åˆ°DC2 (<5åˆ†é’Ÿ)
  å®é™…: é€šè¿‡ âœ…

æµ‹è¯•åœºæ™¯4: ç¾éš¾æ¢å¤
  æ“ä½œ: ä»å¤‡ä»½æ¢å¤å®Œæ•´ä¸šåŠ¡ç³»ç»Ÿ
  é¢„æœŸ: RTO <4å°æ—¶
  å®é™…: é€šè¿‡ âœ…
```

---

## æ¡ˆä¾‹å››: æ··åˆäº‘è™šæ‹ŸåŒ–æ¶æ„

### ä¸šåŠ¡åœºæ™¯

```yaml
ä¼ä¸šèƒŒæ™¯:
  ç±»å‹: ç”µå•†å¹³å°
  ç‰¹ç‚¹: ä¸šåŠ¡æ³¢åŠ¨å¤§ (ä¿ƒé”€æœŸ10xæµé‡)
  
æ¶æ„ç›®æ ‡:
  æœ¬åœ°IDC: æ‰¿è½½å¸¸é©»ä¸šåŠ¡ (100å°VM)
  å…¬æœ‰äº‘: å¼¹æ€§æ‰©å±• (ä¿ƒé”€æœŸ+200å°VM)
  æ··åˆç®¡ç†: ç»Ÿä¸€ç®¡ç†æœ¬åœ°+äº‘ç«¯èµ„æº
```

### æ¶æ„è®¾è®¡

```yaml
æœ¬åœ°IDC:
  å¹³å°: VMware vSphere 8.0
  ä¸»æœº: 8å°é«˜é…æœåŠ¡å™¨
  å­˜å‚¨: vSAN
  
å…¬æœ‰äº‘:
  æä¾›å•†: é˜¿é‡Œäº‘/AWS/Azure
  æœåŠ¡: EC2/ECSå®ä¾‹
  
æ··åˆç®¡ç†:
  å·¥å…·: VMware Cloud Director / vRealize
  ç½‘ç»œ: VPN/ä¸“çº¿ (Aliyun Express Connect)
  ç›‘æ§: ç»Ÿä¸€ç›‘æ§å¹³å°
```

### éƒ¨ç½²å®æ–½

```yaml
é˜¶æ®µ1: æœ¬åœ°IDCéƒ¨ç½²
  - å‚è€ƒæ¡ˆä¾‹ä¸€éƒ¨ç½²vSphereç¯å¢ƒ

é˜¶æ®µ2: äº‘ç«¯ç½‘ç»œæ‰“é€š
  1. é…ç½®VPN/ä¸“çº¿:
     æœ¬åœ°: 192.168.0.0/16
     é˜¿é‡Œäº‘VPC: 172.16.0.0/16
     äº’è”: IPsec VPNæˆ–ä¸“çº¿
  
  2. è·¯ç”±é…ç½®:
     - æœ¬åœ°IDCè·¯ç”±è¡¨æ·»åŠ 172.16.0.0/16 -> VPN
     - é˜¿é‡Œäº‘VPCè·¯ç”±è¡¨æ·»åŠ 192.168.0.0/16 -> VPN

é˜¶æ®µ3: æ··åˆè´Ÿè½½å‡è¡¡
  - ä½¿ç”¨é˜¿é‡Œäº‘SLBæˆ–F5 BIG-IP
  - åç«¯æ± åŒ…å«æœ¬åœ°VM + äº‘ç«¯ECS
  - å¥åº·æ£€æŸ¥: HTTP/TCPæ¢æµ‹

é˜¶æ®µ4: è‡ªåŠ¨å¼¹æ€§ä¼¸ç¼©
  - ç›‘æ§æŒ‡æ ‡: CPU/å†…å­˜/è¯·æ±‚æ•°
  - æ‰©å®¹ç­–ç•¥: é˜ˆå€¼è§¦å‘äº‘ç«¯ECSå¯åŠ¨
  - ç¼©å®¹ç­–ç•¥: æµé‡ä¸‹é™åå›æ”¶ECS
```

---

## å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

```yaml
é—®é¢˜1: ESXiä¸»æœºæ— æ³•è¯†åˆ«NVMe SSD
  åŸå› : ESXiç‰ˆæœ¬è¿‡æ—§æˆ–é©±åŠ¨ä¸å…¼å®¹
  è§£å†³:
    - å‡çº§åˆ°ESXi 8.0 U2
    - æˆ–å®‰è£…ç¤¾åŒºNVMeé©±åŠ¨ (Community NVMe Driver Fling)
  å‚è€ƒ: VMware KB 2147714

é—®é¢˜2: vSANæ€§èƒ½ä¸è¾¾æ ‡
  æ’æŸ¥:
    - æ£€æŸ¥HCLå…¼å®¹æ€§
    - éªŒè¯ç½‘ç»œå¸¦å®½ (è‡³å°‘10GbE)
    - ç¡®è®¤RAIDå¡è®¾ç½®ä¸ºHBAæ¨¡å¼/ç›´é€š
    - æ£€æŸ¥ç¼“å­˜/å®¹é‡æ¯” (æ¨èè‡³å°‘1:10)
  ä¼˜åŒ–:
    - å¯ç”¨Jumbo Frame (MTU 9000)
    - å¯ç”¨vSANå»é‡å‹ç¼©
    - è°ƒæ•´ç£ç›˜æ¡å¸¦æ•°

é—®é¢˜3: vMotionè¿ç§»å¤±è´¥
  åŸå› :
    - vMotionç½‘ç»œä¸é€š
    - CPUå…¼å®¹æ€§é—®é¢˜
    - å­˜å‚¨è®¿é—®æƒé™é—®é¢˜
  è§£å†³:
    - pingæµ‹è¯•vMotionç½‘ç»œ
    - å¯ç”¨EVC (Enhanced vMotion Compatibility)
    - æ£€æŸ¥å…±äº«å­˜å‚¨æƒé™

é—®é¢˜4: KVMè™šæ‹ŸæœºåµŒå¥—è™šæ‹ŸåŒ–ä¸å·¥ä½œ
  è§£å†³:
    # Intel CPU
    modprobe -r kvm_intel
    modprobe kvm_intel nested=1
    
    # AMD CPU  
    modprobe -r kvm_amd
    modprobe kvm_amd nested=1
    
    # æŒä¹…åŒ–
    echo "options kvm_intel nested=1" > /etc/modprobe.d/kvm.conf

é—®é¢˜5: Cephé›†ç¾¤HEALTH_WARN
  å¸¸è§åŸå› :
    - æ—¶é’Ÿä¸åŒæ­¥: é…ç½®NTP
    - OSD down: æ£€æŸ¥OSDæ—¥å¿—
    - PGä¸å¹³è¡¡: ceph balancer on
    - å®¹é‡ä¸è¶³: æ‰©å®¹æˆ–åˆ é™¤æ•°æ®
  
  æ’æŸ¥å‘½ä»¤:
    ceph health detail
    ceph osd tree
    ceph osd df
    ceph pg dump
```

---

## æœ€ä½³å®è·µæ€»ç»“

### ç¡¬ä»¶é€‰å‹

âœ… **CPU**: è™šæ‹ŸåŒ–ä¼˜å…ˆé€‰æ‹©å¤šæ ¸å¿ƒï¼Œæ ¸å¿ƒæ•°æ¯”ä¸»é¢‘æ›´é‡è¦  
âœ… **å†…å­˜**: å¿…é¡»ECCï¼Œå¡«æ»¡æ‰€æœ‰å†…å­˜é€šé“ä»¥è·å¾—æœ€å¤§å¸¦å®½  
âœ… **å­˜å‚¨**: SSD/NVMeæ˜¯è™šæ‹ŸåŒ–åŸºç¡€ï¼Œä¸è¦ä¸ºçœé’±ç”¨HDD  
âœ… **ç½‘ç»œ**: 10GbEæ˜¯èµ·æ­¥æ ‡å‡†ï¼Œå…³é”®ä¸šåŠ¡25GbEèµ·  
âœ… **å†—ä½™**: ç”µæºã€ç½‘å¡ã€å­˜å‚¨æ§åˆ¶å™¨å¿…é¡»å†—ä½™  

### è½¯ä»¶é…ç½®

âœ… **vSphere HA**: ç”Ÿäº§ç¯å¢ƒå¿…é¡»å¯ç”¨ï¼Œå»ºè®®FTT=1  
âœ… **vSphere DRS**: å¯ç”¨å…¨è‡ªåŠ¨æ¨¡å¼ï¼Œä¼˜åŒ–èµ„æºåˆ†é…  
âœ… **å­˜å‚¨ç­–ç•¥**: æ ¹æ®ä¸šåŠ¡é‡è¦æ€§åˆ†çº§ (å…³é”®/ä¸€èˆ¬/æµ‹è¯•)  
âœ… **ç½‘ç»œéš”ç¦»**: ç®¡ç†/vMotion/vSAN/ä¸šåŠ¡ç½‘ç»œå¿…é¡»éš”ç¦»  
âœ… **ç›‘æ§å‘Šè­¦**: å…¨é¢ç›‘æ§CPU/å†…å­˜/å­˜å‚¨/ç½‘ç»œï¼ŒåŠæ—¶å‘Šè­¦  

### è¿ç»´ç®¡ç†

âœ… **æ ‡å‡†åŒ–**: VMæ¨¡æ¿ã€å‘½åè§„èŒƒã€é…ç½®æ ‡å‡†  
âœ… **è‡ªåŠ¨åŒ–**: Ansible/Terraform for IaC  
âœ… **å¤‡ä»½**: 3-2-1è§„åˆ™ (3ä»½å‰¯æœ¬,2ç§ä»‹è´¨,1ä»½å¼‚åœ°)  
âœ… **æ–‡æ¡£åŒ–**: æ¶æ„å›¾ã€é…ç½®æ¸…å•ã€æ“ä½œæ‰‹å†Œ  
âœ… **æ¼”ç»ƒ**: å®šæœŸå®¹ç¾æ¼”ç»ƒï¼ŒéªŒè¯RTO/RPO  

### å®‰å…¨åŠ å›º

âœ… **è®¿é—®æ§åˆ¶**: æœ€å°æƒé™åŸåˆ™ + RBAC  
âœ… **ç½‘ç»œå®‰å…¨**: é˜²ç«å¢™ + ACL + VLANéš”ç¦»  
âœ… **æ•°æ®åŠ å¯†**: é™æ€åŠ å¯† (vSAN/VM) + ä¼ è¾“åŠ å¯† (TLS)  
âœ… **è¡¥ä¸ç®¡ç†**: å®šæœŸæ‰“è¡¥ä¸ï¼Œä½†å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯  
âœ… **å®¡è®¡æ—¥å¿—**: å¼€å¯å®Œæ•´å®¡è®¡ï¼Œé›†ä¸­æ”¶é›†åˆ†æ  

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025-10-19  
**é€‚ç”¨ç¯å¢ƒ**: VMware vSphere 7.0+, KVM, vSAN, Ceph  
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª
