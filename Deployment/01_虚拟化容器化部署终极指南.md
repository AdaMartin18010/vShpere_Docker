# 虚拟化容器化部署终极指南

## 目录

- [虚拟化容器化部署终极指南](#虚拟化容器化部署终极指南)
  - [1. 部署架构概述](#1-部署架构概述)
    - [1.1 整体架构](#11-整体架构)
    - [1.2 部署模式](#12-部署模式)
  - [2. 环境准备](#2-环境准备)
    - [2.1 硬件要求](#21-硬件要求)
    - [2.2 软件要求](#22-软件要求)
    - [2.3 网络配置](#23-网络配置)
  - [3. 虚拟化部署](#3-虚拟化部署)
    - [3.1 VMware vSphere部署](#31-vmware-vsphere部署)
      - [3.1.1 ESXi安装](#311-esxi安装)
      - [3.1.2 vCenter部署](#312-vcenter部署)
    - [3.2 虚拟机模板](#32-虚拟机模板)
  - [4. 容器化部署](#4-容器化部署)
    - [4.1 Docker部署](#41-docker部署)
      - [4.1.1 Docker安装](#411-docker安装)
      - [4.1.2 Docker Compose部署](#412-docker-compose部署)
    - [4.2 Kubernetes部署](#42-kubernetes部署)
      - [4.2.1 集群初始化](#421-集群初始化)
      - [4.2.2 工作节点加入](#422-工作节点加入)
  - [5. 混合部署](#5-混合部署)
    - [5.1 虚拟化+容器化架构](#51-虚拟化容器化架构)
    - [5.2 部署策略](#52-部署策略)
  - [6. 监控与运维](#6-监控与运维)
    - [6.1 监控系统部署](#61-监控系统部署)
    - [6.2 日志管理](#62-日志管理)
    - [6.3 自动化运维](#63-自动化运维)
  - [7. 故障排除](#7-故障排除)
    - [7.1 常见问题诊断](#71-常见问题诊断)
    - [7.2 性能问题排查](#72-性能问题排查)
  - [8. 最佳实践](#8-最佳实践)
    - [8.1 部署最佳实践](#81-部署最佳实践)
    - [8.2 运维最佳实践](#82-运维最佳实践)
    - [8.3 故障恢复](#83-故障恢复)

## 1. 部署架构概述

### 1.1 整体架构

```yaml
部署架构:
  基础设施层:
    - 物理服务器
    - 网络设备
    - 存储设备
    - 安全设备
  
  虚拟化层:
    - VMware vSphere
    - ESXi主机
    - vCenter Server
    - 虚拟网络
  
  容器化层:
    - Docker Engine
    - Kubernetes集群
    - 容器编排
    - 服务网格
  
  应用层:
    - 微服务应用
    - 数据库服务
    - 监控服务
    - 安全服务
```

### 1.2 部署模式

```text
┌─────────────────────────────────────────────────────────────┐
│                    部署模式选择                            │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   纯虚拟化  │  │   纯容器化  │  │   混合部署  │         │
│  │   部署      │  │   部署      │  │             │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────────┐
│                    部署环境                                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   开发环境  │  │   测试环境  │  │   生产环境  │         │
│  │             │  │             │  │             │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
```

## 2. 环境准备

### 2.1 硬件要求

```yaml
硬件要求:
  最小配置:
    CPU: 8核心
    内存: 32GB
    存储: 500GB SSD
    网络: 1Gbps
  
  推荐配置:
    CPU: 16核心
    内存: 64GB
    存储: 1TB NVMe SSD
    网络: 10Gbps
  
  生产配置:
    CPU: 32核心
    内存: 128GB
    存储: 2TB NVMe SSD
    网络: 25Gbps
```

### 2.2 软件要求

```bash
# 操作系统要求
操作系统: Ubuntu 22.04 LTS / CentOS 8 / RHEL 8
内核版本: 5.4+
Docker版本: 24.0+
Kubernetes版本: 1.28+
Go版本: 1.21+
Rust版本: 1.75+
Python版本: 3.11+

# 安装基础软件
sudo apt update && sudo apt upgrade -y
sudo apt install -y curl wget git vim htop
sudo apt install -y build-essential cmake
sudo apt install -y python3-pip nodejs npm
```

### 2.3 网络配置

```yaml
网络配置:
  网络拓扑:
    管理网络: 192.168.1.0/24
    存储网络: 192.168.2.0/24
    业务网络: 192.168.3.0/24
    外部网络: 10.0.0.0/8
  
  端口要求:
    SSH: 22
    HTTP: 80
    HTTPS: 443
    Docker API: 2376
    Kubernetes API: 6443
    etcd: 2379-2380
    kubelet: 10250
    kube-proxy: 10256
```

## 3. 虚拟化部署

### 3.1 VMware vSphere部署

#### 3.1.1 ESXi安装

```bash
# ESXi安装脚本
#!/bin/bash

# 下载ESXi ISO
wget https://downloads.vmware.com/d/info/dlg-desktop-end-user-computing/vmware_vsphere/8_0

# 创建安装脚本
cat > esxi_install.sh << 'EOF'
# ESXi安装配置
install --firstdisk --overwritevmfs
rootpw VMware123!
network --bootproto=static --ip=192.168.1.100 --netmask=255.255.255.0 --gateway=192.168.1.1 --nameserver=8.8.8.8 --hostname=esxi-01
reboot
EOF

# 执行安装
./esxi_install.sh
```

#### 3.1.2 vCenter部署

```yaml
# vCenter部署配置
vcenter_config:
  hostname: vcenter.local
  ip_address: 192.168.1.10
  domain: local
  admin_user: administrator@vsphere.local
  admin_password: VMware123!
  
  database:
    type: embedded
    # 或使用外部数据库
    # type: external
    # host: db.local
    # port: 5432
    # database: vcenter
    # username: vcenter
    # password: password123
  
  ssl:
    certificate: self-signed
    # 或使用自定义证书
    # certificate: custom
    # cert_file: /path/to/cert.pem
    # key_file: /path/to/key.pem
```

### 3.2 虚拟机模板

```bash
# 创建虚拟机模板
#!/bin/bash

# 创建CentOS模板
vmware-vdiskmanager -c -s 40GB -a lsilogic -t 0 centos-template.vmdk

# 安装CentOS
virt-install \
  --name centos-template \
  --ram 2048 \
  --vcpus 2 \
  --disk path=centos-template.vmdk \
  --network network=default \
  --graphics none \
  --console pty,target_type=serial \
  --location /path/to/centos.iso \
  --extra-args 'console=ttyS0,115200n8 serial'

# 配置模板
ssh root@centos-template
yum update -y
yum install -y docker kubelet kubeadm kubectl
systemctl enable docker kubelet
```

## 4. 容器化部署

### 4.1 Docker部署

#### 4.1.1 Docker安装

```bash
# Docker安装脚本
#!/bin/bash

# 卸载旧版本
sudo apt remove -y docker docker-engine docker.io containerd runc

# 安装依赖
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release

# 添加Docker官方GPG密钥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# 添加Docker仓库
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# 安装Docker
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# 启动Docker服务
sudo systemctl start docker
sudo systemctl enable docker

# 配置Docker
sudo usermod -aG docker $USER
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

sudo systemctl restart docker
```

#### 4.1.2 Docker Compose部署

```yaml
# docker-compose.yml
version: '3.8'

services:
  virtualization-monitor:
    build: .
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=info
      - MONITORING_INTERVAL=30
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  container-orchestrator:
    build: .
    ports:
      - "8081:8080"
    environment:
      - GO_LOG_LEVEL=info
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./config:/app/config
    restart: unless-stopped

  semantic-validator:
    build: .
    ports:
      - "8082:8080"
    environment:
      - PYTHON_DEBUG=0
      - LOG_LEVEL=info
    volumes:
      - ./config:/app/config
      - ./models:/app/models
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana

volumes:
  prometheus-data:
  grafana-data:
```

### 4.2 Kubernetes部署

#### 4.2.1 集群初始化

```bash
# Kubernetes集群初始化脚本
#!/bin/bash

# 安装kubeadm, kubelet, kubectl
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl
sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

# 初始化主节点
sudo kubeadm init \
  --pod-network-cidr=10.244.0.0/16 \
  --apiserver-advertise-address=192.168.1.100 \
  --control-plane-endpoint=192.168.1.100:6443 \
  --upload-certs

# 配置kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 安装网络插件
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

# 允许主节点调度Pod
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
```

#### 4.2.2 工作节点加入

```bash
# 工作节点加入脚本
#!/bin/bash

# 在主节点获取加入命令
kubeadm token create --print-join-command

# 在工作节点执行加入命令
sudo kubeadm join 192.168.1.100:6443 --token <token> --discovery-token-ca-cert-hash <hash>

# 验证节点状态
kubectl get nodes
```

## 5. 混合部署

### 5.1 虚拟化+容器化架构

```yaml
混合部署架构:
  虚拟化层:
    - VMware vSphere集群
    - 虚拟机资源池
    - 虚拟网络
    - 存储虚拟化
  
  容器化层:
    - Kubernetes集群
    - 容器运行时
    - 服务网格
    - 容器存储
  
  应用层:
    - 传统应用(虚拟机)
    - 微服务应用(容器)
    - 数据库服务
    - 监控服务
```

### 5.2 部署策略

```bash
# 混合部署脚本
#!/bin/bash

# 创建虚拟机用于传统应用
vmware-vdiskmanager -c -s 100GB -a lsilogic -t 0 traditional-app.vmdk

# 部署传统应用到虚拟机
virt-install \
  --name traditional-app \
  --ram 4096 \
  --vcpus 4 \
  --disk path=traditional-app.vmdk \
  --network network=default \
  --graphics none \
  --console pty,target_type=serial \
  --location /path/to/centos.iso

# 部署微服务到Kubernetes
kubectl apply -f microservices/

# 配置服务发现
kubectl apply -f service-mesh/

# 配置负载均衡
kubectl apply -f ingress/
```

## 6. 监控与运维

### 6.1 监控系统部署

```yaml
# 监控系统配置
monitoring_stack:
  prometheus:
    image: prom/prometheus:latest
    config: prometheus.yml
    storage: 200h
  
  grafana:
    image: grafana/grafana:latest
    dashboards: 
      - virtualization-dashboard
      - container-dashboard
      - application-dashboard
  
  alertmanager:
    image: prom/alertmanager:latest
    config: alertmanager.yml
  
  node_exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
  
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8080:8080"
```

### 6.2 日志管理

```yaml
# 日志管理系统
logging_stack:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
  
  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
  
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
  
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.0
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
```

### 6.3 自动化运维

```python
# 自动化运维脚本
import asyncio
import aiohttp
import json
from datetime import datetime

class AutomationOps:
    def __init__(self):
        self.k8s_api = "https://kubernetes.default.svc"
        self.vmware_api = "https://vcenter.local"
        self.monitoring_api = "http://prometheus:9090"
    
    async def health_check(self):
        """健康检查"""
        services = [
            "virtualization-monitor",
            "container-orchestrator", 
            "semantic-validator",
            "prometheus",
            "grafana"
        ]
        
        for service in services:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f"http://{service}:8080/health") as response:
                        if response.status == 200:
                            print(f"✅ {service} 健康")
                        else:
                            print(f"❌ {service} 不健康")
                            await self.restart_service(service)
            except Exception as e:
                print(f"❌ {service} 检查失败: {e}")
                await self.restart_service(service)
    
    async def restart_service(self, service_name):
        """重启服务"""
        try:
            # Kubernetes服务重启
            if service_name in ["container-orchestrator", "semantic-validator"]:
                await self.restart_k8s_deployment(service_name)
            # Docker服务重启
            else:
                await self.restart_docker_service(service_name)
            print(f"🔄 {service_name} 已重启")
        except Exception as e:
            print(f"❌ {service_name} 重启失败: {e}")
    
    async def scale_services(self, load_metrics):
        """自动扩缩容"""
        for service, metrics in load_metrics.items():
            if metrics["cpu"] > 80 or metrics["memory"] > 80:
                await self.scale_up(service)
            elif metrics["cpu"] < 20 and metrics["memory"] < 20:
                await self.scale_down(service)
    
    async def backup_data(self):
        """数据备份"""
        backup_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 备份数据库
        await self.backup_database(backup_time)
        
        # 备份配置文件
        await self.backup_configs(backup_time)
        
        # 备份日志
        await self.backup_logs(backup_time)
        
        print(f"✅ 备份完成: {backup_time}")
```

## 7. 故障排除

### 7.1 常见问题诊断

```bash
# 故障诊断脚本
#!/bin/bash

echo "=== 系统诊断 ==="

# 检查系统资源
echo "CPU使用率:"
top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1

echo "内存使用率:"
free | grep Mem | awk '{printf "%.2f%%", $3/$2 * 100.0}'

echo "磁盘使用率:"
df -h | grep -E '^/dev/'

# 检查网络连接
echo "网络连接状态:"
netstat -tuln | grep -E ':(80|443|8080|8081|8082|9090|3000)'

# 检查Docker状态
echo "Docker状态:"
docker ps
docker system df

# 检查Kubernetes状态
echo "Kubernetes状态:"
kubectl get nodes
kubectl get pods --all-namespaces
kubectl get services --all-namespaces

# 检查服务日志
echo "服务日志:"
docker logs virtualization-monitor --tail 50
docker logs container-orchestrator --tail 50
docker logs semantic-validator --tail 50
```

### 7.2 性能问题排查

```python
# 性能问题排查工具
import psutil
import docker
import requests
import time

class PerformanceDiagnostics:
    def __init__(self):
        self.docker_client = docker.from_env()
    
    def check_system_performance(self):
        """检查系统性能"""
        print("=== 系统性能检查 ===")
        
        # CPU使用率
        cpu_percent = psutil.cpu_percent(interval=1)
        print(f"CPU使用率: {cpu_percent}%")
        
        # 内存使用率
        memory = psutil.virtual_memory()
        print(f"内存使用率: {memory.percent}%")
        
        # 磁盘IO
        disk_io = psutil.disk_io_counters()
        print(f"磁盘读取: {disk_io.read_bytes / 1024 / 1024:.2f} MB")
        print(f"磁盘写入: {disk_io.write_bytes / 1024 / 1024:.2f} MB")
        
        # 网络IO
        network_io = psutil.net_io_counters()
        print(f"网络接收: {network_io.bytes_recv / 1024 / 1024:.2f} MB")
        print(f"网络发送: {network_io.bytes_sent / 1024 / 1024:.2f} MB")
    
    def check_container_performance(self):
        """检查容器性能"""
        print("=== 容器性能检查 ===")
        
        containers = self.docker_client.containers.list()
        for container in containers:
            stats = container.stats(stream=False)
            
            # CPU使用率
            cpu_delta = stats['cpu_stats']['cpu_usage']['total_usage'] - stats['precpu_stats']['cpu_usage']['total_usage']
            system_delta = stats['cpu_stats']['system_cpu_usage'] - stats['precpu_stats']['system_cpu_usage']
            cpu_percent = (cpu_delta / system_delta) * len(stats['cpu_stats']['cpu_usage']['percpu_usage']) * 100.0
            
            # 内存使用率
            memory_usage = stats['memory_stats']['usage']
            memory_limit = stats['memory_stats']['limit']
            memory_percent = (memory_usage / memory_limit) * 100.0
            
            print(f"容器 {container.name}:")
            print(f"  CPU使用率: {cpu_percent:.2f}%")
            print(f"  内存使用率: {memory_percent:.2f}%")
    
    def check_service_response_time(self):
        """检查服务响应时间"""
        print("=== 服务响应时间检查 ===")
        
        services = [
            "http://localhost:8080/health",
            "http://localhost:8081/health", 
            "http://localhost:8082/health",
            "http://localhost:9090/-/healthy",
            "http://localhost:3000/api/health"
        ]
        
        for service_url in services:
            try:
                start_time = time.time()
                response = requests.get(service_url, timeout=5)
                response_time = time.time() - start_time
                
                if response.status_code == 200:
                    print(f"✅ {service_url}: {response_time:.3f}s")
                else:
                    print(f"❌ {service_url}: HTTP {response.status_code}")
            except Exception as e:
                print(f"❌ {service_url}: {e}")
```

## 8. 最佳实践

### 8.1 部署最佳实践

```yaml
部署最佳实践:
  环境隔离:
    开发环境: 单节点部署
    测试环境: 小规模集群
    生产环境: 高可用集群
  
  资源规划:
    CPU: 预留20%资源
    内存: 预留30%资源
    存储: 预留50%空间
    网络: 预留带宽
  
  安全配置:
    启用防火墙: 限制端口访问
    使用HTTPS: 加密通信
    定期更新: 安全补丁
    访问控制: 最小权限
  
  监控告警:
    资源监控: CPU/内存/磁盘
    应用监控: 响应时间/错误率
    日志监控: 异常日志
    告警通知: 及时通知
```

### 8.2 运维最佳实践

```bash
# 运维最佳实践脚本
#!/bin/bash

# 定期维护任务
maintenance_tasks() {
    echo "=== 定期维护任务 ==="
    
    # 清理Docker镜像
    docker system prune -f
    
    # 清理Kubernetes资源
    kubectl delete pods --field-selector=status.phase=Succeeded
    kubectl delete pods --field-selector=status.phase=Failed
    
    # 清理日志文件
    find /var/log -name "*.log" -mtime +30 -delete
    
    # 更新系统包
    apt update && apt upgrade -y
    
    # 重启服务
    systemctl restart docker
    systemctl restart kubelet
}

# 备份脚本
backup_script() {
    echo "=== 数据备份 ==="
    
    backup_dir="/backup/$(date +%Y%m%d)"
    mkdir -p $backup_dir
    
    # 备份配置文件
    cp -r /etc/docker $backup_dir/
    cp -r /etc/kubernetes $backup_dir/
    
    # 备份数据
    docker run --rm -v /var/lib/docker:/data -v $backup_dir:/backup alpine tar czf /backup/docker-data.tar.gz /data
    
    # 备份数据库
    kubectl exec -n default postgres-0 -- pg_dump -U postgres postgres > $backup_dir/database.sql
    
    echo "备份完成: $backup_dir"
}

# 监控脚本
monitoring_script() {
    echo "=== 系统监控 ==="
    
    # 检查服务状态
    systemctl is-active docker
    systemctl is-active kubelet
    
    # 检查资源使用
    df -h
    free -h
    top -bn1 | head -5
    
    # 检查网络连接
    netstat -tuln | grep -E ':(80|443|8080|8081|8082|9090|3000)'
}

# 执行维护任务
case "$1" in
    "maintenance")
        maintenance_tasks
        ;;
    "backup")
        backup_script
        ;;
    "monitor")
        monitoring_script
        ;;
    *)
        echo "用法: $0 {maintenance|backup|monitor}"
        exit 1
        ;;
esac
```

### 8.3 故障恢复

```yaml
故障恢复策略:
  服务故障:
    自动重启: 配置重启策略
    健康检查: 定期健康检查
    故障转移: 自动故障转移
    负载均衡: 分散负载
  
  数据故障:
    数据备份: 定期备份
    数据恢复: 快速恢复
    数据同步: 实时同步
    数据验证: 完整性检查
  
  网络故障:
    网络冗余: 多路径网络
    故障检测: 网络监控
    自动切换: 网络切换
    故障隔离: 网络隔离
  
  硬件故障:
    硬件冗余: 冗余硬件
    故障检测: 硬件监控
    自动切换: 硬件切换
    故障隔离: 硬件隔离
```

---

*本指南提供了完整的虚拟化容器化部署方案，包括环境准备、部署实施、监控运维和故障排除，确保系统稳定可靠运行。*
