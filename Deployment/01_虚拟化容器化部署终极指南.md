# 虚拟化容器化部署终极指南（2025版）

> **文档定位**: 本文档提供企业级虚拟化与容器化部署的完整指南，涵盖硬件选型、虚拟化平台（VMware/KVM/Hyper-V）、容器编排（Kubernetes）、混合部署架构、存储网络配置与运维管理，对齐2025年最新技术标准[deployment-guide]。

## 文档元信息

| 属性 | 值 |
|------|-----|
| **文档版本** | v3.0 (2025改进版) |
| **总行数** | 3580+ |
| **更新日期** | 2025-10-21 |
| **技术基准** | VMware vSphere 8.0, KVM/QEMU 8.0, Kubernetes 1.30, Docker 25.0, Podman 5.0 |
| **标准对齐** | VMware Reference Architecture, CNCF Kubernetes Best Practices, OCI |
| **状态** | 生产就绪 |

> **版本锚点**: 本文档基于2025年企业级部署标准，对齐VMware vSphere 8.0、Kubernetes 1.30+、Docker 25.0+、Podman 5.0+。完整版本信息参考《2025年技术标准最终对齐报告.md》。

---

## 目录

- [虚拟化容器化部署终极指南（2025版）](#虚拟化容器化部署终极指南2025版)
  - [文档元信息](#文档元信息)
  - [目录](#目录)
  - [1. 部署架构概述](#1-部署架构概述)
    - [1.1 整体架构](#11-整体架构)
    - [1.2 部署模式](#12-部署模式)
  - [2. 环境准备](#2-环境准备)
    - [2.1 硬件要求与选型指南](#21-硬件要求与选型指南)
      - [2.1.1 CPU处理器选型](#211-cpu处理器选型)
      - [2.1.2 内存选型](#212-内存选型)
      - [2.1.3 存储选型](#213-存储选型)
      - [2.1.4 网络设备选型](#214-网络设备选型)
      - [2.1.5 完整硬件配置方案](#215-完整硬件配置方案)
      - [2.1.6 BIOS/固件配置清单 🆕](#216-bios固件配置清单-)
      - [2.1.7 硬件兼容性清单 (HCL) 🆕](#217-硬件兼容性清单-hcl-)
    - [2.2 软件要求](#22-软件要求)
      - [2.2.1 软件安装脚本 🆕](#221-软件安装脚本-)
    - [2.3 网络配置](#23-网络配置)
  - [3. 虚拟化部署](#3-虚拟化部署)
    - [3.1 VMware vSphere部署](#31-vmware-vsphere部署)
      - [3.1.1 ESXi安装准备](#311-esxi安装准备)
      - [3.1.2 ESXi交互式安装步骤 🆕](#312-esxi交互式安装步骤-)
      - [3.1.3 ESXi存储配置 🆕](#313-esxi存储配置-)
      - [3.1.4 ESXi网络配置 🆕](#314-esxi网络配置-)
      - [3.1.5 vCenter Server部署 🆕](#315-vcenter-server部署-)
      - [3.1.6 创建数据中心和集群 🆕](#316-创建数据中心和集群-)
    - [3.2 KVM虚拟化部署 🆕](#32-kvm虚拟化部署-)
      - [3.2.1 KVM环境准备](#321-kvm环境准备)
      - [3.2.2 KVM网络配置](#322-kvm网络配置)
      - [3.2.3 创建KVM虚拟机](#323-创建kvm虚拟机)
    - [3.3 Hyper-V虚拟化部署 🆕](#33-hyper-v虚拟化部署-)
      - [3.3.1 Hyper-V安装](#331-hyper-v安装)
      - [3.3.2 Hyper-V网络配置](#332-hyper-v网络配置)
      - [3.3.3 创建Hyper-V虚拟机](#333-创建hyper-v虚拟机)
    - [3.4 虚拟机模板创建 🆕](#34-虚拟机模板创建-)
      - [3.4.1 VMware虚拟机模板](#341-vmware虚拟机模板)
      - [3.4.2 KVM虚拟机模板](#342-kvm虚拟机模板)
      - [3.4.3 模板最佳实践](#343-模板最佳实践)
  - [4. 容器化部署](#4-容器化部署)
    - [4.1 Docker部署](#41-docker部署)
      - [4.1.1 Docker安装](#411-docker安装)
      - [4.1.2 Docker Compose部署](#412-docker-compose部署)
    - [4.2 Kubernetes部署](#42-kubernetes部署)
      - [4.2.1 集群初始化](#421-集群初始化)
      - [4.2.2 工作节点加入](#422-工作节点加入)
  - [5. 混合部署](#5-混合部署)
    - [5.1 虚拟化+容器化架构](#51-虚拟化容器化架构)
    - [5.2 部署策略](#52-部署策略)
  - [6. 监控与运维](#6-监控与运维)
    - [6.1 监控系统部署](#61-监控系统部署)
    - [6.2 日志管理](#62-日志管理)
    - [6.3 自动化运维](#63-自动化运维)
  - [7. 故障排除](#7-故障排除)
    - [7.1 常见问题诊断](#71-常见问题诊断)
    - [7.2 性能问题排查](#72-性能问题排查)
  - [8. 存储架构标准配置 🆕](#8-存储架构标准配置-)
    - [8.1 存储类型与选型标准](#81-存储类型与选型标准)
    - [8.2 网络架构标准配置 🆕](#82-网络架构标准配置-)
    - [9.2 Kubernetes高可用配置](#92-kubernetes高可用配置)
  - [10. 最佳实践](#10-最佳实践)
    - [10.1 部署最佳实践](#101-部署最佳实践)
    - [10.2 运维最佳实践](#102-运维最佳实践)
    - [10.3 故障恢复](#103-故障恢复)
  - [参考资源](#参考资源)
    - [1. 官方文档](#1-官方文档)
    - [2. 硬件与BIOS](#2-硬件与bios)
    - [3. VMware vSphere](#3-vmware-vsphere)
    - [4. KVM虚拟化](#4-kvm虚拟化)
    - [5. Hyper-V](#5-hyper-v)
    - [6. Docker容器](#6-docker容器)
    - [7. Kubernetes](#7-kubernetes)
    - [8. 存储与网络](#8-存储与网络)
  - [11. 相关文档](#11-相关文档)
    - [核心技术文档](#核心技术文档)
    - [技术实施文档](#技术实施文档)
    - [安全与运维文档](#安全与运维文档)
    - [学习资源](#学习资源)
    - [更新日志 🆕](#更新日志-)

## 1. 部署架构概述

**企业级架构设计原则**[enterprise-architecture]:

### 1.1 整体架构

```yaml
部署架构[deployment-patterns]:
  基础设施层:
    - 物理服务器
    - 网络设备
    - 存储设备
    - 安全设备
  
  虚拟化层:
    - VMware vSphere
    - ESXi主机
    - vCenter Server
    - 虚拟网络
  
  容器化层:
    - Docker Engine
    - Kubernetes集群
    - 容器编排
    - 服务网格
  
  应用层:
    - 微服务应用
    - 数据库服务
    - 监控服务
    - 安全服务
```

### 1.2 部署模式

```text
┌─────────────────────────────────────────────────────────────┐
│                    部署模式选择                              │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │   纯虚拟化   │  │   纯容器化   │  │   混合部署  │          │
│  │   部署       │  │   部署      │  │             │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────────────────┐
│                    部署环境                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐          │
│  │   开发环境   │  │   测试环境  │   │   生产环境  │          │
│  │             │  │             │  │             │          │
│  └─────────────┘  └─────────────┘  └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
```

## 2. 环境准备

### 2.1 硬件要求与选型指南

#### 2.1.1 CPU处理器选型

**CPU虚拟化技术要求**[cpu-virtualization]:

```yaml
CPU要求与选型[cpu-selection]:
  虚拟化必须特性:
    ✅ Intel VT-x / AMD-V (硬件虚拟化)
    ✅ Intel VT-d / AMD-Vi (IO虚拟化)
    ✅ EPT / RVI (内存虚拟化)
    ✅ 支持64位
  
  推荐处理器 (2025):
    Intel:
      入门级: Xeon E-2300 系列
        - 核心: 4-8核
        - 频率: 2.8-4.5GHz
        - 缓存: 16MB
        - 价格: ¥3,000-6,000
        - 适用: 小型虚拟化环境
      
      中端: Xeon Silver 4300 系列
        - 核心: 8-16核
        - 频率: 2.2-3.4GHz
        - 缓存: 22-30MB
        - 价格: ¥8,000-20,000
        - 适用: 中型企业虚拟化
      
      高端: Xeon Gold 6300 系列
        - 核心: 16-40核
        - 频率: 2.0-3.8GHz
        - 缓存: 36-60MB
        - 价格: ¥30,000-80,000
        - 适用: 大型数据中心
      
      旗舰: Xeon Platinum 8300 系列
        - 核心: 28-40核
        - 频率: 2.0-4.0GHz
        - 缓存: 57-120MB
        - 价格: ¥100,000-300,000
        - 适用: 关键业务负载
    
    AMD:
      入门级: EPYC 7232P
        - 核心: 8核16线程
        - 频率: 3.1-3.2GHz
        - 缓存: 32MB L3
        - 价格: ¥4,000-6,000
      
      中端: EPYC 7443
        - 核心: 24核48线程
        - 频率: 2.85-4.0GHz
        - 缓存: 128MB L3
        - 价格: ¥25,000-35,000
      
      高端: EPYC 7763
        - 核心: 64核128线程
        - 频率: 2.45-3.5GHz
        - 缓存: 256MB L3
        - 价格: ¥70,000-90,000
    
    国产:
      海光 (Hygon):
        - C86 7185 (32核)
        - 价格: ¥15,000-25,000
        - 兼容x86架构
        - 支持国产化要求
      
      鲲鹏 (华为):
        - 920-6426 (64核)
        - ARM架构
        - 价格: ¥20,000-40,000
        - 生态逐渐完善

  CPU选型建议:
    小型环境 (<50VM):
      - 2颗 Xeon Silver 4310 (12核)
      - 总核心: 24核48线程
      - 成本: ¥25,000
    
    中型环境 (50-200VM):
      - 2颗 Xeon Gold 6326 (16核)
      - 总核心: 32核64线程
      - 成本: ¥70,000
    
    大型环境 (>200VM):
      - 2颗 Xeon Platinum 8358 (32核)
      - 总核心: 64核128线程
      - 成本: ¥200,000
    
    性价比方案:
      - 2颗 AMD EPYC 7443 (24核)
      - 总核心: 48核96线程
      - 成本: ¥60,000 (节省¥10,000)
```

#### 2.1.2 内存选型

**内存规划最佳实践**[memory-sizing]:

```yaml
内存要求与选型[memory-planning]:
  内存类型:
    DDR4: 2933-3200MHz
      - 成熟稳定
      - 价格较低
      - 适合大多数场景
    
    DDR5: 4800-5600MHz
      - 性能更强 (+50%)
      - 功耗更低 (-20%)
      - 价格较高 (+30%)
      - 适合高性能场景
  
  内存配置:
    基础原则:
      ✅ 对称配置 (多通道)
      ✅ 同品牌同型号
      ✅ 启用ECC (纠错)
      ✅ 预留20%余量
    
    小型环境:
      配置: 8x 16GB DDR4 ECC
      总容量: 128GB
      通道: 8通道
      成本: ¥12,000
      适用: <50VM
    
    中型环境:
      配置: 12x 32GB DDR4 ECC
      总容量: 384GB
      通道: 12通道
      成本: ¥38,000
      适用: 50-200VM
    
    大型环境:
      配置: 24x 64GB DDR4 ECC
      总容量: 1.5TB
      通道: 24通道
      成本: ¥160,000
      适用: >200VM
    
    超大规模:
      配置: 32x 128GB DDR5 ECC
      总容量: 4TB
      通道: 32通道
      成本: ¥500,000
      适用: >1000VM

  内存超额配比:
    保守: 1.5:1 (150%)
    标准: 2:1 (200%)
    激进: 3:1 (300%)
    
    注意: 需配合内存热添加、TPS等技术
```

#### 2.1.3 存储选型

**存储架构设计指南**[storage-architecture]:

```yaml
存储要求与选型[storage-selection]:
  存储类型对比:
    HDD机械硬盘:
      IOPS: 100-200
      延迟: 5-10ms
      价格: ¥0.3/GB
      适用: 冷数据、归档
      品牌: 西部数据、希捷、东芝
    
    SATA SSD:
      IOPS: 50K-100K
      延迟: 0.5-1ms
      价格: ¥1/GB
      适用: 标准虚拟化
      品牌: 三星860/870 EVO, 英睿达MX500
    
    NVMe SSD:
      IOPS: 500K-1M
      延迟: 0.1-0.2ms
      价格: ¥2-3/GB
      适用: 高性能虚拟化
      品牌: 三星980 PRO, WD Black SN850, Intel P5800X
    
    企业级NVMe:
      IOPS: 1M-2M
      延迟: 0.05-0.1ms
      价格: ¥5-10/GB
      适用: 关键业务
      品牌: Intel Optane, Samsung PM9A3, Micron 7450

  存储配置方案:
    小型环境:
      方案1 (经济型):
        - 2x 1TB NVMe SSD (RAID1) - 系统盘
        - 4x 4TB SATA SSD (RAID10) - 数据盘
        - 总容量: 9TB可用
        - 成本: ¥20,000
      
      方案2 (性能型):
        - 2x 1TB NVMe SSD (RAID1) - 系统盘
        - 6x 2TB NVMe SSD (RAID10) - 数据盘
        - 总容量: 7TB可用
        - 成本: ¥35,000
    
    中型环境:
      方案1 (均衡型):
        - 2x 2TB NVMe SSD (RAID1) - 系统盘
        - 8x 4TB NVMe SSD (RAID10) - 数据盘
        - 4x 8TB SATA SSD (RAID10) - 冷数据
        - 总容量: 34TB可用
        - 成本: ¥100,000
      
      方案2 (全闪存):
        - 2x 2TB NVMe SSD (RAID1) - 系统盘
        - 12x 8TB NVMe SSD (RAID10) - 数据盘
        - 总容量: 50TB可用
        - 成本: ¥240,000
    
    大型环境:
      全闪存阵列:
        - Pure Storage FlashArray
        - Dell EMC PowerStore
        - NetApp AFF
        - 容量: 100TB+
        - 成本: ¥1,000,000+

  RAID配置建议:
    系统盘: RAID1 (镜像)
      - 保证可靠性
      - 2块盘组成
    
    数据盘: RAID10 (镜像条带)
      - 平衡性能和可靠性
      - 4/6/8块盘组成
      - 50%空间利用率
    
    大容量: RAID6 (双重校验)
      - 允许2块盘故障
      - 8块盘以上
      - 75%空间利用率
    
    极致性能: RAID0 (条带)
      - 仅用于临时数据
      - 无冗余保护
      - 100%空间利用率
```

#### 2.1.4 网络设备选型

**网络架构最佳实践**[network-architecture]:

```yaml
网络要求与选型[network-planning]:
  网卡选型:
    1GbE (千兆):
      Intel I350-T4 (4口)
        - 价格: ¥800
        - 适用: 管理网络
      
      Broadcom 5719 (4口)
        - 价格: ¥1,000
        - Dell/HP服务器常用
    
    10GbE (万兆):
      Intel X710-DA2 (SFP+)
        - 价格: ¥3,000
        - 适用: 业务网络
      
      Mellanox ConnectX-4 Lx
        - 价格: ¥3,500
        - 更好的性能
    
    25GbE:
      Mellanox ConnectX-5
        - 价格: ¥6,000
        - 适用: 高性能场景
      
      Intel XXV710
        - 价格: ¥5,500
        - 与Intel CPU配合好
    
    100GbE:
      Mellanox ConnectX-6
        - 价格: ¥20,000
        - 适用: 大型数据中心

  交换机选型:
    接入交换机 (1GbE):
      Cisco Catalyst 2960X (48口)
        - 价格: ¥15,000
        - 企业级可靠
      
      HPE OfficeConnect 1920S
        - 价格: ¥8,000
        - 性价比高
      
      华为 S5720-SI
        - 价格: ¥10,000
        - 国产替代
    
    汇聚交换机 (10GbE):
      Cisco Nexus 9300
        - 价格: ¥100,000
        - 数据中心级
      
      Arista 7050X
        - 价格: ¥80,000
        - 低延迟
      
      华为 CE6800
        - 价格: ¥70,000
        - 国产高端
    
    核心交换机 (100GbE):
      Cisco Nexus 9500
        - 价格: ¥500,000+
        - 大型数据中心
      
      Juniper QFX10000
        - 价格: ¥400,000+
        - 高性能

  网络架构:
    小型环境:
      - 2台1GbE接入交换机 (堆叠)
      - 管理网络: 1GbE
      - 业务网络: 1GbE
      - 成本: ¥30,000
    
    中型环境:
      - 2台10GbE汇聚交换机
      - 4台1GbE接入交换机
      - 管理网络: 1GbE
      - 业务网络: 10GbE
      - 存储网络: 10GbE
      - 成本: ¥250,000
    
    大型环境:
      - 2台100GbE核心交换机
      - 4台25GbE汇聚交换机
      - 8台10GbE接入交换机
      - 成本: ¥1,500,000
```

#### 2.1.5 完整硬件配置方案

```yaml
方案对比:
  小型环境 (预算¥15万):
    服务器: Dell PowerEdge R650 x2
      CPU: 2x Xeon Silver 4310 (12核)
      内存: 8x 16GB DDR4 = 128GB
      存储: 2x 1TB NVMe + 4x 4TB SATA SSD
      网络: 4x 1GbE + 2x 10GbE
      价格: ¥60,000/台 x2 = ¥120,000
    
    交换机: HPE 1920S 48口 x2
      价格: ¥8,000/台 x2 = ¥16,000
    
    其他: 线缆、机柜、UPS
      价格: ¥15,000
    
    总计: ¥151,000
    支持: 50-100 VM
  
  中型环境 (预算¥50万):
    服务器: Dell PowerEdge R750 x4
      CPU: 2x Xeon Gold 6326 (16核)
      内存: 12x 32GB DDR4 = 384GB
      存储: 2x 2TB NVMe + 8x 4TB NVMe
      网络: 4x 1GbE + 2x 25GbE
      价格: ¥110,000/台 x4 = ¥440,000
    
    交换机: 
      汇聚: Cisco Nexus 9300 x2 = ¥200,000
      接入: Cisco 2960X x4 = ¥60,000
    
    存储网络: 10GbE专用
    
    其他: 线缆、机柜、UPS
      价格: ¥50,000
    
    总计: ¥750,000
    支持: 200-500 VM
  
  大型环境 (预算¥300万):
    服务器: Dell PowerEdge R760 x8
      CPU: 2x AMD EPYC 7763 (64核)
      内存: 24x 64GB DDR4 = 1.5TB
      存储: 2x 4TB NVMe + 12x 8TB NVMe
      网络: 4x 1GbE + 4x 25GbE
      价格: ¥280,000/台 x8 = ¥2,240,000
    
    存储: Pure Storage FlashArray
      容量: 100TB 全闪存
      价格: ¥1,500,000
    
    网络:
      核心: Cisco Nexus 9500 x2 = ¥1,000,000
      汇聚: Arista 7050X x4 = ¥320,000
      接入: Cisco 2960X x8 = ¥120,000
    
    其他: 专业机柜、高端UPS、冷通道
      价格: ¥200,000
    
    总计: ¥5,380,000
    支持: 1000+ VM
```

#### 2.1.6 BIOS/固件配置清单 🆕

**BIOS虚拟化配置标准**[bios-virtualization]:

```yaml
BIOS配置要求[bios-settings]:
  虚拟化技术:
    ✅ Intel VT-x / AMD-V: 必须启用
      - 位置: Advanced → Processor Configuration → Intel VT-x
      - 说明: 硬件虚拟化基础
    
    ✅ Intel VT-d / AMD-Vi: 强烈推荐
      - 位置: Advanced → System Agent Configuration → VT-d
      - 说明: IO虚拟化，PCI直通必须
    
    ✅ EPT / RVI: 自动启用
      - 说明: 内存虚拟化
      - 与VT-x同时启用
  
  电源管理:
    ✅ Power Technology: 设置为 Custom
    ✅ Energy Efficient Turbo: Disabled
    ✅ C-States: Disabled (禁用省电状态)
    ✅ C1E: Disabled
    ✅ Turbo Boost: Enabled (启用睿频)
    说明: 保证稳定性能，避免延迟波动
  
  内存配置:
    ✅ Node Interleaving: Disabled
    ✅ Memory Patrol Scrub: Disabled
    ✅ ECC Memory: Enabled (如果支持)
    ✅ Memory Speed: 最高支持速度
  
  启动选项:
    ✅ Boot Mode: UEFI (不要用Legacy)
    ✅ Secure Boot: Disabled (虚拟化环境禁用)
    ✅ Network Boot: 按需启用 (PXE)
  
  其他设置:
    ✅ Hyper-Threading: Enabled (超线程)
    ✅ NUMA: Enabled (NUMA架构)
    ✅ SR-IOV: Enabled (网卡虚拟化)
    ✅ ACS: Enabled (PCIe访问控制)

戴尔服务器 (Dell PowerEdge):
  进入BIOS: 开机按F2
  关键路径:
    1. System BIOS → Processor Settings
       - Virtualization Technology: Enabled
       - VT for Direct I/O: Enabled
    
    2. System BIOS → Integrated Devices
       - SR-IOV Global Enable: Enabled
    
    3. System BIOS → System Profile Settings
       - System Profile: Performance (性能模式)
       - C States: Disabled
    
    4. iDRAC Settings → Network
       - 配置远程管理IP

HPE服务器 (ProLiant):
  进入BIOS: 开机按F9
  关键路径:
    1. System Options → Processor Options
       - Intel Virtualization Technology: Enabled
       - Intel VT-d: Enabled
    
    2. System Options → BIOS/Platform Configuration
       - Workload Profile: Virtualization - Max Performance
    
    3. Power Management → Advanced Power Options
       - Power Regulator: HP Static High Performance Mode

联想服务器 (ThinkSystem):
  进入BIOS: 开机按F1
  关键路径:
    1. System Settings → Processors
       - Intel Virtualization Technology: Enabled
       - VT-d: Enabled
    
    2. System Settings → Power
       - Operating Mode: Maximum Performance

华为服务器 (FusionServer):
  进入BIOS: 开机按Delete
  关键路径:
    1. Advanced → Processor Configuration
       - Intel Virtualization Technology: Enabled
       - VT-d: Enabled
    
    2. Advanced → Power Configuration
       - Power Policy: Performance
```

#### 2.1.7 硬件兼容性清单 (HCL) 🆕

**VMware HCL验证标准**[vmware-hcl]:

```yaml
VMware vSphere 8.0 兼容性[vsphere-compatibility]:
  认证服务器品牌:
    Tier 1 (顶级支持):
      ✅ Dell EMC PowerEdge
        - R650, R750, R760 系列
        - 完整支持，最新驱动
      
      ✅ HPE ProLiant
        - DL360 Gen10/Gen11
        - 完整支持，认证完善
      
      ✅ Cisco UCS
        - C-Series, B-Series
        - 深度集成
      
      ✅ 浪潮 (Inspur)
        - NF5280M6, NF8260M6
        - 国产服务器支持好
    
    Tier 2 (良好支持):
      ✅ 联想 ThinkSystem
        - SR650, SR850
      
      ✅ 超微 SuperMicro
        - 性价比高
      
      ✅ 华为 FusionServer
        - 2288H V5, 5288 V5
  
  认证CPU:
    Intel:
      ✅ Xeon Scalable (全系列)
      ✅ Xeon E (入门级)
      ❌ Core/Pentium (不支持)
    
    AMD:
      ✅ EPYC 7002/7003 系列
      ✅ EPYC 9004 系列 (最新)
  
  认证网卡:
    ✅ Intel X710/XXV710 系列
    ✅ Broadcom BCM57xxx 系列
    ✅ Mellanox ConnectX-4/5/6
    ⚠️ Realtek (部分型号不支持)
  
  认证存储控制器:
    ✅ Dell PERC H730P/H750
    ✅ HPE Smart Array P408i
    ✅ Broadcom MegaRAID
    ✅ LSI/Avago 9361/9460

  查询HCL:
    官方网站: https://www.vmware.com/resources/compatibility
    搜索步骤:
      1. 选择vSphere版本
      2. 输入服务器型号
      3. 查看兼容性状态
      4. 下载驱动程序

Kubernetes硬件要求:
  CPU:
    ✅ x86_64 架构
    ✅ ARM64 架构 (实验性)
    ❌ 32位系统不支持
  
  内存:
    Master节点: 最低4GB (推荐8GB+)
    Worker节点: 最低2GB (推荐8GB+)
  
  存储:
    ✅ 本地SSD
    ✅ 网络存储 (NFS/iSCSI)
    ✅ 分布式存储 (Ceph/GlusterFS)

国产化硬件兼容:
  CPU:
    ✅ 海光 (Hygon) - x86兼容
      - 支持: VMware, KVM, Docker, K8s
      - 生态: 较好
    
    ✅ 鲲鹏 (Kunpeng) - ARM64
      - 支持: KVM, Docker, K8s
      - 生态: 快速发展
    
    ✅ 飞腾 (Phytium) - ARM64
      - 支持: KVM, Docker
      - 生态: 持续完善
    
    ⚠️ 龙芯 (Loongson) - LoongArch
      - 支持: 有限
      - 生态: 初期阶段
  
  操作系统:
    ✅ 麒麟 (Kylin)
    ✅ 统信 (UOS)
    ✅ 中标麒麟
    ✅ 欧拉 (openEuler)

硬件测试清单:
  购买前验证:
    □ 查询官方HCL
    □ 确认BIOS版本
    □ 确认固件版本
    □ 查看用户评价
  
  收货后测试:
    □ 硬件自检
    □ 内存测试 (memtest86+)
    □ 硬盘测试 (smartctl)
    □ 网络测试 (iperf3)
    □ CPU压力测试 (stress-ng)
  
  安装前配置:
    □ 更新BIOS
    □ 更新固件
    □ 配置RAID
    □ 配置网络
    □ 导入iDRAC/iLO证书
```

### 2.2 软件要求

```yaml
操作系统要求:
  虚拟化宿主机:
    VMware ESXi:
      - 版本: 7.0 U3 / 8.0 U1
      - 最小内存: 8GB
      - 最小磁盘: 32GB (推荐140GB)
      - 网络: 1Gbps+
    
    Linux KVM:
      Ubuntu Server: 22.04 LTS
      CentOS Stream: 9
      RHEL: 8.6+
      内核: 5.15+
      QEMU/KVM: 6.2+
    
    Windows Hyper-V:
      - Windows Server 2022
      - Hyper-V角色
      - 最小内存: 16GB
  
  容器宿主机:
    推荐系统:
      Ubuntu Server: 22.04 LTS
      RHEL: 8.6 / 9.0
      CentOS Stream: 9
      Rocky Linux: 9
    
    内核要求:
      - 版本: 5.10+ (推荐5.15+)
      - cgroup v2支持
      - namespace支持
      - overlay2文件系统
    
    容器运行时:
      Docker: 24.0+
      containerd: 1.6+
      Podman: 4.5+
    
    编排系统:
      Kubernetes: 1.28+ (推荐1.29/1.30)
      OpenShift: 4.13+

  管理工具:
    vCenter Server: 8.0
    Kubernetes Dashboard: 2.7+
    Portainer: 2.19+
    Rancher: 2.7+

系统优化配置:
  内核参数 (/etc/sysctl.conf):
    ```bash
    # 网络优化
    net.ipv4.ip_forward = 1
    net.bridge.bridge-nf-call-iptables = 1
    net.bridge.bridge-nf-call-ip6tables = 1
    
    # 性能优化
    vm.swappiness = 0
    vm.overcommit_memory = 1
    net.ipv4.tcp_keepalive_time = 600
    net.ipv4.tcp_keepalive_intvl = 30
    net.ipv4.tcp_keepalive_probes = 10
    
    # 文件句柄
    fs.file-max = 2097152
    fs.inotify.max_user_watches = 524288
    ```
  
  资源限制 (/etc/security/limits.conf):
    ```bash
    * soft nofile 655360
    * hard nofile 655360
    * soft nproc 655360
    * hard nproc 655360
    * soft memlock unlimited
    * hard memlock unlimited
    ```
  
  禁用服务:
    ```bash
    # 禁用防火墙 (或配置规则)
    systemctl stop firewalld
    systemctl disable firewalld
    
    # 禁用SELinux (或设置为Permissive)
    setenforce 0
    sed -i 's/SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
    
    # 禁用swap
    swapoff -a
    sed -i '/swap/d' /etc/fstab
    ```
```

#### 2.2.1 软件安装脚本 🆕

```bash
#!/bin/bash
# 系统初始化和软件安装脚本

set -e

echo "=== 系统初始化 ==="

# 更新系统
apt update && apt upgrade -y

# 安装基础工具
apt install -y \
    curl wget git vim htop iotop \
    net-tools iputils-ping dnsutils \
    build-essential cmake \
    python3 python3-pip \
    jq yq

# 配置时区
timedatectl set-timezone Asia/Shanghai

# 配置NTP
apt install -y chrony
systemctl enable chrony
systemctl start chrony

# 安装Docker
echo "=== 安装Docker ==="
curl -fsSL https://get.docker.com | bash
systemctl enable docker
systemctl start docker

# 配置Docker
mkdir -p /etc/docker
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "3"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ],
  "registry-mirrors": [
    "https://docker.mirrors.ustc.edu.cn"
  ]
}
EOF

systemctl restart docker

# 安装Kubernetes工具
echo "=== 安装Kubernetes ==="
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat <<EOF | tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

apt update
apt install -y kubelet=1.29.0-00 kubeadm=1.29.0-00 kubectl=1.29.0-00
apt-mark hold kubelet kubeadm kubectl

# 加载内核模块
modprobe overlay
modprobe br_netfilter

cat > /etc/modules-load.d/k8s.conf <<EOF
overlay
br_netfilter
EOF

# 配置内核参数
cat > /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sysctl --system

echo "=== 安装完成 ==="
echo "请重启系统: sudo reboot"
```

### 2.3 网络配置

```yaml
网络配置:
  网络拓扑:
    管理网络: 192.168.1.0/24
    存储网络: 192.168.2.0/24
    业务网络: 192.168.3.0/24
    外部网络: 10.0.0.0/8
  
  端口要求:
    SSH: 22
    HTTP: 80
    HTTPS: 443
    Docker API: 2376
    Kubernetes API: 6443
    etcd: 2379-2380
    kubelet: 10250
    kube-proxy: 10256
```

## 3. 虚拟化部署

### 3.1 VMware vSphere部署

**VMware vSphere 8.0架构**[vsphere-architecture]:

#### 3.1.1 ESXi安装准备

**ESXi安装指南**[esxi-installation]:

```yaml
安装前准备[esxi-requirements]:
  下载ESXi:
    版本: VMware ESXi 8.0 U2
    来源: https://my.vmware.com
    文件: VMware-VMvisor-Installer-8.0U2-xxx.iso
    大小: ~500MB
  
  制作启动U盘:
    Windows方法:
      工具: Rufus 3.20+
      步骤:
        1. 插入U盘 (8GB+)
        2. 打开Rufus
        3. 选择ESXi ISO
        4. 分区类型: GPT
        5. 目标系统: UEFI
        6. 文件系统: FAT32
        7. 点击开始
    
    Linux/Mac方法:
      ```bash
      # 查找U盘设备
      lsblk
      
      # 写入ISO (假设U盘是/dev/sdb)
      sudo dd if=VMware-VMvisor-Installer-8.0U2.iso of=/dev/sdb bs=4M status=progress
      sudo sync
      ```
  
  服务器准备:
    □ BIOS已配置虚拟化（参考2.1.6）
    □ RAID已配置
    □ 网线已连接
    □ iDRAC/iLO已配置（可选）
    □ 记录硬件信息（序列号、网卡MAC等）

自动化安装配置 (kickstart):
  创建配置文件 (ks.cfg):
    ```bash
    # ESXi自动化安装配置
    vmaccepteula
    
    # 安装到第一块硬盘
    install --firstdisk --overwritevmfs
    
    # Root密码
    rootpw VMware123!
    
    # 网络配置
    network --bootproto=static --ip=192.168.1.101 --netmask=255.255.255.0 --gateway=192.168.1.1 --nameserver=8.8.8.8,8.8.4.4 --hostname=esxi-01.domain.local --vlanid=0
    
    # 安装后重启
    reboot
    
    # 安装后脚本
    %firstboot --interpreter=busybox
    
    # 启用SSH和ESXi Shell
    vim-cmd hostsvc/enable_ssh
    vim-cmd hostsvc/start_ssh
    vim-cmd hostsvc/enable_esx_shell
    vim-cmd hostsvc/start_esx_shell
    
    # 配置NTP
    esxcli system ntp set --server=ntp.aliyun.com
    esxcli system ntp set --enabled=yes
    
    # 配置防火墙允许NTP
    esxcli network firewall ruleset set --ruleset-id=ntpClient --enabled=yes
    
    # 设置主机名
    esxcli system hostname set --fqdn=esxi-01.domain.local
    
    # 重启管理服务
    /etc/init.d/hostd restart
    /etc/init.d/vpxa restart
    ```
```

#### 3.1.2 ESXi交互式安装步骤 🆕

```yaml
安装流程:
  步骤1: 启动安装程序
    1. 插入U盘，开机
    2. 进入BIOS设置启动顺序（F11/F12）
    3. 选择U盘启动
    4. 等待加载（约30秒）
    5. 看到欢迎界面 "Welcome to VMware ESXi"
  
  步骤2: 接受许可协议
    1. 按 Enter 继续
    2. 阅读EULA
    3. 按 F11 接受协议
  
  步骤3: 选择安装磁盘
    1. 显示所有可用磁盘
    2. 使用方向键选择目标磁盘
       ⚠️ 警告: 磁盘上所有数据将被清除
    3. 按 Enter 确认
    
    推荐选择:
      - RAID1镜像盘（推荐）
      - 本地SSD
      - USB/SD卡（小型环境）
  
  步骤4: 选择键盘布局
    1. 默认: US Default
    2. 中文环境可选择
    3. 按 Enter 继续
  
  步骤5: 设置Root密码
    1. 输入密码（至少7个字符）
    2. 再次确认密码
    3. 按 Enter 继续
    
    密码策略:
      ✅ 至少7个字符
      ✅ 包含大小写字母
      ✅ 包含数字
      ✅ 包含特殊字符
      示例: VMware@2025
  
  步骤6: 确认安装
    1. 检查安装摘要
       - 安装磁盘
       - 键盘布局
    2. 按 F11 开始安装
    3. 等待安装（约5-10分钟）
    4. 显示 "Installation Complete"
    5. 移除U盘
    6. 按 Enter 重启

安装后首次配置:
  步骤1: 登录控制台
    1. 重启后进入DCUI (Direct Console User Interface)
    2. 按 F2 进入系统定制
    3. 输入root密码
  
  步骤2: 配置管理网络
    1. 选择 "Configure Management Network"
    2. 配置选项:
       a. Network Adapters
          - 选择管理网卡（vmnic0）
          - 按空格选中
       
       b. VLAN (optional)
          - 输入VLAN ID（如有）
          - 留空则使用原生VLAN
       
       c. IPv4 Configuration
          - 选择 "Set static IPv4 address"
          - IP地址: 192.168.1.101
          - 子网掩码: 255.255.255.0
          - 默认网关: 192.168.1.1
       
       d. IPv6 Configuration
          - 默认禁用（按需启用）
       
       e. DNS Configuration
          - 主DNS: 8.8.8.8
          - 备DNS: 8.8.4.4
          - 主机名: esxi-01.domain.local
       
    3. 按 Esc 返回
    4. 按 Y 确认更改并重启网络
  
  步骤3: 测试网络连接
    1. 选择 "Test Management Network"
    2. 按 Enter 测试
    3. 检查:
       - Ping 网关: OK
       - Ping 主DNS: OK
       - Ping 备DNS: OK
       - Resolve hostname: OK
  
  步骤4: 启用服务
    1. 返回主菜单
    2. 选择 "Troubleshooting Options"
    3. 启用 "Enable ESXi Shell"
    4. 启用 "Enable SSH"
    5. 按 Esc 返回

Web访问配置:
  访问ESXi:
    URL: https://192.168.1.101
    用户: root
    密码: 设置的Root密码
  
  界面导航:
    左侧菜单:
      - 主机: 查看硬件信息
      - 虚拟机: 管理虚拟机
      - 存储: 管理数据存储
      - 网络: 管理网络
      - 许可: 添加许可证
  
  基础配置:
    1. 许可证配置:
       - 导航到 主机 → 管理 → 许可
       - 点击 "分配许可证"
       - 输入许可证密钥（60天评估期）
    
    2. 时间配置:
       - 导航到 主机 → 管理 → 时间和日期
       - 选择 "使用网络时间协议"
       - 添加NTP服务器: ntp.aliyun.com
       - 启动NTP服务
    
    3. 防火墙配置:
       - 导航到 主机 → 管理 → 安全配置文件
       - 编辑防火墙规则
       - 允许需要的服务（SSH、NTP等）
```

#### 3.1.3 ESXi存储配置 🆕

```yaml
数据存储配置:
  创建VMFS数据存储:
    步骤:
      1. 导航到 存储 → 数据存储
      2. 点击 "新建数据存储"
      3. 选择类型: "创建新VMFS数据存储"
      4. 输入名称: datastore1
      5. 选择设备（未使用的磁盘/RAID）
      6. 选择VMFS版本: VMFS6
      7. 分区选项:
         - 使用全部可用空间（推荐）
         - 或自定义大小
      8. 完成创建
  
  创建NFS数据存储:
    前提: 已有NFS服务器
    步骤:
      1. 导航到 存储 → 数据存储
      2. 点击 "新建数据存储"
      3. 选择类型: "挂载NFS数据存储"
      4. 配置:
         - 名称: nfs-datastore1
         - NFS服务器: 192.168.2.10
         - NFS共享: /export/vmware
         - NFS版本: NFS 3 (推荐)
      5. 完成创建
  
  存储最佳实践:
    命名规范:
      - 本地存储: local-esxi01
      - SSD存储: ssd-datastore1
      - NFS存储: nfs-storage1
      - iSCSI存储: iscsi-lun01
    
    性能优化:
      ✅ 系统盘: 使用SSD
      ✅ VM磁盘: 使用NVMe或SSD
      ✅ ISO存储: 可用HDD
      ✅ 启用VAAI (硬件加速)
      ✅ 配置多路径 (多链路)
```

#### 3.1.4 ESXi网络配置 🆕

```yaml
虚拟交换机配置:
  创建标准交换机 (vSwitch):
    步骤:
      1. 导航到 网络 → 虚拟交换机
      2. 点击 "添加标准虚拟交换机"
      3. 配置:
         - 名称: vSwitch1
         - MTU: 1500 (标准) 或 9000 (Jumbo Frame)
         - 上行链路: vmnic1, vmnic2 (链路聚合)
         - 安全策略: 拒绝混杂模式
      4. 完成创建
  
  创建端口组:
    业务网络端口组:
      1. 导航到 网络 → 端口组
      2. 点击 "添加端口组"
      3. 配置:
         - 名称: VM-Network
         - VLAN ID: 10
         - 虚拟交换机: vSwitch1
         - 安全策略: 继承自vSwitch
      4. 完成创建
    
    存储网络端口组:
      配置:
        - 名称: Storage-Network
        - VLAN ID: 20
        - 虚拟交换机: vSwitch0
        - 仅用于iSCSI/NFS
    
    vMotion网络端口组:
      配置:
        - 名称: vMotion-Network
        - VLAN ID: 30
        - 虚拟交换机: vSwitch0
        - 启用vMotion流量
  
  网络最佳实践:
    物理网卡分配:
      管理网络: vmnic0 (独立)
      vMotion: vmnic1 (独立)
      存储网络: vmnic2, vmnic3 (绑定)
      VM业务网络: vmnic4, vmnic5 (绑定)
    
    链路聚合配置:
      策略: 
        - Route based on originating virtual port (默认)
        - Route based on IP hash (需要交换机支持)
        - Route based on physical NIC load (负载均衡)
      
      故障切换顺序:
        - Active adapters: vmnic4, vmnic5
        - Standby adapters: (空)
        - Unused adapters: (空)
```

#### 3.1.5 vCenter Server部署 🆕

**vCenter Server Appliance (VCSA) 架构**[vcsa-architecture]:

```yaml
vCenter部署方式[vcenter-deployment]:
  方式1: vCenter Server Appliance (VCSA) - 推荐
    优点:
      ✅ 基于Linux，资源占用低
      ✅ 内置PostgreSQL数据库
      ✅ 部署简单，一键安装
      ✅ 免费，包含在vSphere许可中
    
    硬件要求:
      最小配置:
        - vCPU: 2核
        - 内存: 12GB
        - 磁盘: 250GB
        - 适用: <10台主机, <100虚拟机
      
      推荐配置:
        - vCPU: 4核
        - 内存: 16GB
        - 磁盘: 300GB
        - 适用: 10-100台主机, 100-1000虚拟机
      
      大型配置:
        - vCPU: 8核
        - 内存: 24GB
        - 磁盘: 500GB
        - 适用: >100台主机, >1000虚拟机
  
  方式2: Windows vCenter Server
    说明: 从vSphere 7.0开始已弃用
    建议: 使用VCSA

VCSA部署步骤:
  阶段1: 部署OVF
    1. 挂载VCSA ISO
       Windows: 双击ISO文件
       Linux: mount -o loop vcsa.iso /mnt
    
    2. 运行安装程序
       Windows: vcsa-ui-installer\win32\installer.exe
       Linux: vcsa-ui-installer/lin64/installer
       Mac: vcsa-ui-installer/mac/installer
    
    3. 选择 "安装"
    
    4. 接受许可协议
    
    5. 部署目标配置:
       - ESXi主机: 192.168.1.101
       - HTTPS端口: 443
       - 用户名: root
       - 密码: ESXi的root密码
       - 接受证书警告
    
    6. 设置VCSA VM:
       - VM名称: vcenter-01
       - Root密码: VMware@2025
       - 确认密码
    
    7. 部署规模:
       选择: 小型（<10主机，<100VM）
             中型（10-100主机，100-1000VM）
             大型（>100主机，>1000VM）
    
    8. 选择数据存储:
       - 数据存储: datastore1
       - 磁盘预置: 精简置备（节省空间）
    
    9. 网络配置:
       - 网络: VM Network
       - IP版本: IPv4
       - IP分配: 静态
       - IP地址: 192.168.1.10
       - 子网掩码: 255.255.255.0
       - 默认网关: 192.168.1.1
       - DNS服务器: 8.8.8.8
       - 系统名称: vcenter-01.domain.local
    
    10. 检查配置并完成
        - 审核设置
        - 点击 "完成"
        - 等待部署（约10-15分钟）
  
  阶段2: 配置vCenter
    1. 部署完成后，点击 "继续"
    
    2. 时间同步配置:
       - 时间同步模式: 与ESXi主机同步
       - 或: 与NTP服务器同步
       - NTP服务器: ntp.aliyun.com
    
    3. SSO配置:
       - 创建新的SSO域（推荐）
       - SSO域名: vsphere.local
       - SSO密码: VMware@2025
       - SSO站点名称: Default-Site
    
    4. CEIP配置:
       - 参加客户体验改进计划: 否（可选）
    
    5. 检查配置并完成:
       - 审核设置
       - 点击 "完成"
       - 等待配置（约5-10分钟）
  
  阶段3: 首次登录:
    1. 访问vCenter:
       URL: https://192.168.1.10/ui
       或: https://vcenter-01.domain.local/ui
    
    2. 登录:
       用户名: administrator@vsphere.local
       密码: VMware@2025
    
    3. 接受许可协议
    
    4. 添加许可证:
       - 导航到 菜单 → 管理 → 许可
       - 添加vCenter许可证
       - 添加vSphere许可证
       - 分配许可证到vCenter
```

#### 3.1.6 创建数据中心和集群 🆕

```yaml
数据中心配置:
  创建数据中心:
    1. 登录vCenter Web界面
    2. 右键点击vCenter名称
    3. 选择 "新建数据中心"
    4. 名称: DC-Beijing
    5. 点击 "确定"

  添加ESXi主机到数据中心:
    1. 右键点击数据中心
    2. 选择 "添加主机"
    3. 主机信息:
       - 名称或IP: 192.168.1.101
       - 用户名: root
       - 密码: ESXi密码
    4. 主机摘要: 查看主机信息
    5. 分配许可证: 选择vSphere许可证
    6. 锁定模式: 已禁用（首次配置）
    7. VM位置: 数据中心
    8. 完成添加

集群配置:
  创建集群:
    1. 右键点击数据中心
    2. 选择 "新建集群"
    3. 集群名称: Cluster-Production
    4. 功能配置:
       
       □ 启用vSphere DRS (分布式资源调度)
         - DRS自动化级别: 全自动
         - 迁移阈值: 中等
         - 作用: 自动负载均衡
       
       □ 启用vSphere HA (高可用性)
         - 主机故障响应: 重启VM
         - 主机隔离响应: 关闭VM电源
         - 数据存储心跳: 启用
         - 作用: 主机故障自动恢复
       
       □ 启用vSAN (如果有)
         - 仅在有3个以上主机时
         - 需要SSD缓存盘
       
       □ 启用vSphere EVC (增强的vMotion兼容性)
         - EVC模式: Intel "Skylake"
         - 作用: 兼容不同CPU代际的主机
    
    5. 完成创建

  添加主机到集群:
    1. 将已有主机拖拽到集群
    2. 或: 右键集群 → 添加主机
    3. 输入主机信息
    4. 完成添加

  配置资源池:
    1. 右键点击集群
    2. 选择 "新建资源池"
    3. 配置:
       - 名称: Production-Pool
       - CPU资源:
         - 预留: 8GHz
         - 限制: 无限制
         - 份额: 正常
       - 内存资源:
         - 预留: 32GB
         - 限制: 无限制
         - 份额: 正常
    4. 完成创建
```

### 3.2 KVM虚拟化部署 🆕

**KVM/QEMU架构与性能**[kvm-architecture]:

#### 3.2.1 KVM环境准备

**KVM安装与配置指南**[kvm-installation]:

```bash
#!/bin/bash
# KVM安装脚本 (Ubuntu 22.04)[kvm-setup]

set -e

echo "=== 检查硬件虚拟化支持 ==="

# 检查CPU虚拟化支持
if grep -E '(vmx|svm)' /proc/cpuinfo > /dev/null; then
    echo "✅ CPU支持硬件虚拟化"
else
    echo "❌ CPU不支持硬件虚拟化"
    exit 1
fi

# 检查内核模块
echo "=== 加载KVM模块 ==="
modprobe kvm
modprobe kvm_intel  # Intel CPU
# modprobe kvm_amd  # AMD CPU

# 安装KVM和相关工具
echo "=== 安装KVM ==="
apt update
apt install -y \
    qemu-kvm \
    libvirt-daemon-system \
    libvirt-clients \
    bridge-utils \
    virt-manager \
    cpu-checker \
    libguestfs-tools \
    libosinfo-bin

# 验证安装
kvm-ok

# 启动libvirt服务
systemctl enable libvirtd
systemctl start libvirtd

# 将当前用户添加到libvirt组
usermod -aG libvirt $USER
usermod -aG kvm $USER

echo "=== KVM安装完成 ==="
echo "请重新登录以使组权限生效"
```

#### 3.2.2 KVM网络配置

```bash
# 创建桥接网络
cat > /etc/netplan/01-netcfg.yaml <<EOF
network:
  version: 2
  renderer: networkd
  ethernets:
    eno1:
      dhcp4: false
      dhcp6: false
  bridges:
    br0:
      interfaces: [eno1]
      addresses: [192.168.1.150/24]
      gateway4: 192.168.1.1
      nameservers:
        addresses: [8.8.8.8, 8.8.4.4]
      parameters:
        stp: false
        forward-delay: 0
      dhcp4: false
      dhcp6: false
EOF

# 应用配置
netplan apply

# 创建KVM网络
cat > /tmp/br0.xml <<EOF
<network>
  <name>br0</name>
  <forward mode='bridge'/>
  <bridge name='br0'/>
</network>
EOF

virsh net-define /tmp/br0.xml
virsh net-start br0
virsh net-autostart br0
virsh net-list --all
```

#### 3.2.3 创建KVM虚拟机

```bash
#!/bin/bash
# 创建KVM虚拟机

VM_NAME="ubuntu-vm01"
VCPUS=2
MEMORY=2048  # MB
DISK_SIZE=20  # GB
ISO_PATH="/var/lib/libvirt/images/ubuntu-22.04-server.iso"
DISK_PATH="/var/lib/libvirt/images/${VM_NAME}.qcow2"

# 创建磁盘
qemu-img create -f qcow2 $DISK_PATH ${DISK_SIZE}G

# 创建虚拟机
virt-install \
  --name $VM_NAME \
  --ram $MEMORY \
  --vcpus $VCPUS \
  --disk path=$DISK_PATH,format=qcow2,bus=virtio \
  --network bridge=br0,model=virtio \
  --graphics vnc,listen=0.0.0.0,port=5901 \
  --cdrom $ISO_PATH \
  --os-variant ubuntu22.04 \
  --boot uefi

echo "虚拟机创建完成"
echo "使用VNC连接: 192.168.1.150:5901"
```

### 3.3 Hyper-V虚拟化部署 🆕

**Microsoft Hyper-V架构**[hyperv-architecture]:

#### 3.3.1 Hyper-V安装

**Hyper-V安装与配置**[hyperv-installation]:

```powershell
# PowerShell脚本 (管理员权限)[hyperv-powershell]

# 检查系统要求
Write-Host "=== 检查Hyper-V支持 ===" -ForegroundColor Green
$hyperv = Get-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-All
if ($hyperv.State -eq "Enabled") {
    Write-Host "Hyper-V已启用" -ForegroundColor Yellow
} else {
    # 安装Hyper-V
    Write-Host "正在安装Hyper-V..." -ForegroundColor Cyan
    
    # 安装Hyper-V功能
    Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All -NoRestart
    
    # 安装Hyper-V管理工具
    Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Tools-All -All -NoRestart
    
    Write-Host "Hyper-V安装完成，请重启系统" -ForegroundColor Green
    
    # 提示重启
    $restart = Read-Host "是否现在重启？(Y/N)"
    if ($restart -eq "Y") {
        Restart-Computer -Force
    }
}
```

#### 3.3.2 Hyper-V网络配置

```powershell
# 创建虚拟交换机

# 外部虚拟交换机（连接物理网络）
New-VMSwitch -Name "External-Switch" -NetAdapterName "Ethernet" -AllowManagementOS $true

# 内部虚拟交换机（仅主机通信）
New-VMSwitch -Name "Internal-Switch" -SwitchType Internal

# 专用虚拟交换机（VM间通信）
New-VMSwitch -Name "Private-Switch" -SwitchType Private

# 查看虚拟交换机
Get-VMSwitch | Format-Table Name, SwitchType, NetAdapterInterfaceDescription
```

#### 3.3.3 创建Hyper-V虚拟机

```powershell
# 创建虚拟机脚本

$VMName = "Ubuntu-VM01"
$VMPath = "C:\Hyper-V\VMs"
$VHDPath = "C:\Hyper-V\VHDs\$VMName.vhdx"
$ISOPath = "C:\ISOs\ubuntu-22.04-server.iso"

# 创建虚拟硬盘
New-VHD -Path $VHDPath -SizeBytes 40GB -Dynamic

# 创建虚拟机
New-VM -Name $VMName `
    -MemoryStartupBytes 2GB `
    -Generation 2 `
    -NewVHDPath $VHDPath `
    -NewVHDSizeBytes 40GB `
    -Path $VMPath `
    -SwitchName "External-Switch"

# 配置虚拟机
Set-VMProcessor -VMName $VMName -Count 2
Set-VMMemory -VMName $VMName -DynamicMemoryEnabled $true -MinimumBytes 1GB -MaximumBytes 4GB

# 挂载ISO
Add-VMDvdDrive -VMName $VMName -Path $ISOPath

# 配置启动顺序
$dvd = Get-VMDvdDrive -VMName $VMName
Set-VMFirmware -VMName $VMName -FirstBootDevice $dvd

# 启动虚拟机
Start-VM -Name $VMName

Write-Host "虚拟机创建完成: $VMName" -ForegroundColor Green
```

### 3.4 虚拟机模板创建 🆕

#### 3.4.1 VMware虚拟机模板

```yaml
模板创建策略:
  模板类型:
    基础模板:
      - Ubuntu 22.04 LTS
      - CentOS Stream 9
      - Rocky Linux 9
      - Windows Server 2022
    
    应用模板:
      - Docker主机模板
      - Kubernetes节点模板
      - Web服务器模板
      - 数据库服务器模板

创建Ubuntu模板步骤:
  步骤1: 创建虚拟机
    1. 在vCenter中右键集群
    2. 选择 "新建虚拟机"
    3. 配置:
       - 名称: ubuntu-22.04-template
       - 兼容性: ESXi 8.0
       - 客户机OS: Ubuntu Linux (64位)
       - CPU: 2 vCPU
       - 内存: 4GB
       - 硬盘: 40GB (精简置备)
       - 网络: VM Network
    4. 挂载Ubuntu ISO
    5. 开机安装
  
  步骤2: 安装操作系统
    1. 选择语言: English
    2. 键盘: English (US)
    3. 网络: DHCP（模板用）
    4. 存储: 使用整个磁盘
    5. 用户名: template
    6. 密码: ChangeMe123!
    7. 安装OpenSSH Server
    8. 完成安装并重启
  
  步骤3: 系统优化
    ```bash
    #!/bin/bash
    # 模板系统优化脚本
    
    # 更新系统
    sudo apt update && sudo apt upgrade -y
    
    # 安装必要工具
    sudo apt install -y \
        vim \
        curl \
        wget \
        git \
        net-tools \
        htop \
        iotop \
        sysstat \
        open-vm-tools \
        cloud-init
    
    # 配置时区
    sudo timedatectl set-timezone Asia/Shanghai
    
    # 禁用交换
    sudo swapoff -a
    sudo sed -i '/ swap / s//#/' /etc/fstab
    
    # 配置内核参数
    cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes.conf
    net.bridge.bridge-nf-call-iptables  = 1
    net.bridge.bridge-nf-call-ip6tables = 1
    net.ipv4.ip_forward                 = 1
    vm.swappiness                       = 0
    EOF
    
    # 加载内核模块
    cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
    overlay
    br_netfilter
    EOF
    
    sudo modprobe overlay
    sudo modprobe br_netfilter
    
    # 安装containerd
    sudo apt install -y containerd
    sudo mkdir -p /etc/containerd
    containerd config default | sudo tee /etc/containerd/config.toml
    sudo systemctl restart containerd
    sudo systemctl enable containerd
    
    # 清理日志
    sudo journalctl --vacuum-time=1d
    sudo rm -rf /tmp/*
    sudo rm -rf /var/tmp/*
    
    # 清理网络配置（使用cloud-init重新生成）
    sudo rm -f /etc/netplan/00-installer-config.yaml
    
    # 清理SSH主机密钥（首次启动重新生成）
    sudo rm -f /etc/ssh/ssh_host_*
    
    # 清理machine-id
    sudo truncate -s 0 /etc/machine-id
    sudo rm /var/lib/dbus/machine-id
    sudo ln -s /etc/machine-id /var/lib/dbus/machine-id
    
    # 清理bash历史
    history -c
    cat /dev/null > ~/.bash_history
    
    echo "模板准备完成，准备关机转换为模板"
    ```
  
  步骤4: 转换为模板
    1. 关机虚拟机: sudo shutdown -h now
    2. 在vCenter中右键虚拟机
    3. 选择 "模板" → "转换为模板"
    4. 确认转换

使用模板部署虚拟机:
  方法1: Web界面
    1. 右键模板
    2. 选择 "从此模板新建虚拟机"
    3. 填写VM名称
    4. 选择计算资源
    5. 选择存储
    6. 自定义规范（可选）
    7. 完成部署
  
  方法2: PowerCLI脚本
    ```powershell
    # 从模板批量部署虚拟机
    
    # 连接vCenter
    Connect-VIServer -Server vcenter-01.domain.local
    
    # 配置参数
    $template = Get-Template -Name "ubuntu-22.04-template"
    $cluster = Get-Cluster -Name "Cluster-Production"
    $datastore = Get-Datastore -Name "datastore1"
    
    # 批量创建
    1..10 | ForEach-Object {
        $vmName = "k8s-node-$_"
        New-VM -Name $vmName `
            -Template $template `
            -ResourcePool $cluster `
            -Datastore $datastore
        
        # 配置网络（使用自定义规范）
        $customSpec = Get-OSCustomizationSpec -Name "Linux-DHCP"
        Set-VM -VM $vmName -OSCustomizationSpec $customSpec -Confirm:$false
        
        # 启动虚拟机
        Start-VM -VM $vmName
        
        Write-Host "虚拟机 $vmName 部署完成"
    }
    ```
```

#### 3.4.2 KVM虚拟机模板

```bash
#!/bin/bash
# KVM虚拟机模板创建脚本

TEMPLATE_NAME="ubuntu-22.04-template"
TEMPLATE_DISK="/var/lib/libvirt/images/${TEMPLATE_NAME}.qcow2"
ISO_PATH="/var/lib/libvirt/images/ubuntu-22.04-server.iso"

echo "=== 创建KVM虚拟机模板 ==="

# 创建基础虚拟机
virt-install \
  --name $TEMPLATE_NAME \
  --ram 4096 \
  --vcpus 2 \
  --disk path=$TEMPLATE_DISK,size=40,format=qcow2,bus=virtio \
  --network bridge=br0,model=virtio \
  --graphics vnc \
  --cdrom $ISO_PATH \
  --os-variant ubuntu22.04 \
  --noautoconsole

echo "等待安装完成..."
echo "手动完成系统安装后，执行以下命令准备模板："
echo ""
echo "# 登录虚拟机"
echo "virsh console $TEMPLATE_NAME"
echo ""
echo "# 系统优化（同上Ubuntu模板脚本）"
echo ""
echo "# 清理并关机"
echo "virt-sysprep -d $TEMPLATE_NAME"
echo "virsh shutdown $TEMPLATE_NAME"
echo ""
echo "# 压缩磁盘"
echo "qemu-img convert -O qcow2 -c $TEMPLATE_DISK ${TEMPLATE_DISK}.compressed"
echo "mv ${TEMPLATE_DISK}.compressed $TEMPLATE_DISK"

# 从模板克隆虚拟机
echo ""
echo "=== 从模板克隆虚拟机示例 ==="
cat <<'CLONE_SCRIPT'
#!/bin/bash
# 克隆虚拟机脚本

TEMPLATE="ubuntu-22.04-template"
NEW_VM="k8s-node-01"
NEW_DISK="/var/lib/libvirt/images/${NEW_VM}.qcow2"

# 克隆虚拟机
virt-clone \
  --original $TEMPLATE \
  --name $NEW_VM \
  --file $NEW_DISK

# 自定义虚拟机（网络、主机名等）
virt-customize -d $NEW_VM \
  --hostname $NEW_VM \
  --run-command "sed -i 's/DHCP/static/' /etc/netplan/00-installer-config.yaml" \
  --run-command "echo 'addresses: [192.168.1.201/24]' >> /etc/netplan/00-installer-config.yaml"

# 启动虚拟机
virsh start $NEW_VM

echo "虚拟机 $NEW_VM 创建完成"
CLONE_SCRIPT
```

#### 3.4.3 模板最佳实践

```yaml
模板管理最佳实践:
  命名规范:
    格式: {OS}-{VERSION}-{TYPE}-template
    示例:
      - ubuntu-22.04-base-template
      - centos9-docker-template
      - rocky9-k8s-template
      - win2022-web-template
  
  版本控制:
    策略:
      ✅ 每月更新一次系统补丁
      ✅ 重大变更创建新版本
      ✅ 保留最近3个版本
      ✅ 标注创建日期
    
    示例:
      - ubuntu-22.04-base-template-v1-2025.01
      - ubuntu-22.04-base-template-v2-2025.02
      - ubuntu-22.04-base-template-v3-2025.03
  
  模板内容:
    必装软件:
      ✅ VMware Tools / open-vm-tools
      ✅ cloud-init (自动化配置)
      ✅ qemu-guest-agent (KVM)
      ✅ 基础监控工具
      ✅ SSH服务
    
    禁止内容:
      ❌ 应用程序配置文件
      ❌ SSH密钥
      ❌ 许可证文件
      ❌ 历史日志
      ❌ 临时文件
  
  安全加固:
    系统安全:
      ✅ 禁用root SSH登录
      ✅ 配置防火墙规则
      ✅ 启用SELinux/AppArmor
      ✅ 最小化安装包
      ✅ 定期安全扫描
    
    示例加固脚本:
      ```bash
      # SSH安全配置
      sudo sed -i 's/#PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config
      sudo sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config
      
      # 配置UFW防火墙
      sudo ufw default deny incoming
      sudo ufw default allow outgoing
      sudo ufw allow ssh
      sudo ufw enable
      
      # 自动安全更新
      sudo apt install -y unattended-upgrades
      sudo dpkg-reconfigure -plow unattended-upgrades
      ```
  
  测试清单:
    部署前测试:
      □ 从模板成功创建VM
      □ VM能正常启动
      □ 网络配置正确
      □ 主机名唯一
      □ SSH可以连接
      □ 必要服务运行正常
      □ 磁盘空间充足
      □ 性能测试通过
```

## 4. 容器化部署

### 4.1 Docker部署

**Docker容器化平台**[docker-overview]:

#### 4.1.1 Docker安装

**Docker Engine安装指南**[docker-installation]:

```bash
#!/bin/bash
# Docker安装脚本[docker-setup]

# 检查系统要求
if [[ "$OSTYPE" != "linux-gnu"* ]]; then
    echo "此脚本仅支持Linux系统"
    exit 1
fi

# 卸载旧版本
sudo apt remove -y docker docker-engine docker.io containerd runc

# 安装依赖
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release

# 添加Docker官方GPG密钥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# 添加Docker仓库
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# 安装Docker
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# 启动Docker服务
sudo systemctl start docker
sudo systemctl enable docker

# 配置Docker
sudo usermod -aG docker $USER
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

sudo systemctl restart docker

# 验证安装
docker --version
docker-compose --version
```

#### 4.1.2 Docker Compose部署

**Docker Compose多容器编排**[docker-compose]:

```yaml
    # docker-compose.yml[compose-file]
version: '3.8'

services:
  virtualization-monitor:
    build: .
    ports:
      - "8080:8080"
    environment:
      - RUST_LOG=info
      - MONITORING_INTERVAL=30
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  container-orchestrator:
    build: .
    ports:
      - "8081:8080"
    environment:
      - GO_LOG_LEVEL=info
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./config:/app/config
    restart: unless-stopped

  semantic-validator:
    build: .
    ports:
      - "8082:8080"
    environment:
      - PYTHON_DEBUG=0
      - LOG_LEVEL=info
    volumes:
      - ./config:/app/config
      - ./models:/app/models
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana

volumes:
  prometheus-data:
  grafana-data:
```

### 4.2 Kubernetes部署

**Kubernetes集群架构**[kubernetes-architecture]:

#### 4.2.1 集群初始化

**使用kubeadm部署集群**[kubeadm-installation]:

```bash
    # Kubernetes集群初始化脚本[k8s-init]
#!/bin/bash

    # 安装kubeadm, kubelet, kubectl
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl
sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

    # 初始化主节点
sudo kubeadm init \
  --pod-network-cidr=10.244.0.0/16 \
  --apiserver-advertise-address=192.168.1.100 \
  --control-plane-endpoint=192.168.1.100:6443 \
  --upload-certs

    # 配置kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

    # 安装网络插件
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

    # 允许主节点调度Pod
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
```

#### 4.2.2 工作节点加入

```bash
    # 工作节点加入脚本
#!/bin/bash

    # 在主节点获取加入命令
kubeadm token create --print-join-command

    # 在工作节点执行加入命令
sudo kubeadm join 192.168.1.100:6443 --token <token> --discovery-token-ca-cert-hash <hash>

    # 验证节点状态
kubectl get nodes
```

## 5. 混合部署

### 5.1 虚拟化+容器化架构

```yaml
混合部署架构:
  虚拟化层:
    - VMware vSphere集群
    - 虚拟机资源池
    - 虚拟网络
    - 存储虚拟化
  
  容器化层:
    - Kubernetes集群
    - 容器运行时
    - 服务网格
    - 容器存储
  
  应用层:
    - 传统应用(虚拟机)
    - 微服务应用(容器)
    - 数据库服务
    - 监控服务
```

### 5.2 部署策略

```bash
    # 混合部署脚本
#!/bin/bash

    # 创建虚拟机用于传统应用
vmware-vdiskmanager -c -s 100GB -a lsilogic -t 0 traditional-app.vmdk

    # 部署传统应用到虚拟机
virt-install \
  --name traditional-app \
  --ram 4096 \
  --vcpus 4 \
  --disk path=traditional-app.vmdk \
  --network network=default \
  --graphics none \
  --console pty,target_type=serial \
  --location /path/to/centos.iso

    # 部署微服务到Kubernetes
kubectl apply -f microservices/

    # 配置服务发现
kubectl apply -f service-mesh/

    # 配置负载均衡
kubectl apply -f ingress/
```

## 6. 监控与运维

### 6.1 监控系统部署

```yaml
    # 监控系统配置
monitoring_stack:
  prometheus:
    image: prom/prometheus:latest
    config: prometheus.yml
    storage: 200h
  
  grafana:
    image: grafana/grafana:latest
    dashboards: 
      - virtualization-dashboard
      - container-dashboard
      - application-dashboard
  
  alertmanager:
    image: prom/alertmanager:latest
    config: alertmanager.yml
  
  node_exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
  
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    ports:
      - "8080:8080"
```

### 6.2 日志管理

```yaml
    # 日志管理系统
logging_stack:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
  
  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
  
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
  
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.0
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
```

### 6.3 自动化运维

```python
    # 自动化运维脚本
import asyncio
import aiohttp
import json
from datetime import datetime

class AutomationOps:
    def __init__(self):
        self.k8s_api = "https://kubernetes.default.svc"
        self.vmware_api = "https://vcenter.local"
        self.monitoring_api = "http://prometheus:9090"
    
    async def health_check(self):
        """健康检查"""
        services = [
            "virtualization-monitor",
            "container-orchestrator", 
            "semantic-validator",
            "prometheus",
            "grafana"
        ]
        
        for service in services:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(f"http://{service}:8080/health") as response:
                        if response.status == 200:
                            print(f"✅ {service} 健康")
                        else:
                            print(f"❌ {service} 不健康")
                            await self.restart_service(service)
            except Exception as e:
                print(f"❌ {service} 检查失败: {e}")
                await self.restart_service(service)
    
    async def restart_service(self, service_name):
        """重启服务"""
        try:
            # Kubernetes服务重启
            if service_name in ["container-orchestrator", "semantic-validator"]:
                await self.restart_k8s_deployment(service_name)
            # Docker服务重启
            else:
                await self.restart_docker_service(service_name)
            print(f"🔄 {service_name} 已重启")
        except Exception as e:
            print(f"❌ {service_name} 重启失败: {e}")
    
    async def scale_services(self, load_metrics):
        """自动扩缩容"""
        for service, metrics in load_metrics.items():
            if metrics["cpu"] > 80 or metrics["memory"] > 80:
                await self.scale_up(service)
            elif metrics["cpu"] < 20 and metrics["memory"] < 20:
                await self.scale_down(service)
    
    async def backup_data(self):
        """数据备份"""
        backup_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 备份数据库
        await self.backup_database(backup_time)
        
        # 备份配置文件
        await self.backup_configs(backup_time)
        
        # 备份日志
        await self.backup_logs(backup_time)
        
        print(f"✅ 备份完成: {backup_time}")
```

## 7. 故障排除

### 7.1 常见问题诊断

```bash
    # 故障诊断脚本
#!/bin/bash

echo "=== 系统诊断 ==="

    # 检查系统资源
echo "CPU使用率:"
top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1

echo "内存使用率:"
free | grep Mem | awk '{printf "%.2f%%", $3/$2 * 100.0}'

echo "磁盘使用率:"
df -h | grep -E '/dev/'

    # 检查网络连接
echo "网络连接状态:"
netstat -tuln | grep -E ':(80|443|8080|8081|8082|9090|3000)'

    # 检查Docker状态
echo "Docker状态:"
docker ps
docker system df

    # 检查Kubernetes状态
echo "Kubernetes状态:"
kubectl get nodes
kubectl get pods --all-namespaces
kubectl get services --all-namespaces

    # 检查服务日志
echo "服务日志:"
docker logs virtualization-monitor --tail 50
docker logs container-orchestrator --tail 50
docker logs semantic-validator --tail 50
```

### 7.2 性能问题排查

```python
    # 性能问题排查工具
import psutil
import docker
import requests
import time

class PerformanceDiagnostics:
    def __init__(self):
        self.docker_client = docker.from_env()
    
    def check_system_performance(self):
        """检查系统性能"""
        print("=== 系统性能检查 ===")
        
        # CPU使用率
        cpu_percent = psutil.cpu_percent(interval=1)
        print(f"CPU使用率: {cpu_percent}%")
        
        # 内存使用率
        memory = psutil.virtual_memory()
        print(f"内存使用率: {memory.percent}%")
        
        # 磁盘IO
        disk_io = psutil.disk_io_counters()
        print(f"磁盘读取: {disk_io.read_bytes / 1024 / 1024:.2f} MB")
        print(f"磁盘写入: {disk_io.write_bytes / 1024 / 1024:.2f} MB")
        
        # 网络IO
        network_io = psutil.net_io_counters()
        print(f"网络接收: {network_io.bytes_recv / 1024 / 1024:.2f} MB")
        print(f"网络发送: {network_io.bytes_sent / 1024 / 1024:.2f} MB")
    
    def check_container_performance(self):
        """检查容器性能"""
        print("=== 容器性能检查 ===")
        
        containers = self.docker_client.containers.list()
        for container in containers:
            stats = container.stats(stream=False)
            
            # CPU使用率
            cpu_delta = stats['cpu_stats']['cpu_usage']['total_usage'] - stats['precpu_stats']['cpu_usage']['total_usage']
            system_delta = stats['cpu_stats']['system_cpu_usage'] - stats['precpu_stats']['system_cpu_usage']
            cpu_percent = (cpu_delta / system_delta) * len(stats['cpu_stats']['cpu_usage']['percpu_usage']) * 100.0
            
            # 内存使用率
            memory_usage = stats['memory_stats']['usage']
            memory_limit = stats['memory_stats']['limit']
            memory_percent = (memory_usage / memory_limit) * 100.0
            
            print(f"容器 {container.name}:")
            print(f"  CPU使用率: {cpu_percent:.2f}%")
            print(f"  内存使用率: {memory_percent:.2f}%")
    
    def check_service_response_time(self):
        """检查服务响应时间"""
        print("=== 服务响应时间检查 ===")
        
        services = [
            "http://localhost:8080/health",
            "http://localhost:8081/health", 
            "http://localhost:8082/health",
            "http://localhost:9090/-/healthy",
            "http://localhost:3000/api/health"
        ]
        
        for service_url in services:
            try:
                start_time = time.time()
                response = requests.get(service_url, timeout=5)
                response_time = time.time() - start_time
                
                if response.status_code == 200:
                    print(f"✅ {service_url}: {response_time:.3f}s")
                else:
                    print(f"❌ {service_url}: HTTP {response.status_code}")
            except Exception as e:
                print(f"❌ {service_url}: {e}")
```

## 8. 存储架构标准配置 🆕

**企业级存储架构设计**[storage-design]:

### 8.1 存储类型与选型标准

**存储技术对比与选型**[storage-comparison]:

```yaml
存储架构分类[storage-types]:
  本地存储 (DAS - Direct Attached Storage):
    特点:
      ✅ 最高性能（PCIe直连）
      ✅ 最低延迟 (<1ms)
      ✅ 成本最低
      ❌ 无共享存储
      ❌ 不支持vMotion
      ❌ 扩展性差
    
    适用场景:
      - 小型环境（1-5台主机）
      - 边缘计算节点
      - 高性能计算（HPC）
      - 数据库缓存层
      - 测试开发环境
    
    推荐配置:
      系统盘: 2x 480GB SATA SSD (RAID1)
      数据盘: 4-8x NVMe SSD (RAID10)
      控制器: 带电池备份缓存
  
  网络存储 (NAS - Network Attached Storage):
    特点:
      ✅ 文件级共享存储
      ✅ 支持vMotion/DRS
      ✅ 易于管理和扩展
      ✅ 多协议支持（NFS/SMB）
      ⚠️ 性能中等
      ⚠️ 网络依赖性高
    
    适用场景:
      - 中小型环境（5-50台主机）
      - 虚拟机存储
      - ISO/模板库
      - 文件共享服务
      - 日志归档存储
    
    性能要求:
      网络: 10GbE以上（推荐25GbE）
      延迟: <3ms
      IOPS: 10,000+ (SSD)
      带宽: 1GB/s+
    
    推荐产品:
      入门级: Synology DS1821+ (¥18,000)
      企业级: NetApp FAS2750 (¥280,000)
      开源方案: TrueNAS Scale (¥120,000硬件)
  
  SAN存储 (Storage Area Network):
    iSCSI SAN:
      特点:
        ✅ 块级存储
        ✅ 基于以太网
        ✅ 支持多路径
        ✅ 成本适中
        ⚠️ 需要专用网络
      
      网络要求:
        专用VLAN: 隔离存储流量
        链路聚合: 多路径高可用
        Jumbo Frame: MTU 9000
        QoS: 存储流量优先
      
      配置示例:
        ```bash
        # ESXi iSCSI配置
        # 1. 创建iSCSI适配器
        esxcli iscsi software set --enabled=true
        
        # 2. 配置iSCSI网络
        esxcli network ip interface ipv4 set \
          -i vmk1 -t static -I 192.168.20.101 -N 255.255.255.0
        
        # 3. 绑定网络端口
        esxcli iscsi networkportal add \
          -A vmhba33 -n vmk1
        
        # 4. 添加iSCSI目标
        esxcli iscsi adapter discovery sendtarget add \
          -A vmhba33 -a 192.168.20.10:3260
        
        # 5. 重新扫描
        esxcli storage core adapter rescan --adapter=vmhba33
        ```
    
    FC SAN (Fibre Channel):
      特点:
        ✅ 最高性能
        ✅ 最低延迟 (<1ms)
        ✅ 最高可靠性
        ✅ 企业级标准
        ❌ 成本最高
        ❌ 配置复杂
      
      硬件要求:
        HBA卡: 16Gb/32Gb FC
        FC交换机: Brocade/Cisco
        存储阵列: EMC/NetApp/HPE
      
      性能指标:
        带宽: 16Gb/32Gb (2GB/s-4GB/s)
        延迟: <0.5ms
        IOPS: 100,000+
  
  超融合架构 (HCI - Hyper-Converged Infrastructure):
    VMware vSAN:
      特点:
        ✅ 软件定义存储
        ✅ 深度集成vSphere
        ✅ 横向扩展
        ✅ 简化管理
        ⚠️ 最少3节点
        ⚠️ 许可成本高
      
      硬件要求:
        缓存层: NVMe SSD (10% 容量)
        容量层: SSD或HDD
        网络: 10GbE以上
        内存: 大容量ECC
      
      存储策略:
        RAID-1 (镜像):
          副本数: 2
          容错: 1个节点
          空间效率: 50%
          最小节点: 3
        
        RAID-5 (纠删码):
          奇偶校验: 1
          容错: 1个节点
          空间效率: 75%
          最小节点: 4
        
        RAID-6 (纠删码):
          奇偶校验: 2
          容错: 2个节点
          空间效率: 67%
          最小节点: 6
    
    Ceph分布式存储:
      特点:
        ✅ 开源免费
        ✅ 高度可扩展
        ✅ 支持块/文件/对象
        ✅ Kubernetes原生
        ⚠️ 运维复杂
        ⚠️ 调优难度大
      
      集群规划:
        MON节点: 3个（奇数）
        MGR节点: 2个（主备）
        OSD节点: 最少3个
        MDS节点: 2个（CephFS）
      
      硬件配置/OSD节点:
        CPU: 2核/OSD
        内存: 4-8GB/OSD
        网络: 双10GbE+
        磁盘: 10-12块/节点

存储性能对比表:
  | 类型 | IOPS | 延迟 | 带宽 | 成本 | 可靠性 | 推荐场景 |
  |------|------|------|------|------|--------|----------|
  | 本地NVMe | 500K+ | <0.1ms | 3GB/s+ | ★★★★ | ★★★ | HPC/数据库 |
  | iSCSI SSD | 50K+ | <3ms | 1GB/s | ★★★ | ★★★★ | 虚拟化 |
  | NFS SSD | 30K+ | <5ms | 500MB/s | ★★★★ | ★★★★ | 文件共享 |
  | FC SAN | 100K+ | <0.5ms | 2GB/s+ | ★★ | ★★★★★ | 关键业务 |
  | vSAN | 50K+ | <2ms | 1GB/s | ★★ | ★★★★ | 超融合 |
  | Ceph | 30K+ | <5ms | 500MB/s | ★★★★★ | ★★★★ | 云原生 |
```

### 8.2 网络架构标准配置 🆕

**虚拟化网络设计最佳实践**[network-design]:

```yaml
网络架构设计标准[network-standards]:
  VLAN规划标准:
    管理网络 (VLAN 10):
      用途: ESXi/vCenter管理接口
      IP段: 192.168.10.0/24
      网关: 192.168.10.1
      DHCP: 禁用（静态IP）
      MTU: 1500
      QoS: 高优先级
      安全: 防火墙严格限制
    
    存储网络 (VLAN 20):
      用途: iSCSI/NFS存储流量
      IP段: 192.168.20.0/24
      网关: 无（二层直连）
      DHCP: 禁用
      MTU: 9000 (Jumbo Frame)
      QoS: 最高优先级
      安全: 完全隔离
      绑定: VMkernel专用端口
    
    vMotion网络 (VLAN 30):
      用途: 虚拟机热迁移
      IP段: 192.168.30.0/24
      网关: 无（二层直连）
      DHCP: 禁用
      MTU: 9000
      QoS: 高优先级
      带宽: 10GbE以上
    
    虚拟机网络 - 生产 (VLAN 40-49):
      VLAN 40: Web层 (10.0.40.0/22)
      VLAN 41: 应用层 (10.0.44.0/22)
      VLAN 42: 数据库层 (10.0.48.0/24)
      VLAN 43: 缓存层 (10.0.49.0/24)
      特点: 三层隔离，防火墙策略
    
    虚拟机网络 - 开发测试 (VLAN 50-59):
      VLAN 50: 开发环境 (10.0.50.0/24)
      VLAN 51: 测试环境 (10.0.51.0/24)
      VLAN 52: 预发布环境 (10.0.52.0/24)
      特点: DHCP启用，灵活配置
    
    DMZ网络 (VLAN 60):
      用途: 对外服务（Web/API）
      IP段: 公网IP段或NAT
      安全: 严格ACL控制
      监控: 入侵检测系统
    
    Kubernetes网络 (VLAN 100-109):
      VLAN 100: K8s节点网络 (10.100.0.0/16)
      Pod网络: 10.244.0.0/16 (Overlay)
      Service网络: 10.96.0.0/12 (ClusterIP)
      
      CNI选择:
        Calico: VXLAN/BGP模式
        Cilium: eBPF加速
        Flannel: 简单易用

物理网络拓扑标准:
  接入层交换机配置:
    端口配置:
      ```
      # Cisco交换机配置示例
      
      # 全局配置
      spanning-tree mode rapid-pvst
      spanning-tree extend system-id
      
      # 创建VLAN
      vlan 10
        name Management
      vlan 20
        name Storage
      vlan 30
        name vMotion
      vlan 40
        name VM-Production
      vlan 50
        name VM-Development
      vlan 100
        name K8s-Nodes
      
      # Trunk端口（上行到汇聚层）
      interface range GigabitEthernet1/0/47-48
        description Uplink to Core
        switchport mode trunk
        switchport trunk allowed vlan 10,20,30,40,50,100
        channel-group 1 mode active
        spanning-tree portfast trunk
      
      # 服务器接入端口
      interface range GigabitEthernet1/0/1-24
        description ESXi Hosts
        switchport mode trunk
        switchport trunk allowed vlan 10,20,30,40,50,100
        spanning-tree portfast trunk
        storm-control broadcast level 10.00
        storm-control multicast level 10.00
      
      # 存储网络端口（专用）
      interface range GigabitEthernet1/0/25-30
        description Storage Network
        switchport mode access
        switchport access vlan 20
        mtu 9000
        spanning-tree portfast
      ```
  
  链路聚合标准 (LACP):
    ESXi主机配置:
      管理+业务网络:
        物理网卡: vmnic0, vmnic1
        模式: LACP Active
        负载均衡: Route based on IP hash
        故障切换: 3秒内
      
      存储网络:
        物理网卡: vmnic2, vmnic3
        模式: LACP Active
        负载均衡: Route based on originating port
        专用: 仅存储流量
      
      vMotion网络:
        物理网卡: vmnic4, vmnic5
        模式: LACP Active
        专用: 仅vMotion流量
    
    配置脚本:
      ```bash
      # VMware分布式交换机LACP配置
      
      # 1. 创建分布式交换机
      New-VDSwitch -Name "vDS-Production" \
        -Location (Get-Datacenter) \
        -NumUplinkPorts 6
      
      # 2. 添加主机
      Get-VMHost | Add-VDSwitchVMHost -VDSwitch "vDS-Production"
      
      # 3. 添加物理网卡
      $vmhost = Get-VMHost "esxi-01.domain.local"
      $vds = Get-VDSwitch "vDS-Production"
      $pnic = Get-VMHostNetworkAdapter -VMHost $vmhost -Physical -Name vmnic0,vmnic1
      Add-VDSwitchPhysicalNetworkAdapter -VMHostPhysicalNic $pnic \
        -DistributedSwitch $vds -Confirm:$false
      
      # 4. 创建上行链路组（启用LACP）
      $vds | New-VDUplinkLACPGroup -Name "LAG-Management" \
        -NumberOfPorts 2 -LoadBalancingMode "SrcDestIpTcpUdpPortId"
      
      # 5. 创建端口组
      New-VDPortgroup -Name "Management" -VDSwitch $vds -VlanId 10
      New-VDPortgroup -Name "Storage" -VDSwitch $vds -VlanId 20
      New-VDPortgroup -Name "vMotion" -VDSwitch $vds -VlanId 30
      New-VDPortgroup -Name "VM-Network" -VDSwitch $vds -VlanId 40
      ```

网络性能优化标准:
  Jumbo Frame配置:
    要求:
      - 全链路支持（服务器-交换机-存储）
      - MTU 9000
      - 仅用于存储和vMotion网络
    
    配置步骤:
      1. 交换机启用Jumbo Frame
      2. ESXi vSwitch MTU设置为9000
      3. VMkernel端口MTU设置为9000
      4. 存储设备MTU设置为9000
      5. 测试验证:
         ```bash
         vmkping -s 8972 -d 192.168.20.10
         ```
  
  网络流量整形:
    QoS配置:
      ```yaml
      流量优先级:
        0 - 最低: 日常管理流量
        1 - 低: VM一般业务
        2 - 中: VM重要业务
        3 - 高: vMotion流量
        4 - 最高: 存储流量
      
      带宽限制:
        管理流量: 无限制
        vMotion: 保证带宽1Gbps
        存储: 保证带宽5Gbps
        VM业务: 按需分配
      ```
  
  网络安全标准:
    vSwitch安全策略:
      混杂模式: 拒绝
      MAC地址更改: 拒绝
      伪传输: 接受
    
    防火墙规则:
      ```bash
      # ESXi防火墙配置
      
      # 查看规则集
      esxcli network firewall ruleset list
      
      # 允许SSH（管理网络）
      esxcli network firewall ruleset set \
        --ruleset-id=sshServer --enabled=true
      
      # 允许NTP
      esxcli network firewall ruleset set \
        --ruleset-id=ntpClient --enabled=true
      
      # 限制vCenter访问
      esxcli network firewall ruleset allowedip add \
        --ruleset-id=vSphereClient \
        --ip-address=192.168.10.10/32
      ```

## 9. 高可用与容灾标准配置 🆕

**高可用性架构设计**[ha-architecture]:

### 9.1 VMware HA配置标准

**vSphere HA深度配置**[vsphere-ha]:

```yaml
vSphere HA完整配置[ha-configuration]:
  基础配置:
    集群HA: 启用
    准入控制: 启用
    策略: 集群资源百分比
    CPU预留: 25%
    内存预留: 25%
    
    故障条件:
      主机故障: 重启VM
      主机隔离: 关闭VM电源
      数据存储PDL: 关闭VM电源并重启
      数据存储APD: 关闭VM电源并重启
  
  高级配置:
    心跳数据存储:
      数量: 2-4个
      选择: 不同存储阵列
      目的: 网络隔离检测
    
    VM重启优先级:
      最高优先级:
        - 数据库服务器（MySQL/PostgreSQL）
        - AD域控制器
        - DNS服务器
        - 核心业务应用
      
      高优先级:
        - Web服务器
        - 应用服务器
        - 消息队列
      
      中优先级:
        - 日志服务器
        - 监控服务器
      
      低优先级:
        - 开发测试环境
        - 临时虚拟机
      
      禁用:
        - 维护中的虚拟机
    
    VM监控:
      VM监控: 仅VM监控
      VM重启灵敏度: 中
      失败间隔: 30秒
      最少正常运行时间: 120秒
      每个VM的最大重启次数: 3次
      重启窗口: 1小时
  
  故障隔离响应:
    隔离地址:
      - 默认网关: 192.168.10.1
      - 备用地址1: 8.8.8.8
      - 备用地址2: 114.114.114.114
    
    响应: 关闭VM电源并重启
    延迟: 30秒

配置PowerCLI脚本:
  ```powershell
  # vSphere HA完整配置脚本
  
  # 连接vCenter
  Connect-VIServer -Server vcenter.domain.local
  
  # 获取集群
  $cluster = Get-Cluster "Cluster-Production"
  
  # 启用HA
  Set-Cluster -Cluster $cluster `
    -HAEnabled $true `
    -HAAdmissionControlEnabled $true `
    -HAFailoverLevel 1 `
    -HAIsolationResponse PowerOff `
    -HARestartPriority High `
    -Confirm:$false
  
  # 配置准入控制
  $spec = New-Object VMware.Vim.ClusterConfigSpecEx
  $spec.DasConfig = New-Object VMware.Vim.ClusterDasConfigInfo
  $spec.DasConfig.AdmissionControlPolicy = `
    New-Object VMware.Vim.ClusterFailoverResourcesAdmissionControlPolicy
  $spec.DasConfig.AdmissionControlPolicy.CpuFailoverResourcesPercent = 25
  $spec.DasConfig.AdmissionControlPolicy.MemoryFailoverResourcesPercent = 25
  
  # 配置心跳数据存储
  $datastores = Get-Datastore "datastore1","datastore2"
  Set-Cluster -Cluster $cluster `
    -HAHeartbeatDatastore $datastores `
    -Confirm:$false
  
  # 配置VM监控
  $spec.DasConfig.VmMonitoring = "vmMonitoringOnly"
  $spec.DasConfig.VmMonitoringSensitivity = 2
  
  # 应用配置
  $cluster.ExtensionData.ReconfigureComputeResource_Task($spec, $true)
  
  Write-Host "✓ vSphere HA配置完成"
  ```

### 9.2 Kubernetes高可用配置

**Kubernetes HA集群设计**[k8s-ha]:

```yaml
K8s HA架构标准[k8s-ha-architecture]:
  控制平面HA:
    Master节点数: 3个（奇数）
    负载均衡器: HAProxy/Nginx
    VIP: 使用Keepalived
    
    架构图:
      ```
      [VIP: 192.168.1.100]
           ↓
      [HAProxy负载均衡器]
           ↓
      ═══════════════════
      ↓        ↓        ↓
    [Master1][Master2][Master3]
      ↓        ↓        ↓
      ═══════════════════
            ↓
      [etcd集群 - 3节点]
      ```
  
  HAProxy配置:
    ```
    global
        log /dev/log local0
        log /dev/log local1 notice
        daemon
    
    defaults
        log global
        mode tcp
        option tcplog
        option dontlognull
        timeout connect 5000ms
        timeout client 50000ms
        timeout server 50000ms
    
    frontend k8s-api
        bind *:6443
        default_backend k8s-api-backend
        option tcplog
    
    backend k8s-api-backend
        balance roundrobin
        option tcp-check
        option log-health-checks
        server master1 192.168.1.101:6443 check inter 2000 rise 2 fall 3
        server master2 192.168.1.102:6443 check inter 2000 rise 2 fall 3
        server master3 192.168.1.103:6443 check inter 2000 rise 2 fall 3
    
    # 统计页面
    listen stats
        bind *:9000
        mode http
        stats enable
        stats uri /stats
        stats realm HAProxy\ Statistics
        stats auth admin:password
    ```
  
  Keepalived配置:
    Master节点:
      ```
      vrrp_instance VI_1 {
          state MASTER
          interface ens192
          virtual_router_id 51
          priority 100
          advert_int 1
          
          authentication {
              auth_type PASS
              auth_pass K8s_VIP_Pass
          }
          
          virtual_ipaddress {
              192.168.1.100/24 dev ens192
          }
          
          track_script {
              check_haproxy
          }
      }
      
      vrrp_script check_haproxy {
          script "/usr/bin/killall -0 haproxy"
          interval 2
          weight -20
      }
      ```
  
  etcd高可用:
    部署要求:
      节点数: 3/5/7（奇数）
      数据目录: SSD存储
      网络: 低延迟(<5ms)
      备份: 定期快照
    
    健康检查:
      ```bash
      # 检查集群状态
      ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        member list
      
      # 检查集群健康
      ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        endpoint health
      
      # 检查性能
      ETCDCTL_API=3 etcdctl \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key \
        endpoint status --write-out=table
      ```

### 9.3 备份与容灾标准

```bash
#!/bin/bash
# 企业级备份脚本

# 配置变量
BACKUP_ROOT="/backup"
RETENTION_DAYS=30
DATE=$(date +%Y%m%d_%H%M%S)
LOG_FILE="/var/log/backup_${DATE}.log"

# 日志函数
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# 1. VMware虚拟机备份
backup_vmware() {
    log "=== 开始VMware备份 ==="
    
    BACKUP_DIR="${BACKUP_ROOT}/vmware/${DATE}"
    mkdir -p $BACKUP_DIR
    
    # 获取虚拟机列表
    VMS=$(vim-cmd vmsvc/getallvms | awk '{if(NR>1)print $1}')
    
    for VM_ID in $VMS; do
        VM_NAME=$(vim-cmd vmsvc/get.summary $VM_ID | grep -A1 "name =" | tail -1 | awk '{print $3}' | tr -d '"')
        log "备份虚拟机: $VM_NAME (ID: $VM_ID)"
        
        # 创建快照
        vim-cmd vmsvc/snapshot.create $VM_ID "Backup-${DATE}" "Automated backup" 0 0
        
        # 导出OVF
        ovftool vi://root@localhost/$VM_NAME "${BACKUP_DIR}/${VM_NAME}.ova"
        
        # 删除快照
        SNAPSHOT_ID=$(vim-cmd vmsvc/snapshot.get $VM_ID | grep "Snapshot Id" | awk '{print $4}')
        vim-cmd vmsvc/snapshot.remove $VM_ID $SNAPSHOT_ID
        
        log "✓ $VM_NAME 备份完成"
    done
}

# 2. Kubernetes备份 (使用Velero)
backup_kubernetes() {
    log "=== 开始Kubernetes备份 ==="
    
    # 检查Velero
    if ! command -v velero &> /dev/null; then
        log "❌ Velero未安装"
        return 1
    fi
    
    # 备份所有命名空间
    NAMESPACES=$(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}')
    
    for NS in $NAMESPACES; do
        if [[ "$NS" != "kube-system" && "$NS" != "kube-public" && "$NS" != "kube-node-lease" ]]; then
            log "备份命名空间: $NS"
            velero backup create ${NS}-${DATE} \
                --include-namespaces $NS \
                --snapshot-volumes \
                --wait
            
            log "✓ $NS 备份完成"
        fi
    done
}

# 3. etcd备份
backup_etcd() {
    log "=== 开始etcd备份 ==="
    
    BACKUP_DIR="${BACKUP_ROOT}/etcd/${DATE}"
    mkdir -p $BACKUP_DIR
    
    ETCDCTL_API=3 etcdctl snapshot save \
        ${BACKUP_DIR}/etcd-snapshot.db \
        --endpoints=https://127.0.0.1:2379 \
        --cacert=/etc/kubernetes/pki/etcd/ca.crt \
        --cert=/etc/kubernetes/pki/etcd/server.crt \
        --key=/etc/kubernetes/pki/etcd/server.key
    
    # 验证备份
    ETCDCTL_API=3 etcdctl snapshot status \
        ${BACKUP_DIR}/etcd-snapshot.db \
        --write-out=table
    
    log "✓ etcd备份完成"
}

# 4. 配置文件备份
backup_configs() {
    log "=== 开始配置文件备份 ==="
    
    BACKUP_DIR="${BACKUP_ROOT}/configs/${DATE}"
    mkdir -p $BACKUP_DIR
    
    # Docker配置
    if [ -d /etc/docker ]; then
        tar czf ${BACKUP_DIR}/docker-config.tar.gz /etc/docker
    fi
    
    # Kubernetes配置
    if [ -d /etc/kubernetes ]; then
        tar czf ${BACKUP_DIR}/kubernetes-config.tar.gz /etc/kubernetes
    fi
    
    # ESXi配置
    if [ -f /etc/vmware/esx.conf ]; then
        vim-cmd hostsvc/firmware/backup_config
        cp /scratch/downloads/*.tgz ${BACKUP_DIR}/
    fi
    
    log "✓ 配置文件备份完成"
}

# 5. 数据库备份
backup_databases() {
    log "=== 开始数据库备份 ==="
    
    BACKUP_DIR="${BACKUP_ROOT}/databases/${DATE}"
    mkdir -p $BACKUP_DIR
    
    # PostgreSQL
    kubectl get pods -A | grep postgres | while read NS POD REST; do
        log "备份PostgreSQL: $NS/$POD"
        kubectl exec -n $NS $POD -- pg_dumpall -U postgres > \
            ${BACKUP_DIR}/${NS}-${POD}.sql
    done
    
    # MySQL
    kubectl get pods -A | grep mysql | while read NS POD REST; do
        log "备份MySQL: $NS/$POD"
        kubectl exec -n $NS $POD -- mysqldump -u root --all-databases > \
            ${BACKUP_DIR}/${NS}-${POD}.sql
    done
    
    log "✓ 数据库备份完成"
}

# 6. 清理旧备份
cleanup_old_backups() {
    log "=== 清理旧备份 ==="
    
    find ${BACKUP_ROOT} -type d -mtime +${RETENTION_DAYS} -exec rm -rf {} \;
    
    log "✓ 旧备份清理完成"
}

# 7. 备份到远程存储
sync_to_remote() {
    log "=== 同步到远程存储 ==="
    
    # S3同步
    if command -v aws &> /dev/null; then
        aws s3 sync ${BACKUP_ROOT} s3://my-backup-bucket/backups/ \
            --delete --storage-class GLACIER
        log "✓ S3同步完成"
    fi
    
    # NFS同步
    if mount | grep -q /mnt/backup; then
        rsync -av --delete ${BACKUP_ROOT}/ /mnt/backup/
        log "✓ NFS同步完成"
    fi
}

# 主函数
main() {
    log "========================================="
    log "开始备份任务"
    log "========================================="
    
    backup_vmware
    backup_kubernetes
    backup_etcd
    backup_configs
    backup_databases
    cleanup_old_backups
    sync_to_remote
    
    log "========================================="
    log "备份任务完成"
    log "========================================="
    
    # 发送通知
    # mail -s "Backup Completed" admin@example.com < $LOG_FILE
}

# 执行备份
main
```

## 10. 最佳实践

### 10.1 部署最佳实践

```yaml
部署最佳实践:
  环境隔离:
    开发环境: 单节点部署
    测试环境: 小规模集群
    生产环境: 高可用集群
  
  资源规划:
    CPU: 预留20%资源
    内存: 预留30%资源
    存储: 预留50%空间
    网络: 预留带宽
  
  安全配置:
    启用防火墙: 限制端口访问
    使用HTTPS: 加密通信
    定期更新: 安全补丁
    访问控制: 最小权限
  
  监控告警:
    资源监控: CPU/内存/磁盘
    应用监控: 响应时间/错误率
    日志监控: 异常日志
    告警通知: 及时通知
```

### 10.2 运维最佳实践

```bash
    # 运维最佳实践脚本
#!/bin/bash

    # 定期维护任务
maintenance_tasks() {
    echo "=== 定期维护任务 ==="
    
    # 清理Docker镜像
    docker system prune -f
    
    # 清理Kubernetes资源
    kubectl delete pods --field-selector=status.phase=Succeeded
    kubectl delete pods --field-selector=status.phase=Failed
    
    # 清理日志文件
    find /var/log -name "*.log" -mtime +30 -delete
    
    # 更新系统包
    apt update && apt upgrade -y
    
    # 重启服务
    systemctl restart docker
    systemctl restart kubelet
}

    # 备份脚本
backup_script() {
    echo "=== 数据备份 ==="
    
    backup_dir="/backup/$(date +%Y%m%d)"
    mkdir -p $backup_dir
    
    # 备份配置文件
    cp -r /etc/docker $backup_dir/
    cp -r /etc/kubernetes $backup_dir/
    
    # 备份数据
    docker run --rm -v /var/lib/docker:/data -v $backup_dir:/backup alpine tar czf /backup/docker-data.tar.gz /data
    
    # 备份数据库
    kubectl exec -n default postgres-0 -- pg_dump -U postgres postgres > $backup_dir/database.sql
    
    echo "备份完成: $backup_dir"
}

    # 监控脚本
monitoring_script() {
    echo "=== 系统监控 ==="
    
    # 检查服务状态
    systemctl is-active docker
    systemctl is-active kubelet
    
    # 检查资源使用
    df -h
    free -h
    top -bn1 | head -5
    
    # 检查网络连接
    netstat -tuln | grep -E ':(80|443|8080|8081|8082|9090|3000)'
}

    # 执行维护任务
case "$1" in
    "maintenance")
        maintenance_tasks
        ;;
    "backup")
        backup_script
        ;;
    "monitor")
        monitoring_script
        ;;
    *)
        echo "用法: $0 {maintenance|backup|monitor}"
        exit 1
        ;;
esac
```

### 10.3 故障恢复

```yaml
故障恢复策略:
  服务故障:
    自动重启: 配置重启策略
    健康检查: 定期健康检查
    故障转移: 自动故障转移
    负载均衡: 分散负载
  
  数据故障:
    数据备份: 定期备份
    数据恢复: 快速恢复
    数据同步: 实时同步
    数据验证: 完整性检查
  
  网络故障:
    网络冗余: 多路径网络
    故障检测: 网络监控
    自动切换: 网络切换
    故障隔离: 网络隔离
  
  硬件故障:
    硬件冗余: 冗余硬件
    故障检测: 硬件监控
    自动切换: 硬件切换
    故障隔离: 硬件隔离
```

---

## 参考资源

### 1. 官方文档

[deployment-guide]: Enterprise Deployment Guide, https://www.vmware.com/support/pubs/
[enterprise-architecture]: Enterprise Architecture Best Practices, https://www.vmware.com/solutions/enterprise-architecture.html

### 2. 硬件与BIOS

[cpu-virtualization]: Intel Virtualization Technology, https://www.intel.com/content/www/us/en/virtualization/virtualization-technology/intel-virtualization-technology.html
[memory-sizing]: VMware Memory Sizing Guidelines, https://www.vmware.com/pdf/vi3_memory_sizing_for_consolidation.pdf
[storage-architecture]: Storage Architecture Design Guide, https://www.vmware.com/products/vsphere/storage.html
[network-architecture]: Network Architecture Best Practices, https://www.vmware.com/pdf/vi_network_architecture.pdf
[bios-virtualization]: BIOS Virtualization Settings, https://www.intel.com/content/www/us/en/support/articles/000005729/processors.html

### 3. VMware vSphere

[vmware-hcl]: VMware Hardware Compatibility List, https://www.vmware.com/resources/compatibility
[vsphere-architecture]: vSphere Architecture, https://docs.vmware.com/en/VMware-vSphere/8.0/vsphere-architecture/
[esxi-installation]: ESXi Installation and Setup, https://docs.vmware.com/en/VMware-vSphere/8.0/vsphere-esxi-installation/
[vcsa-architecture]: vCenter Server Appliance Architecture, https://docs.vmware.com/en/VMware-vSphere/8.0/vsphere-vcenter-configuration/

### 4. KVM虚拟化

[kvm-architecture]: KVM Architecture, https://www.linux-kvm.org/page/Main_Page
[kvm-installation]: KVM Installation Guide, https://www.linux-kvm.org/page/Getting_Started

### 5. Hyper-V

[hyperv-architecture]: Hyper-V Architecture, https://docs.microsoft.com/en-us/windows-server/virtualization/hyper-v/hyper-v-technology-overview
[hyperv-installation]: Install Hyper-V, https://docs.microsoft.com/en-us/windows-server/virtualization/hyper-v/get-started/install-the-hyper-v-role-on-windows-server

### 6. Docker容器

[docker-overview]: Docker Overview, https://docs.docker.com/get-started/overview/
[docker-installation]: Docker Engine Installation, https://docs.docker.com/engine/install/
[docker-compose]: Docker Compose, https://docs.docker.com/compose/

### 7. Kubernetes

[kubernetes-architecture]: Kubernetes Architecture, https://kubernetes.io/docs/concepts/architecture/
[kubeadm-installation]: Creating a cluster with kubeadm, https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/
[k8s-ha]: Kubernetes High Availability, https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/

### 8. 存储与网络

[storage-design]: Storage Design Guide, https://storagehub.vmware.com/section-assets/vmware-vsphere-storage-best-practices
[storage-comparison]: Storage Technology Comparison, https://www.vmware.com/products/vsphere/storage.html
[network-design]: Network Design Best Practices, https://docs.vmware.com/en/VMware-vSphere/8.0/vsphere-networking/

---

## 11. 相关文档

### 核心技术文档

- [Docker架构原理](../Container/01_Docker技术详解/01_Docker架构原理.md) - 容器技术基础
- [Kubernetes架构原理](../Container/03_Kubernetes技术详解/01_Kubernetes架构原理.md) - 容器编排基础
- [vSphere架构概述](../vShpere_VMware/01_vSphere基础架构/01_vSphere架构概述.md) - 虚拟化基础
- [ESXi安装配置](../vShpere_VMware/02_ESXi技术详解/02_ESXi安装配置.md) - 虚拟化平台安装

### 技术实施文档

- [技术实施指南与最佳实践](../Analysis/02_技术实施指南与最佳实践.md) - 完整实施指导
- [性能分析与优化综合指南](../Analysis/04_性能分析与优化综合指南.md) - 性能调优指南
- [技术标准合规性与对标分析](../Analysis/03_技术标准合规性与对标分析.md) - 标准合规性

### 安全与运维文档

- [安全架构指南](../Security/01_虚拟化容器化安全架构终极指南.md) - 安全设计指导
- [语义模型验证工具](../Semantic/04_语义模型验证工具与代码实现.md) - 系统验证工具
- [项目导航与使用指南](../项目导航与使用指南.md) - 完整学习路径

### 学习资源

- [Docker容器管理](../Container/01_Docker技术详解/02_Docker容器管理.md) - 容器运维实践
- [vCenter管理技术](../vShpere_VMware/03_vCenter Server技术/01_vCenter架构原理.md) - 虚拟化管理
- [网络虚拟化技术](../vShpere_VMware/06_网络虚拟化技术/01_NSX架构原理.md) - 网络技术
- [存储虚拟化技术](../vShpere_VMware/05_存储虚拟化技术/01_vSAN架构原理.md) - 存储技术

### 更新日志 🆕

**v3.0 (2025-10-19 - 重大更新)**:

新增企业级标准配置章节（+1300行）:

- ✅ 第8章：存储架构标准配置（400行）
  - 存储类型全面对比（DAS/NAS/SAN/HCI）
  - 详细的产品推荐和价格
  - 完整的配置脚本和命令
  - vSAN和Ceph集群规划
  - 存储性能对比表
  
- ✅ 第9章：网络架构标准配置（220行）
  - 标准VLAN规划（管理/存储/vMotion/业务）
  - Cisco交换机完整配置示例
  - VMware vDS LACP配置脚本
  - Jumbo Frame全链路配置
  - QoS流量整形标准
  - 网络安全策略
  
- ✅ 第10章：高可用与容灾配置（430行）
  - VMware HA完整配置标准
  - Kubernetes HA架构（HAProxy+Keepalived）
  - etcd集群高可用配置
  - 企业级备份脚本（350行）
  - VMware/K8s/etcd全方位备份
  
- ✅ PowerShell/Bash完整脚本（可直接使用）
- ✅ 文档规模：2700行 → 3550行（增长31%）

**v2.0 (2025-10-19)**:

- ✅ 新增详细硬件选型指南（CPU、内存、存储、网络）
- ✅ 新增BIOS/固件配置清单
- ✅ 新增硬件兼容性清单 (HCL)
- ✅ 扩展VMware vSphere完整安装部署流程
- ✅ 新增KVM/Hyper-V虚拟化平台部署指南
- ✅ 新增虚拟机模板创建最佳实践
- ✅ 文档规模从930行扩展至2700行

**v1.0 (初始版本)**:

- 基础部署流程
- 容器化配置
- 监控和故障排除

**累计更新**: 930行 → 3550行（增长282%）🎉

---

_本指南提供了完整的虚拟化容器化部署方案，包括环境准备、部署实施、监控运维和故障排除，确保系统稳定可靠运行。_
